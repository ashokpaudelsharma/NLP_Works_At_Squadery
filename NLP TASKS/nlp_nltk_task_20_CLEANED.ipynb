{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941e4b40",
   "metadata": {},
   "source": [
    "20. The bigram chunker scores about 90% accuracy. Study its errors and try to work out why it doesn't get 100% accuracy. Experiment with trigram chunking. Are you able to improve the performance anymore?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839ab24",
   "metadata": {},
   "source": [
    "UNIGRAM CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25f7601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad904caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "        print(train_data[0])\n",
    "        \n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef911e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
    "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f930b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 'B-NP'), ('IN', 'O'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'O'), ('RB', 'O'), ('VBN', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'O'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "unigram_chunker = UnigramChunker(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81328201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10076\\1622758052.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(unigram_chunker.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  92.9%%\n",
      "    Precision:     79.9%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     83.2%%\n"
     ]
    }
   ],
   "source": [
    "print(unigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a50ea7",
   "metadata": {},
   "source": [
    "BIGRAM CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6d9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbc2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        tokens_list=[[w for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        t_c_tuples_list=[[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        print(t_c_tuples_list[0])\n",
    "        print()\n",
    "        \n",
    "        '''\n",
    "        bigrams=[]\n",
    "        i=0\n",
    "        for tokens in t_c_tuples_list:\n",
    "            bigrams.append(list(ngrams(tokens,2)))\n",
    "            i=i+1\n",
    "        \n",
    "        print(bigrams[0])\n",
    "        '''\n",
    "        \n",
    "        self.tagger = nltk.BigramTagger(t_c_tuples_list)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287a1b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 'B-NP'), ('IN', 'O'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'O'), ('RB', 'O'), ('VBN', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'O'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_chunker = BigramChunker(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fae20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10076\\4254016035.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(bigram_chunker.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.3%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.5%%\n"
     ]
    }
   ],
   "source": [
    "print(bigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ff337",
   "metadata": {},
   "source": [
    "TRIGRAM CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5947d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        tokens_list=[[w for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        t_c_tuples_list=[[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        print(t_c_tuples_list[0])\n",
    "        print()\n",
    "        \n",
    "        self.tagger = nltk.TrigramTagger(t_c_tuples_list)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155a97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 'B-NP'), ('IN', 'O'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'O'), ('RB', 'O'), ('VBN', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'O'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'O'), ('TO', 'O'), ('VB', 'O'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_chunker = TrigramChunker(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0bb38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10076\\2905930914.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(trigram_chunker.evaluate(test_sents))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.5%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.6%%\n"
     ]
    }
   ],
   "source": [
    "print(trigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dbe7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebf54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eab91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2238c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c9308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5cf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292f803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
