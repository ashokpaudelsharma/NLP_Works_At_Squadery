{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a316315",
   "metadata": {},
   "source": [
    "# Collocations and Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a7ee2",
   "metadata": {},
   "source": [
    "Collocations are the multi-word phrases in pieces of text coming from various from text source (web- page, document, etc.). In case of collocations, we group the words that tend to frequently appear together into various phrases in various combinations of different numbers.\n",
    "\n",
    "Two common types of collocations: \n",
    "\n",
    "A: Bigrams: Groups each containing two frequently occuring words together.\n",
    "e.g,\"artificial intelligence\",\"due to\", etc.\n",
    "\n",
    "B: Trigrams: Groups each containing two frequently occuring words together. \n",
    "e.g, \"the New York\", \"the United States\", etc. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea81b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906d92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('The', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumped'), ('jumped', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dog'), ('dog', '.'))\n"
     ]
    }
   ],
   "source": [
    "#Defining the example text to be considered\n",
    "text= \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "#Extracting unigram tokens first\n",
    "Tokens= nltk.word_tokenize(text)\n",
    "\n",
    "#Creating bigrams from the tokens\n",
    "bigram_tokens= tuple(nltk.bigrams(Tokens))\n",
    "print(bigram_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616136af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('The', 'quick', 'brown'), ('quick', 'brown', 'fox'), ('brown', 'fox', 'jumped'), ('fox', 'jumped', 'over'), ('jumped', 'over', 'the'), ('over', 'the', 'lazy'), ('the', 'lazy', 'dog'), ('lazy', 'dog', '.'))\n"
     ]
    }
   ],
   "source": [
    "#Creating trigrams from the tokens\n",
    "trigram_tokens= tuple(nltk.trigrams(Tokens))\n",
    "print(trigram_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99970378",
   "metadata": {},
   "source": [
    "Note: Not all bigrams and trigrams are meaningful. Combinations like ('brown', 'fox'), ('fox', 'jumped'),('quick', 'brown', 'fox'), ('brown', 'fox', 'jumped'), , can be used meaningfully, ('over', 'the'), ('over', 'the', 'lazy'), while combinations like  hold little significance since the bigram and trigram, in the latter cases, don't add much of semantic significance over the  semantic significance of the individual words like ('over','the') or don't act as self- content, stand-alone phrases as in the case of ('over', 'the', 'lazy') . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421ac68",
   "metadata": {},
   "source": [
    "Now, we are going to explore some of the methods that are going to filter- off the meaningful collocations from the non- meaningful ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5ddcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the text to be considered\n",
    "\n",
    "original_text=\"Artificial Intelligence (AI) By JAKE FRANKENFIELD Updated March 08, 2021 Reviewed by GORDON SCOTT What Is Artificial Intelligence (AI)? Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving. The ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. A subset of artificial intelligence is machine learning, which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by humans. Deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as text, images, or video. KEY TAKEAWAYS Artificial intelligence refers to the simulation of human intelligence in machines. The goals of artificial intelligence include learning, reasoning, and perception. AI is being used across different industries including finance and healthcare. Weak AI tends to be simple and single-task oriented, while strong AI carries on tasks that are more complex and human-like. What if you had started investing years ago? Find out what a hypothetical investment would be worth today. SELECT A STOCK TSLA TESLA INC AAPL APPLE INC NKE NIKE INC AMZN AMAZON.COM, INC WMT WALMART INC SELECT INVESTMENT AMOUNT $ 1,000 SELECT A PURCHASE DATE 5 years ago CALCULATE Understanding Artificial Intelligence (AI) When most people hear the term artificial intelligence, the first thing they usually think of is robots. That's because big-budget films and novels weave stories about human-like machines that wreak havoc on Earth. But nothing could be further from the truth. Artificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute tasks, from the most simple to those that are even more complex.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd584a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given piece of text converted to a list:\n",
      "\n",
      "['artificial', 'intelligence', '(ai)', 'by', 'jake', 'frankenfield', 'updated', 'march', '08,', '2021', 'reviewed', 'by', 'gordon', 'scott', 'what', 'is', 'artificial', 'intelligence', '(ai)?', 'artificial', 'intelligence', '(ai)', 'refers', 'to', 'the', 'simulation', 'of', 'human', 'intelligence', 'in', 'machines', 'that', 'are', 'programmed', 'to', 'think', 'like', 'humans', 'and', 'mimic', 'their', 'actions.', 'the', 'term', 'may', 'also', 'be', 'applied', 'to', 'any', 'machine', 'that', 'exhibits', 'traits', 'associated', 'with', 'a', 'human', 'mind', 'such', 'as', 'learning', 'and', 'problem-solving.', 'the', 'ideal', 'characteristic', 'of', 'artificial', 'intelligence', 'is', 'its', 'ability', 'to', 'rationalize', 'and', 'take', 'actions', 'that', 'have', 'the', 'best', 'chance', 'of', 'achieving', 'a', 'specific', 'goal.', 'a', 'subset', 'of', 'artificial', 'intelligence', 'is', 'machine', 'learning,', 'which', 'refers', 'to', 'the', 'concept', 'that', 'computer', 'programs', 'can', 'automatically', 'learn', 'from', 'and', 'adapt', 'to', 'new', 'data', 'without', 'being', 'assisted', 'by', 'humans.', 'deep', 'learning', 'techniques', 'enable', 'this', 'automatic', 'learning', 'through', 'the', 'absorption', 'of', 'huge', 'amounts', 'of', 'unstructured', 'data', 'such', 'as', 'text,', 'images,', 'or', 'video.', 'key', 'takeaways', 'artificial', 'intelligence', 'refers', 'to', 'the', 'simulation', 'of', 'human', 'intelligence', 'in', 'machines.', 'the', 'goals', 'of', 'artificial', 'intelligence', 'include', 'learning,', 'reasoning,', 'and', 'perception.', 'ai', 'is', 'being', 'used', 'across', 'different', 'industries', 'including', 'finance', 'and', 'healthcare.', 'weak', 'ai', 'tends', 'to', 'be', 'simple', 'and', 'single-task', 'oriented,', 'while', 'strong', 'ai', 'carries', 'on', 'tasks', 'that', 'are', 'more', 'complex', 'and', 'human-like.', 'what', 'if', 'you', 'had', 'started', 'investing', 'years', 'ago?', 'find', 'out', 'what', 'a', 'hypothetical', 'investment', 'would', 'be', 'worth', 'today.', 'select', 'a', 'stock', 'tsla', 'tesla', 'inc', 'aapl', 'apple', 'inc', 'nke', 'nike', 'inc', 'amzn', 'amazon.com,', 'inc', 'wmt', 'walmart', 'inc', 'select', 'investment', 'amount', '$', '1,000', 'select', 'a', 'purchase', 'date', '5', 'years', 'ago', 'calculate', 'understanding', 'artificial', 'intelligence', '(ai)', 'when', 'most', 'people', 'hear', 'the', 'term', 'artificial', 'intelligence,', 'the', 'first', 'thing', 'they', 'usually', 'think', 'of', 'is', 'robots.', \"that's\", 'because', 'big-budget', 'films', 'and', 'novels', 'weave', 'stories', 'about', 'human-like', 'machines', 'that', 'wreak', 'havoc', 'on', 'earth.', 'but', 'nothing', 'could', 'be', 'further', 'from', 'the', 'truth.', 'artificial', 'intelligence', 'is', 'based', 'on', 'the', 'principle', 'that', 'human', 'intelligence', 'can', 'be', 'defined', 'in', 'a', 'way', 'that', 'a', 'machine', 'can', 'easily', 'mimic', 'it', 'and', 'execute', 'tasks,', 'from', 'the', 'most', 'simple', 'to', 'those', 'that', 'are', 'even', 'more', 'complex.']\n"
     ]
    }
   ],
   "source": [
    "print(\"The given piece of text converted to a list:\")\n",
    "print()\n",
    "text=original_text.lower().split()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7924f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: [10, 12, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 6, 10, 12, 1, 10, 12, 3, 3, 9, 13, 2, 9, 4, 12, 3, 2, 9, 3, 1, 9, 2, 1, 1, 10, 2, 1, 1, 13, 2, 1, 1, 5, 1, 9, 1, 3, 9, 1, 1, 1, 1, 8, 4, 1, 2, 2, 3, 10, 1, 13, 1, 1, 9, 10, 12, 6, 1, 1, 9, 1, 10, 1, 1, 9, 1, 13, 1, 1, 9, 1, 8, 1, 1, 8, 1, 9, 10, 12, 6, 3, 2, 1, 3, 9, 13, 1, 9, 1, 1, 3, 1, 1, 3, 10, 1, 9, 1, 2, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 1, 3, 1, 13, 1, 9, 1, 1, 9, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 10, 12, 3, 9, 13, 2, 9, 4, 12, 3, 1, 13, 1, 9, 10, 12, 1, 2, 1, 10, 1, 3, 6, 2, 1, 1, 1, 1, 1, 1, 10, 1, 1, 3, 1, 9, 5, 2, 10, 1, 1, 1, 1, 3, 1, 3, 1, 9, 3, 2, 1, 10, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 8, 1, 2, 1, 5, 1, 1, 3, 8, 1, 1, 1, 5, 1, 1, 5, 1, 1, 5, 1, 1, 5, 1, 1, 5, 3, 2, 1, 1, 1, 3, 8, 1, 1, 1, 2, 1, 1, 1, 10, 12, 3, 1, 2, 1, 1, 13, 2, 10, 1, 13, 1, 1, 1, 1, 2, 9, 6, 1, 1, 1, 1, 1, 10, 1, 1, 1, 1, 1, 2, 9, 1, 1, 3, 1, 1, 1, 1, 5, 1, 3, 13, 1, 10, 12, 6, 1, 3, 13, 1, 9, 4, 12, 3, 5, 1, 3, 8, 1, 9, 8, 3, 3, 1, 2, 1, 10, 1, 1, 3, 13, 2, 2, 9, 1, 9, 3, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the frequency of unigrams\n",
    "\n",
    "wordfreq=[]\n",
    "for w in text:\n",
    "    wordfreq.append(text.count(w))\n",
    "\n",
    "print(\"Frequencies: \"+str(wordfreq))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e240bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: (('artificial', 10), ('intelligence', 12), ('(ai)', 3), ('by', 3), ('jake', 1), ('frankenfield', 1), ('updated', 1), ('march', 1), ('08,', 1), ('2021', 1), ('reviewed', 1), ('by', 3), ('gordon', 1), ('scott', 1), ('what', 3), ('is', 6), ('artificial', 10), ('intelligence', 12), ('(ai)?', 1), ('artificial', 10), ('intelligence', 12), ('(ai)', 3), ('refers', 3), ('to', 9), ('the', 13), ('simulation', 2), ('of', 9), ('human', 4), ('intelligence', 12), ('in', 3), ('machines', 2), ('that', 9), ('are', 3), ('programmed', 1), ('to', 9), ('think', 2), ('like', 1), ('humans', 1), ('and', 10), ('mimic', 2), ('their', 1), ('actions.', 1), ('the', 13), ('term', 2), ('may', 1), ('also', 1), ('be', 5), ('applied', 1), ('to', 9), ('any', 1), ('machine', 3), ('that', 9), ('exhibits', 1), ('traits', 1), ('associated', 1), ('with', 1), ('a', 8), ('human', 4), ('mind', 1), ('such', 2), ('as', 2), ('learning', 3), ('and', 10), ('problem-solving.', 1), ('the', 13), ('ideal', 1), ('characteristic', 1), ('of', 9), ('artificial', 10), ('intelligence', 12), ('is', 6), ('its', 1), ('ability', 1), ('to', 9), ('rationalize', 1), ('and', 10), ('take', 1), ('actions', 1), ('that', 9), ('have', 1), ('the', 13), ('best', 1), ('chance', 1), ('of', 9), ('achieving', 1), ('a', 8), ('specific', 1), ('goal.', 1), ('a', 8), ('subset', 1), ('of', 9), ('artificial', 10), ('intelligence', 12), ('is', 6), ('machine', 3), ('learning,', 2), ('which', 1), ('refers', 3), ('to', 9), ('the', 13), ('concept', 1), ('that', 9), ('computer', 1), ('programs', 1), ('can', 3), ('automatically', 1), ('learn', 1), ('from', 3), ('and', 10), ('adapt', 1), ('to', 9), ('new', 1), ('data', 2), ('without', 1), ('being', 2), ('assisted', 1), ('by', 3), ('humans.', 1), ('deep', 1), ('learning', 3), ('techniques', 1), ('enable', 1), ('this', 1), ('automatic', 1), ('learning', 3), ('through', 1), ('the', 13), ('absorption', 1), ('of', 9), ('huge', 1), ('amounts', 1), ('of', 9), ('unstructured', 1), ('data', 2), ('such', 2), ('as', 2), ('text,', 1), ('images,', 1), ('or', 1), ('video.', 1), ('key', 1), ('takeaways', 1), ('artificial', 10), ('intelligence', 12), ('refers', 3), ('to', 9), ('the', 13), ('simulation', 2), ('of', 9), ('human', 4), ('intelligence', 12), ('in', 3), ('machines.', 1), ('the', 13), ('goals', 1), ('of', 9), ('artificial', 10), ('intelligence', 12), ('include', 1), ('learning,', 2), ('reasoning,', 1), ('and', 10), ('perception.', 1), ('ai', 3), ('is', 6), ('being', 2), ('used', 1), ('across', 1), ('different', 1), ('industries', 1), ('including', 1), ('finance', 1), ('and', 10), ('healthcare.', 1), ('weak', 1), ('ai', 3), ('tends', 1), ('to', 9), ('be', 5), ('simple', 2), ('and', 10), ('single-task', 1), ('oriented,', 1), ('while', 1), ('strong', 1), ('ai', 3), ('carries', 1), ('on', 3), ('tasks', 1), ('that', 9), ('are', 3), ('more', 2), ('complex', 1), ('and', 10), ('human-like.', 1), ('what', 3), ('if', 1), ('you', 1), ('had', 1), ('started', 1), ('investing', 1), ('years', 2), ('ago?', 1), ('find', 1), ('out', 1), ('what', 3), ('a', 8), ('hypothetical', 1), ('investment', 2), ('would', 1), ('be', 5), ('worth', 1), ('today.', 1), ('select', 3), ('a', 8), ('stock', 1), ('tsla', 1), ('tesla', 1), ('inc', 5), ('aapl', 1), ('apple', 1), ('inc', 5), ('nke', 1), ('nike', 1), ('inc', 5), ('amzn', 1), ('amazon.com,', 1), ('inc', 5), ('wmt', 1), ('walmart', 1), ('inc', 5), ('select', 3), ('investment', 2), ('amount', 1), ('$', 1), ('1,000', 1), ('select', 3), ('a', 8), ('purchase', 1), ('date', 1), ('5', 1), ('years', 2), ('ago', 1), ('calculate', 1), ('understanding', 1), ('artificial', 10), ('intelligence', 12), ('(ai)', 3), ('when', 1), ('most', 2), ('people', 1), ('hear', 1), ('the', 13), ('term', 2), ('artificial', 10), ('intelligence,', 1), ('the', 13), ('first', 1), ('thing', 1), ('they', 1), ('usually', 1), ('think', 2), ('of', 9), ('is', 6), ('robots.', 1), (\"that's\", 1), ('because', 1), ('big-budget', 1), ('films', 1), ('and', 10), ('novels', 1), ('weave', 1), ('stories', 1), ('about', 1), ('human-like', 1), ('machines', 2), ('that', 9), ('wreak', 1), ('havoc', 1), ('on', 3), ('earth.', 1), ('but', 1), ('nothing', 1), ('could', 1), ('be', 5), ('further', 1), ('from', 3), ('the', 13), ('truth.', 1), ('artificial', 10), ('intelligence', 12), ('is', 6), ('based', 1), ('on', 3), ('the', 13), ('principle', 1), ('that', 9), ('human', 4), ('intelligence', 12), ('can', 3), ('be', 5), ('defined', 1), ('in', 3), ('a', 8), ('way', 1), ('that', 9), ('a', 8), ('machine', 3), ('can', 3), ('easily', 1), ('mimic', 2), ('it', 1), ('and', 10), ('execute', 1), ('tasks,', 1), ('from', 3), ('the', 13), ('most', 2), ('simple', 2), ('to', 9), ('those', 1), ('that', 9), ('are', 3), ('even', 1), ('more', 2), ('complex.', 1))\n"
     ]
    }
   ],
   "source": [
    "#Printing the pairs of words and frequencies: \n",
    "print(\"Pairs: \"+str(tuple(zip(text,wordfreq))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031841d",
   "metadata": {},
   "source": [
    "# Calculate the Frequency of Bigrams and Find the most frequent Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a947e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('artificial', 'intelligence'): 9, ('intelligence', '(ai)'): 3, ('refers', 'to'): 3, ('to', 'the'): 3, ('human', 'intelligence'): 3, ('that', 'are'): 3, ('of', 'artificial'): 3, ('intelligence', 'is'): 3, ('the', 'simulation'): 2, ('simulation', 'of'): 2, ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_generator=nltk.bigrams(text)\n",
    "#for frequency distribution\n",
    "bigram_fd=nltk.FreqDist(bigram_generator)\n",
    "bigram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350eb5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('artificial', 'intelligence'), 9),\n",
       " (('intelligence', '(ai)'), 3),\n",
       " (('refers', 'to'), 3),\n",
       " (('to', 'the'), 3),\n",
       " (('human', 'intelligence'), 3),\n",
       " (('that', 'are'), 3),\n",
       " (('of', 'artificial'), 3),\n",
       " (('intelligence', 'is'), 3),\n",
       " (('the', 'simulation'), 2),\n",
       " (('simulation', 'of'), 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfeb7fd",
   "metadata": {},
   "source": [
    "# Calculate the Frequency of Trigrams and Find the most frequent Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60c7a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('artificial', 'intelligence', '(ai)'): 3, ('refers', 'to', 'the'): 3, ('of', 'artificial', 'intelligence'): 3, ('artificial', 'intelligence', 'is'): 3, ('to', 'the', 'simulation'): 2, ('the', 'simulation', 'of'): 2, ('simulation', 'of', 'human'): 2, ('of', 'human', 'intelligence'): 2, ('human', 'intelligence', 'in'): 2, ('intelligence', '(ai)', 'by'): 1, ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_generator=nltk.trigrams(text)\n",
    "#for frequency distribution\n",
    "trigram_fd=nltk.FreqDist(trigram_generator)\n",
    "trigram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ec97cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('artificial', 'intelligence', '(ai)'), 3),\n",
       " (('refers', 'to', 'the'), 3),\n",
       " (('of', 'artificial', 'intelligence'), 3),\n",
       " (('artificial', 'intelligence', 'is'), 3),\n",
       " (('to', 'the', 'simulation'), 2),\n",
       " (('the', 'simulation', 'of'), 2),\n",
       " (('simulation', 'of', 'human'), 2),\n",
       " (('of', 'human', 'intelligence'), 2),\n",
       " (('human', 'intelligence', 'in'), 2),\n",
       " (('intelligence', '(ai)', 'by'), 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdc074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
