{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38014e15",
   "metadata": {},
   "source": [
    "IMPORTING NLTK LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08d8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize #For tokenization\n",
    "from nltk.corpus import stopwords #For stopwords\n",
    "\n",
    "import re #For regular expressions\n",
    "from nltk.stem import WordNetLemmatizer #For Lemmatization\n",
    "from  nltk.stem import PorterStemmer #For stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4559c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the sample text to be considered for various NLP processes\n",
    "example_text=\"Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290fad2",
   "metadata": {},
   "source": [
    "SENTENCE TOKENIZATION AND WORD TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6554c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans.', 'AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.']\n"
     ]
    }
   ],
   "source": [
    "#Implementing Sentence Tokenization\n",
    "print(sent_tokenize(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad454b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence number 1: Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans.\n",
      "\n",
      "Sentence number 2: AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Expressing Sentence Tokenization In More Readable Way\n",
    "\n",
    "i=1\n",
    "for sent in sent_tokenize(example_text):\n",
    "    print(\"Sentence number \"+str(i)+\": \"+sent)\n",
    "    print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b025d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'intelligence', '(', 'AI', ')', 'is', 'intelligence', 'demonstrated', 'by', 'machines', ',', 'as', 'opposed', 'to', 'the', 'natural', 'intelligence', 'displayed', 'by', 'animals', 'including', 'humans', '.', 'AI', 'research', 'has', 'been', 'defined', 'as', 'the', 'field', 'of', 'study', 'of', 'intelligent', 'agents', ',', 'which', 'refers', 'to', 'any', 'system', 'that', 'perceives', 'its', 'environment', 'and', 'takes', 'actions', 'that', 'maximize', 'its', 'chance', 'of', 'achieving', 'its', 'goals', '.']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenizer\n",
    "original_tokens= word_tokenize(example_text)\n",
    "print(original_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b71e9",
   "metadata": {},
   "source": [
    "Note: As we can see that a lot of stop- symbols stopwords were observed in the word tokenization process, so, let's attempt to clean up the text as follows. We start by dealing with punctuation symbols known as stop symbols and semantically low-significance words known as stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c31c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence  AI  is intelligence demonstrated by machines  as opposed to the natural intelligence displayed by animals including humans  AI research has been defined as the field of study of intelligent agents  which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals \n"
     ]
    }
   ],
   "source": [
    "#Cleaning off the punctuation symbols \n",
    "\n",
    "cleaned_sent= re.sub(\"[^a-zA-Z]\",\" \",example_text)\n",
    "print(cleaned_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d0d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'intelligence', 'AI', 'is', 'intelligence', 'demonstrated', 'by', 'machines', 'as', 'opposed', 'to', 'the', 'natural', 'intelligence', 'displayed', 'by', 'animals', 'including', 'humans', 'AI', 'research', 'has', 'been', 'defined', 'as', 'the', 'field', 'of', 'study', 'of', 'intelligent', 'agents', 'which', 'refers', 'to', 'any', 'system', 'that', 'perceives', 'its', 'environment', 'and', 'takes', 'actions', 'that', 'maximize', 'its', 'chance', 'of', 'achieving', 'its', 'goals']\n"
     ]
    }
   ],
   "source": [
    "#Performing the word tokenization again to obtain the words only\n",
    "cleaned_words= word_tokenize(cleaned_sent)\n",
    "print(cleaned_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfd3df",
   "metadata": {},
   "source": [
    "DEALING WITH STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df39b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the stopwrords\n",
    "stop_words= set(stopwords.words(\"english\"))\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a334bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'intelligence', 'AI', 'intelligence', 'demonstrated', 'machines', 'opposed', 'natural', 'intelligence', 'displayed', 'animals', 'including', 'humans', 'AI', 'research', 'defined', 'field', 'study', 'intelligent', 'agents', 'refers', 'system', 'perceives', 'environment', 'takes', 'actions', 'maximize', 'chance', 'achieving', 'goals']\n"
     ]
    }
   ],
   "source": [
    "#Filtering the list of words by removing the stopwords \n",
    "\n",
    "filtered_word_list=[]\n",
    "\n",
    "for w in cleaned_words:\n",
    "    if w not in stop_words:\n",
    "        filtered_word_list.append(w)\n",
    "        \n",
    "print(filtered_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7703f8",
   "metadata": {},
   "source": [
    "Note: The above list of words can be called the logically and semantically significant results of word-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec70ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence AI intelligence demonstrated machines opposed natural intelligence displayed animals including humans AI research defined field study intelligent agents refers system perceives environment takes actions maximize chance achieving goals\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the sentence- version of the filtered_word_list\n",
    "\n",
    "filtered_sentence=\" \".join(filtered_word_list)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac64c90",
   "metadata": {},
   "source": [
    "PERFORMING STEMMING AND LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a530863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the objects for stemming and lemmatization\n",
    "\n",
    "ps=PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8174b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of stemmed versions of the words: \n",
      "['artifici', 'intellig', 'ai', 'intellig', 'demonstr', 'machin', 'oppos', 'natur', 'intellig', 'display', 'anim', 'includ', 'human', 'ai', 'research', 'defin', 'field', 'studi', 'intellig', 'agent', 'refer', 'system', 'perceiv', 'environ', 'take', 'action', 'maxim', 'chanc', 'achiev', 'goal']\n",
      "\n",
      "The list of lemmatized versions of the words: \n",
      "['Artificial', 'intelligence', 'AI', 'intelligence', 'demonstrated', 'machine', 'opposed', 'natural', 'intelligence', 'displayed', 'animal', 'including', 'human', 'AI', 'research', 'defined', 'field', 'study', 'intelligent', 'agent', 'refers', 'system', 'perceives', 'environment', 'take', 'action', 'maximize', 'chance', 'achieving', 'goal']\n"
     ]
    }
   ],
   "source": [
    "stemmed_word_list=[] #For stemming\n",
    "lemmatized_word_list=[] #For lemmatizing\n",
    "\n",
    "for word in filtered_word_list:\n",
    "    stemmed_word_list.append(ps.stem(word))\n",
    "    lemmatized_word_list.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "        \n",
    "print(\"The list of stemmed versions of the words: \")\n",
    "print(stemmed_word_list)\n",
    "print()\n",
    "print(\"The list of lemmatized versions of the words: \")\n",
    "print(lemmatized_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0d680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed sentence: \n",
      "artifici intellig ai intellig demonstr machin oppos natur intellig display anim includ human ai research defin field studi intellig agent refer system perceiv environ take action maxim chanc achiev goal\n",
      "\n",
      "The lemmatized sentence: \n",
      "Artificial intelligence AI intelligence demonstrated machine opposed natural intelligence displayed animal including human AI research defined field study intelligent agent refers system perceives environment take action maximize chance achieving goal\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the sentence- version of the stemmed_word_list and lemmatized_word_list\n",
    "\n",
    "print(\"The stemmed sentence: \")\n",
    "stemmed_sentence=\" \".join(stemmed_word_list)\n",
    "print(stemmed_sentence)\n",
    "print()\n",
    "print(\"The lemmatized sentence: \")\n",
    "lemmatized_sentence=\" \".join(lemmatized_word_list)\n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfef9e",
   "metadata": {},
   "source": [
    "PART-OF-SPEECH (POS) TAGGING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cc51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6bf93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'intelligence', 'AI', 'is', 'intelligence', 'demonstrated', 'by', 'machines', 'as', 'opposed', 'to', 'the', 'natural', 'intelligence', 'displayed', 'by', 'animals', 'including', 'humans', 'AI', 'research', 'has', 'been', 'defined', 'as', 'the', 'field', 'of', 'study', 'of', 'intelligent', 'agents', 'which', 'refers', 'to', 'any', 'system', 'that', 'perceives', 'its', 'environment', 'and', 'takes', 'actions', 'that', 'maximize', 'its', 'chance', 'of', 'achieving', 'its', 'goals']\n"
     ]
    }
   ],
   "source": [
    "#Retrieving the list of words only (exclude puctuation signs)\n",
    "print(cleaned_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f100fc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('AI', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('demonstrated', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('machines', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('opposed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('natural', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('displayed', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('animals', 'NNS'),\n",
       " ('including', 'VBG'),\n",
       " ('humans', 'NNS'),\n",
       " ('AI', 'NNP'),\n",
       " ('research', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('defined', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('study', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('intelligent', 'NN'),\n",
       " ('agents', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('refers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('any', 'DT'),\n",
       " ('system', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('perceives', 'VBZ'),\n",
       " ('its', 'PRP$'),\n",
       " ('environment', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('takes', 'VBZ'),\n",
       " ('actions', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('maximize', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('chance', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('achieving', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('goals', 'NNS')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words= pos_tag(cleaned_words)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa29fa",
   "metadata": {},
   "source": [
    "CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b30ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noun Phrase Chunking\n",
    "\n",
    "chunk_grammar=\"NP:{<DT>?<JJ>*<NN>|<NNS>}\" #combination of optional determiner(dt), at least 0 adjectives and common noun is a noun-phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ebde349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a parser \n",
    "\n",
    "chunk_parser= nltk.RegexpParser(chunk_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f82d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding output of parsing\n",
    "\n",
    "chunk_parse_result= chunk_parser.parse(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e97fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the result\n",
    "\n",
    "#chunk_parse_result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e381c",
   "metadata": {},
   "source": [
    "CHINKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f34d236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am attempting to chink the prepositions and determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d93be73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chink_grammar=\"NOT_IN_DT: }<IN|DT>{\" #chink the prepositions and determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c3729cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a parser \n",
    "\n",
    "chink_parser= nltk.RegexpParser(chink_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "552798d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding output of parsing\n",
    "\n",
    "chink_parse_result= chink_parser.parse(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aafee6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the result\n",
    "\n",
    "chink_parse_result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79face",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
