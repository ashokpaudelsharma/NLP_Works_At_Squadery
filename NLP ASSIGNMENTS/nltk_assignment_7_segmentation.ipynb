{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8fdfc4",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41578c2",
   "metadata": {},
   "source": [
    "Create a python program to get the different segments like Abstract, Methodology, Conclusion in a research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65561b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from PyPDF2) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "#install pyDF2\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154efb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# importing all the required modules\n",
    "import PyPDF2\n",
    "\n",
    "# creating an object \n",
    "file = open('example_research_paper.pdf', 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(fileReader.numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f266e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "pageObj=[]\n",
    "for page in range(0,fileReader.numPages):\n",
    "        pageObj.append(fileReader.getPage(page))\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c9b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pageObj[0]\n",
    "#print(pageObj[1].extractText())\n",
    "#len(pageObj[1].extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cee82ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Beyond News Contents:\\nThe Role of Social Context for Fake News Detection\\nKai Shu\\nArizona State University\\nkai.shu@asu.eduSuhang Wang\\nPenn State University\\nszw494@psu.eduHuan Liu\\nArizona State University\\nhuan.liu@asu.edu\\nABSTRACT\\nSocial media is becoming popular for news consumption due to\\nitsfastdissemination,easyaccess,andlowcost.However,italso\\nenablesthewidepropagationoffake news,i.e.,newswithintention-\\nally false information. Detecting fake news is an important task,\\nwhich not only ensures users receive authentic information but\\nalsohelpsmaintainatrustworthynewsecosystem.Themajority\\nofexistingdetectionalgorithmsfocusonfindingcluesfromnews\\ncontents, which are generally not effective because fake news is of-\\nten intentionally written to mislead users by mimicking true news.\\nTherefore, we need to explore auxiliary information to improve\\ndetection.Thesocialcontextduringnewsdisseminationprocess\\non social media formsthe inherenttri-relationship, the relationship\\namongpublishers,newspieces,andusers,whichhaspotentialto\\nimprovefakenewsdetection.Forexample,partisan-biasedpublish-\\ners are more likely to publish fake news, and low-credible users\\nare more likely to share fake news. In this paper, we study the\\nnovel problem of exploiting social context for fake news detection.\\nWe propose a tri-relationship embedding framework TriFN, which\\nmodels publisher-news relations and user-news interactions simul-\\ntaneously for fake news classification. We conduct experiments\\non two real-worlddatasets, which demonstratethat the proposed\\napproachsignificantlyoutperformsotherbaselinemethodsforfake\\nnews detection.\\nKEYWORDS\\nFake news detection; joint learning; social media mining\\nACM Reference Format:\\nKaiShu,SuhangWang,andHuanLiu.2019.BeyondNewsContents:The\\nRole of Social Context for Fake News Detection. InThe Twelfth ACM Inter-\\nnational Conference on Web Search and Data Mining (WSDM ’19), February\\n11–15, 2019, Melbourne, VIC, Australia.ACM, New York, NY, USA, 9 pages.\\nhttps://doi.org/10.1145/3289600.3290994\\n1 INTRODUCTION\\nPeoplenowadaystendtoseekoutand consumenewsfromsocial\\nmediaratherthantraditionalnewsorganizations.Forexample,62%\\nof U.S. adults get news on social media in 2016, while in 2012, only\\nPermissionto make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\\non the first page. Copyrights for components of this work owned by others than ACM\\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,\\ntopostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\\nfee. Request permissions from permissions@acm.org.\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n© 2019 Association for Computing Machinery.\\nACM ISBN 978-1-4503-5940-5/19/02...$15.00\\nhttps://doi.org/10.1145/3289600.329099449percentisreportedseeingnewsonsocialmedia1\\n.However,social\\nmedia is a double-edged sword for news consumption. The quality\\nof news on social media is much lower than that of traditional\\nnews organizations. Large volumes offake news, i.e., news with\\nintentionallyfalseinformation,areproducedonlineforavariety\\nof purposes, such as financial and political gain [2, 13].\\nFakenewscanhavedetrimentaleffectsonindividualsandthe\\nsociety. First, people may be misled by fake news and accept false\\nbeliefs [18,21]. Second, fake news could change the way people\\nrespondtotruenews2\\n.Third,thewidepropagationoffakenews\\ncould break the trustworthiness of entire news ecosystem. Thus, it\\nisimportanttodetectfakenewsonsocialmedia.Fakenewsisinten-\\ntionallywrittentomisleadconsumers,whichmakesitnontrivial\\ntodetectsimplybasedonnewscontent.Tobuildaneffectiveand\\npractical fake news detection system, it is natural and necessary to\\nexploreauxiliary informationfrom different perspectives.\\nThenewsecosystemonsocialmediaprovidesabundantsocial\\ncontextinformation,whichinvolvesthreebasicentities,i.e.,pub-\\nlishers, news pieces, and social media users. Figure 1 gives an il-\\nlustration of such ecosystem. In Figure 1,\\np\\n1,p\\n2andp\\n3are news\\npublishers who publish news\\na\\n1,...,a\\n4andu\\n1,...,u\\n6are users\\nwho have engaged in sharing these news pieces. In addition, users\\ntendtoformsociallinkswithlike-mindedpeoplewithsimilarinter-\\nests.Aswewillshow,thetri-relationship,therelationshipamong\\npublishers, news pieces, and users, contains additional information\\nto help detect fake news.\\nFirst,sociological studies on journalism have theorized the cor-\\nrelation between the partisan bias of publisher and the veracity\\ndegree of news content [8]. The partisan bias means the perceived\\nbiasofthepublisherintheselectionofhownewsisreportedand\\ncovered[6].Forexample,inFigure1,p\\n1isapublisherwithextreme\\nleft partisan bias andp\\n2is a publisher with extreme right partisan\\nbias. To support their own partisan viewpoints, they have high\\ndegreetodistortthefactsandreportfakenewspieces,suchasa\\n1\\nanda\\n3; while for a mainstream publisherp\\n3that has least partisan\\nbias,he/shehasalowerchancetomanipulateoriginalnewsevents,\\nand is more likely to write a true news piecea\\n4. Thus, exploit-\\ning the partisan bias of publishers to bridge the publisher-news\\nrelationships can bring additional benefits to predict fake news.\\nSecond,mininguserengagementstowardsnewspiecesonsocial\\nmedia also help fake news detection. Previous approaches try to\\naggregate users’ attributesto infer the degree of news veracity by\\nassumingthateither(i)alltheuserscontributeequallyforlearning\\nfeature representations of news pieces [\\n10]; or (ii) user features are\\n1\\nhttp://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-\\n2016/\\n2\\nhttps://www.nytimes.com/2016/11/28/opinion/fake-news-and-the-internet-shell-\\ngame.html?\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n312Figure 1: An illustration of tri-relationship among publish-\\ners, news pieces, and users, during the news dissemination\\nprocess. For example, an edge(p→a)demonstrates that\\npublisherppublishes news itema,anedge(a→u)repre-\\nsents news itemais spread by useru, and an edge(u\\n1↔u\\n2)\\nindicatesthe social relation between useru\\n1andu\\n2.\\ngrouped locally for specific news and the global user-news interac-\\ntions are ignored [\\n4]. However, in practice, these assumptions may\\nnot hold. On social media, different users have different credibility\\nlevels. The credibility score, which means “the quality of being\\ntrustworthy”[1],hasastrongindicationofwhethersomeuseris\\nmore likely to share fake news or not. Those less credible users,\\nsuch as malicious accounts or normal users who are vulnerable to\\nfakenews,aremorelikelytospreadfakenews.Forexample,u\\n2and\\nu\\n4areuserswithlowcredibilityscores,andtheytendtospreadfake\\nnews more than other highly credible users. In addition, users tend\\nto form relationships with like-minded people [25]. For example,\\nuser\\nu\\n5andu\\n6are friends on social media, so they tend to post\\nthose news that confirm their own views, such as\\na\\n4. Therefore,\\nincorporatingtheusercredibilitylevelstocapturetheuser-news\\ninteractionshaspotentials to improve fake news prediction.\\nMoreover,thepublisher-newsrelationshipsanduser-newsinter-\\nactionsbothprovide new anddifferent perspectives ofsocial con-\\ntext, and thus contain complementary information to advance fake\\nnews detection. In this paper, we investigate: (1) how to mathemat-\\nicallymodelthetri-relationshiptoextractfeaturerepresentations\\nof news pieces; and (2) how to take advantage of tri-relationship\\nmodeling for fake news detection. Our solutions to these two chal-\\nlenges results in a novel framework TriFN for fake news detection\\nproblem. Our main contributions are summarized as follows:\\n•\\nWeprovideaprincipledwaytomodeltri-relationshipamong\\npublishers,news pieces, and users simultaneously;\\n•\\nWeproposeanovelframeworkTriFN,whichexploitsboth\\nuser-newsinteractionsandpublisher-newsrelationsforlearn-\\ning news feature representations to predict fake news; and\\n•\\nWeconductextensiveexperimentsontworeal-worlddatasets\\nto assess the effectiveness of TriFN.\\n2 PROBLEM STATEMENT\\nLetA={a\\n1,a\\n2,...,a\\nn}be the set ofnnews pieces, andU=\\n{u\\n1,u\\n2,...,u\\nm}be the set ofmusers on social media posting these\\nnewspieces.WedenoteX∈Rn×t\\nasthebag-of-wordfeaturematrix\\n\\nFigure2:Thetri-relationshipembeddingframework,which\\nconsistsoffivecomponents:newscontentsembedding,user\\nembedding, user-news interaction embedding, publisher-\\nnews relation embedding, and news classification.\\nofnewspieces,wheretisthedimensionofvocabularysize.Weuse\\nA∈{0,1}m×m\\nto denote the user-user adjacency matrix, where\\nA\\nij=1indicatesthatuseru\\niandu\\njarefriends;otherwiseA\\nij=0.\\nWe denote the user-news interaction matrix asW∈{0,1}m×n\\n,\\nwhere\\nW\\nij=1 indicates that useru\\nihas shared the news piece\\na\\nj; otherwiseW\\nij=0. It’s worth mentioning that we focus on\\nthoseuser-newsinteractionsinwhichusersagreewiththenews.\\nFor example, we only consider those users who share news pieces\\nwithout comments, and these users share the same alignment of\\nviewpointswiththenewsitems[12].Wewillintroducemoredetails\\nin Section 3.3. We also denoteP={p\\n1,p\\n2,...,p\\nl}as the set ofl\\nnews publishers. In addition, we denoteB∈Rl×n\\nas the publisher-\\nnews publishing matrix, andB\\nkj=1 means news publisherp\\nk\\npublishesthenewsarticlea\\nj;otherwiseB\\nkj=0.Weassumethat\\nthe partisan biaslabels of some publishers are given and available\\n(seemoredetailsofhowtocollectpartisanbiaslabelsinSec3.4).\\nWedefineo∈{− 1,0,1}l×1\\nasthepartisan label vectors,where-1,\\n0, 1 represents left-, neutral-, and right-partisan bias.\\nSimilartopreviousresearch[10,32],wetreatfakenewsdetec-\\ntionproblemasabinaryclassificationproblem.Inotherwords,each\\nnews piece can be true or fake, and we usey={y\\n1;y\\n2;...;y\\nn}∈\\nR\\nn×1\\nto represent the labels, andy\\nj=1 means news piecea\\njis\\nfake news;\\ny\\nj=−1 means true news. With the notations given\\nabove, the problem is formally defined as,\\nGiven news article feature matrixX, user adjacency matrixA, user\\nsocial engagement matrixW, publisher-news publishing matrixB,\\npublisher partisan label vectoro, and partial labeled news vectory\\nL,\\nwe aim to predict remaining unlabeled news label vectory\\nU.\\n3 A TRI-RELATIONSHIP EMBEDDING\\nFRAMEWORK\\nInthissection,wepresentthedetailsoftheproposedframework\\nTriFN for modeling tri-relationship for fake news detection. It con-\\nsistsoffivemajor components (Figure2):anewscontentsembed-\\ndingcomponent,auserembeddingcomponent,auser-newsinterac-\\ntion embedding component, a publisher-news relation embedding\\ncomponent, and a semi-supervised classification component.\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n313Ingeneral,thenewscontentsembeddingcomponentdescribes\\nthemappingofnewsfrombag-of-wordfeaturestolatentfeature\\nspace; the user embedding component illustrates the extraction\\nof user latent features from user social relations; the user-news\\ninteractionembeddingcomponentlearnthefeaturerepresentations\\nof newspieces guidedby theirpartial labelsand usercredibilities;\\nThe publisher-news relation embedding component regularize the\\nfeature representations of news pieces through publisher partisan\\nbias labels; The semi-supervised classification component learns a\\nclassificationfunctionto predict unlabeled news items.\\n3.1 News Contents Embedding\\nWecanusenewscontentstofindcluestodifferentiatefakenews\\nandtruenews.Recently,ithasbeenshownthatnonnegativematrix\\nfactorization(NMF)algorithmsareverypracticalandpopularto\\nlearndocumentrepresentations[20,28,38].Itcanprojectthenews-\\nword matrixXto a joint latent semantic factor space with low\\ndimensionality, such that the news-word relations are modeled\\nas the inner product in the space. Specifically, giving the news-\\nword matrixX∈Rn×t\\n, NMF methods try to find two nonnegative\\nmatricesD∈Rn×d+\\nandV∈Rt×d+\\n, wheredis the dimension of the\\nlatent space, by solving the following optimization problem,\\nmin\\nD,V≥0/bardblX−DVT\\n/bardbl2F\\n+λ(/bardblD/bardbl2F\\n+/bardblV/bardbl2F\\n)(1)\\nwhereDandVare the nonnegative matrices indicating low dimen-\\nsionrepresentationsofnewspiecesandwords.Notethatwedenote\\nD=[D\\nL;D\\nU], whereD\\nL∈Rr×d\\nis the news latent feature matrix\\nforlabelednews;whileD\\nU∈R(n−r)×d\\nisthenewslatentfeature\\nmatrixforunlabelednews.Thetermλ(/bardblD/bardbl2F\\n+/bardblV/bardbl2F\\n)isintroduced\\nto avoid over-fitting.\\n3.2 UserEmbedding\\nOnsocialmedia,peopletendtoformrelationshipswithlike-minded\\npeople,ratherthanthoseuserswhohaveopposingpreferencesand\\ninterests. Thus, connected users are more likely to share similar\\nlatentinterestsinnewspieces.Toobtainastandardizedrepresen-\\ntation, we use nonnegative matrixfactorization to learn the users’\\nlatent representations. Specifically, giving user-user adjacency ma-\\ntrixA∈{0,1}m×m\\n, we learn nonnegative matrixU∈Rm×d+\\nby\\nsolvingthe followingoptimizationproblem,\\nmin\\nU,T≥0/bardblY⊙(A−UTUT\\n)/bardbl2F\\n+λ(/bardblU/bardbl2F\\n+/bardblT/bardbl2F\\n)(2)\\nwhereUis the user latent matrix,T∈Rd×d+\\nis the user-user cor-\\nrelation matrix,\\nY∈Rm×m\\ncontrols the contribution ofA, and\\n⊙denotes the Hadamard product operation. Since only positive\\nlinks are observed inA, following common strategies [19], we first\\nsetY\\nij=1if A\\nij=1, and then perform negative sampling and\\ngenerate the same number of unobserved links and set weights as\\n0. The termλ(/bardblU/bardbl2F\\n+/bardblT/bardbl2F\\n)is to avoid over-fitting.\\n3.3 User-News Interaction Embedding\\nWemodeltheuser-newsinteractionsbyconsideringtherelation-\\nships between user features and the labels of news items. We have\\nshown (see Section 1) that users with low credibilities are more\\nlikelytospreadfakenews,whileuserswithhighcredibilitiesareless likely to spread fake news. To measure user credibility scores,\\nwe adopt the practical approach in [1]. The basic idea in [1]is\\nthat less credible users are more likely to coordinate with each\\nother and form big clusters, while more credible users are likely to\\nfromsmallclusters.Specifically,thecredibilityscoresaremeasured\\nthrough the following major steps: 1) detect and cluster coordinate\\nusersbasedonusersimilarities;2)weighteachclusterbasedonthe\\nclustersize.Notethatforourfakenewsdetectiontask,wedonot\\nassume that credibility scores are directly provided, but inferred\\nfrom widely available data, such as user-generated contents. By\\nusing the method in [\\n1], we can assign each useru\\nia credibility\\nscore\\nc\\ni∈[0,1]. A largerc\\niindicates that useru\\nihas a higher\\ncredibility, while a lowerc\\niindicates a lower credibility score. We\\nusec={c\\n1,c\\n2,...,c\\nm}to denote the credibility score vector for all\\nusers.\\nFirst,high-credibilityusersaremorelikelytosharetruenews\\npieces, so we ensure that the distance between latent features of\\nhigh-credibility users and that of true news is minimized,\\nmin\\nU,D\\nL≥0m/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1W\\nijc\\ni(1−1+yLj\\n\\n2)||Ui−D\\nL\\nj||22\\n(3)\\nand(1−1+y\\nLj\\n\\n2)is to ensure we only include true news pieces (i.e.,\\ny\\nLj=−1), andc\\niis to adjust the contribution of useru\\nito the loss\\nfunction. For example, ifc\\niis large (high-credibility) andW\\nij=1,\\nwe put a bigger weight on forcing the distance of featureU\\niand\\nD\\nLjto be small; ifc\\niis small (low-credibility) andW\\nij=1, than\\nweputasmallerweightonforcingthedistanceoffeatureU\\niand\\nD\\nLjto be small.\\nSecond, low-credibility users are more likely to share fake news\\npieces,andweaimtominimizethedistancebetweenlatentfeatures\\nof low-credibility users and that of fake news,\\nmin\\nU,D\\nL≥0m/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1W\\nij(1−c\\ni)(1+yLj\\n\\n2)||Ui−D\\nL\\nj||22\\n(4)\\nandtheterm(1+y\\nLj\\n\\n2)istoensureweonlyincludefakenewspieces\\n(i.e.,\\ny\\nL\\nj=1),and(1−c\\ni)istoadjustthecontributionofuseru\\nito\\nthelossfunction.Forexample,ifc\\niislarge(high-credibility)and\\nW\\nij=1,weputasmallerweightonforcingthedistanceoffeature\\nU\\niandD\\nLjto be small; ifc\\niis small (low-credibility) andW\\nij=1,\\nthenweputabiggerweightonforcingthedistanceoffeatureU\\ni\\nandD\\nLjto be small.\\nFinally, We combine Eqn 3 and Eqn 4 to consider the above two\\nsituations,and obtain the followingobjective function,\\nmin\\nU,D\\nL≥0m/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1W\\nijc\\ni(1−1+yLj\\n\\n2)||Ui−D\\nL\\nj||22\\n/bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright\\nTrue news\\n+m\\n/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1W\\nij(1−c\\ni)(1+yLj\\n\\n2)||Ui−D\\nL\\nj||22\\n/bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright\\nFake news(5)\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n314For simplicity, Eqn 5 can be rewritten as,\\nmin\\nU,D\\nL≥0m/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1G\\nij||U\\ni−D\\nL\\nj||22\\n(6)\\nwhereG\\nij=W\\nij(c\\ni(1−1+y\\nLj\\n\\n2)+(1−c\\ni)(1+y\\nLj\\n\\n2)). If we denote a\\nnewmatrixH=[U;D\\nL]∈R(m+r)×d\\n,wecanalsorewriteEqn.6as\\na matrix form as follows,\\nmin\\nU,D\\nL≥0m/summationdisplay.1\\ni=1r/summationdisplay.1\\nj=1G\\nij||U\\ni−D\\nL\\nj||22\\n⇔min\\nH≥0m/summationdisplay.1\\ni=1r+m/summationdisplay.1\\nj=1+mG\\nij||H\\ni−H\\nj||22\\n⇔min\\nH≥0m+r/summationdisplay.1\\ni,j=1F\\nij||H\\ni−H\\nj||22\\n⇔min\\nH≥0tr(HT\\nLH)\\n(7)\\nwhereL=S−Fis the Laplacian matrix andSis a diagonal ma-\\ntrix with diagonal element\\nS\\nii=/summationtext.1m+rj=1\\nF\\nij.F∈R(m+r)×(m+r)\\nis\\ncomputed as follows,\\nF\\nij=⎧⎪⎪⎪⎨\\n⎪⎪⎪⎩0,i,j∈[1,m]ori,j∈[m+1,m+r]\\nG\\ni(j−m),i∈[1,m],j∈[m+1,m+r]\\nG\\n(i−m)j,i∈[m+1,m+r],j∈[1,m](8)\\n3.4 Publisher-News Relation Embedding\\nFakenewsisoftenwrittentoconveyopinionsorclaimsthatsup-\\nportthepartisanbiasofnewspublishers.Thus,agoodnewsrep-\\nresentation should be good at predicting the partisan bias of its\\npublisher.Weobtainthelistofpublishers’partisanscoresfroma\\nwell-known media bias fact-checking websites MBFC3\\n. The parti-\\nsan bias labels are checked with a principled methodology that en-\\nsuresthereliabilityandobjectivityofthepartisanannotations.The\\nlabelsarecategorizedintofivecategories:“left”,“left-Center”,“least-\\nbiased”,“right-Center”and“right”.Tofurtherensuretheaccuracyof\\nthelabels,weonlyconsiderthosenewspublisherswiththeannota-\\ntions [“left”,“least-biased”, “Right”], and rewrite the corresponding\\nlabels as [-1,0,1]. Thus, we can construct a partisan label vectors\\nfor news publishers aso. Note that we may not obtain the partisan\\nlabelsforallpublishers,soweintroducee∈{0,1}l×1\\ntocontrolthe\\nweight ofo. If we have the partisan bias label of publisherp\\nk, then\\ne\\nk=1; otherwise,e\\nk=0. The basic idea is to utilize publisher par-\\ntisanlabelsvectoro∈Rl×1\\nandpublisher-newsmatrixB∈Rl×n\\ntooptimizethenewsfeaturerepresentationlearning.Specifically,\\nwe optimization following objective function,\\nmin\\nD≥0,q/bardble⊙(¯BDq−o)/bardbl22\\n+λ/bardblq/bardbl22\\n(9)\\nwhere we assume that the latent feature of news publisher can\\nbe represented by the features of all the news it published, i.e.,\\n¯BD\\n.¯B\\nis the normalized user-news publishing relation matrix, i.e.,\\n¯B\\nkj=B\\nkj\\n\\n/summationtext.1\\nnj=1\\nB\\nkj.q∈Rd×1\\nistheweightingmatrixthatmapsnews\\npublishers’ latent features to corresponding partisan label vectoro.\\n3\\nhttps://mediabiasfactcheck.com/3.5 Proposed Framework - TriFN\\nWehaveintroducedhowwecanlearnnewslatentfeaturesbymod-\\neling different aspects of the tri-relationship. We further employ a\\nsemi-supervised linear classifier term as follows,\\nmin\\np/bardblD\\nLp−y\\nL/bardbl22\\n+λ/bardblp/bardbl22\\n(10)\\nwherep∈Rd×1\\nis the weighting matrix that maps news latent\\nfeatures to fake news labels. With all previous components, TriFN\\nsolves the following optimization problem,\\nmin\\nD,U,V,T≥0,p,q/bardblX−DVT\\n/bardbl2F\\n+α/bardblY⊙(A−UTUT\\n)/bardbl2F\\n+βtr(HT\\nLH)+γ/bardble⊙(¯BDq−o)/bardbl22\\n+η/bardblD\\nLp−y\\nL/bardbl22\\n+λR(11)\\nwhereR=(/bardblD/bardbl2F\\n+/bardblV/bardbl2F\\n+/bardblU/bardbl2F\\n+/bardblT/bardbl2F\\n+/bardblp/bardbl22\\n+/bardblq/bardbl22\\n)is to\\navoidover-fitting.Thefirsttermmodelsthenewslatentfeatures\\nfrom news contents; the second term extracts user latent features\\nfrom their social relationships; and the third term incorporates the\\nuser-newsinteractions;andthefourthtermmodelspublisher-news\\nrelationships. The fifth term adds a semi-supervised fake news\\nclassifier. Therefore,this frameworkprovides aprincipledway to\\nmodel tri-relationship for fake news prediction.\\n4 AN OPTIMIZATION ALGORITHM\\nInthissection,wepresentthedetailoptimizationprocessforthe\\nproposed framework TriFN. If we update the variables jointly, the\\nobjective function in Eq. 11 is not convex. Thus, we propose to\\nuse alternating least squares to update the variables separately. For\\nsimplicity, we userLto denote the objective function in Eq. 11.\\nNext, we introduce the updating rules for each variable in details.\\nUpdateD.\\nLetΨ\\nDbe the Lagrange multiplier for constraint\\nD≥0, the Lagrange function related toDis,\\nmin\\nD/bardblX−DVT\\n/bardbl2F\\n+βtr(HT\\nLH)+γ/bardble⊙(¯BDq−o)/bardbl22\\n+η/bardblD\\nLp−y\\nL/bardbl22\\n+λ/bardblD/bardbl2F\\n−tr(Ψ\\nDDT\\n)(12)\\nandD=[D\\nL;D\\nU]andH=[U;D\\nL].WerewriteL=[L\\n11,L\\n12;L\\n21,L\\n22],\\nwhere\\nL\\n11∈Rm×m\\n,L\\n12∈Rm×r\\n,L\\n21∈Rr×m\\n,andL\\n22∈Rr×r\\n;and\\nX=[X\\nL,X\\nU]. The partial derivative ofLw.r.t.Das follows,\\n1\\n2∂L\\n\\n∂D=(DVT\\n−X)V+λD+γ¯BT\\nET\\n(E¯BDq−Eo)qT\\n+/bracketleftbigβL\\n21U+βL\\n22D\\nL+η(D\\nLp−y\\nL)pT\\n;0/bracketrightbig−Ψ\\nD(13)\\nwhereE∈Rl×l\\nis a diagonal matrix with{e\\nk}lk=1\\non the diago-\\nnal and zeros everywhere else. By setting the derivative to zero\\nandusingKarush-KuhnTuckercomplementarycondition[3],i.e.,\\nΨ\\nD(i,j)D\\nij=0,we get,\\nD\\nij←D\\nij/radicalBigg\\n\\nˆD(i,j)\\n\\n˜D(i,j)(14)\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n315ˆD=XV+γ/parenleftbig¯BT\\nET\\nEoqT/parenrightbig\\n+\\n+γ/parenleftbig¯BT\\nET\\nE¯BDqqT/parenrightbig\\n−\\n+/bracketleftbigη/parenleftbigD\\nLppT/parenrightbig\\n−\\n+η/parenleftbigy\\nLpT/parenrightbig\\n+\\n+β(L\\n21U)−\\n+β(L\\n22D\\nL)−\\n;0/bracketrightbig\\n˜D=DV\\nT\\nV+λD+γ/parenleftbigBT\\nET\\nE¯BDqqT\\n)+\\n+γ/parenleftbig¯BT\\nET\\nEoqT/parenrightbig\\n−\\n+/bracketleftbigβ(L\\n21U)+\\n+β(L\\n22D\\nL)+\\n+η/parenleftbigD\\nLppT/parenrightbig\\n+\\n+η/parenleftbigy\\nLpT/parenrightbig\\n−\\n;0/bracketrightbig(15)\\nwhere for any matrixX,(X)+\\nand(X)−\\ndenote the positive and\\nnegative parts of\\nX, respectively. Specifically, we have(X)+\\n=\\nABS(X)+X\\n\\n2and(X)−\\n=ABS(X)−X\\n\\n2,ABS(X)is the matrix with the\\nabsolutevalueof elements inX.\\nUpdateU,VandT.\\nThepartialderivativeoftheLagrangeob-\\njective function w.r.t.Uand updating rule are as follows,\\n1\\n2∂L\\n\\n∂U=α(Y⊙(UTUT\\n−A))UTT\\n+α(Y⊙(UTUT\\n−A))T\\nUT\\n+λU−Ψ\\nU+β(L\\n11U+L\\n12D\\nL)\\n(16)\\nU\\nij←U\\nij/radicaltp/radicalbt\\n/bracketleftbigˆU/bracketrightbig(i,j)\\n\\n/bracketleftbig˜U/bracketrightbig(i,j)(17)\\nˆU=α(Y⊙A)UT\\nT\\n+α(Y⊙A)T\\nUT+β(L\\n11U)−\\n+β(L\\n12D\\nL)−\\n˜U=α(Y⊙UTUT\\n)UTT\\n+α(Y⊙UTUT\\n)T\\nUT+λU\\n+β(L\\n11U)+\\n+β(L\\n12D\\nL)+\\n(18)\\nThe partial derivatives of the Lagrange objective w.r.tVand updat-\\ning rule are,\\n1\\n2∂L\\n\\n∂V=(DVT\\n−X)T\\nD+λV−Ψ\\nV(19)\\nV\\nij←V\\nij/radicaltp/radicalbt\\n/bracketleftbigX\\nT\\nD/bracketrightbig(i,j)\\n\\n/bracketleftbigVD\\nT\\nD+λV/bracketrightbig(i,j)(20)\\nThe partial derivative of the Lagrange objective w.r.tTand the\\nupdating rule are,\\n1\\n2∂L\\n\\n∂T=αUT\\n(Y⊙(UTUT\\n−A))U+λT−Ψ\\nT(21)\\nT\\nij←T\\nij/radicaltp/radicalbt\\n/bracketleftbigαU\\nT\\n(Y⊙A)U/bracketrightbig(i,j)\\n\\n/bracketleftbigαU\\nT\\n(Y⊙UTUT\\n)U+λT/bracketrightbig(i,j)(22)\\nUpdatepandq.\\nOptimization w.r.tpandqare essentially least\\nsquareproblems.Bysetting∂L\\n\\n∂p=0and∂L\\n\\n∂q=0,theclosedfrom\\nsolutionsofpandqare as follows,\\np=(ηD\\nTL\\nD\\nL+λI)−1\\nηDTL\\ny\\nL\\nq=(γDT\\n¯BT\\nE¯BD+λI)−1\\nγDT\\n¯BT\\nEo(23)\\nWhereIis an identity matrix, andE∈Rl×l\\nwithe\\nk,k=1,...,l\\non the diagonal and zeros everywhere else.\\n4.1 OptimizationAlgorithmof TriFN\\nWepresentthedetailstooptimizeTriFNinAlgorithm1.Wefirstran-\\ndomlyinitialize\\nU,V,T,D,p,qinline1,andconstructtheLaplacian\\nmatrixLinline2.Thenwerepeatedlyupdaterelatedparameters\\nthrough Line 4 to Line 8 until convergence. Finally, we predict the\\nlabelsofunlabelednewsy\\nUinline10.TheconvergenceofAlgo-\\nrithm1isguaranteedbecausetheobjectivefunctionisnonnegative\\nAlgorithm1Theoptimizationprocess of TriFN framework\\n\\nRequire:X,A,B,W,Y,o,y\\nL,α,β,γ,λ,η\\nEnsure:y\\nU\\n1:RandomlyinitializeU,V,T,D,p,q\\n2:Precompute Laplacian matrixL\\n3:repeat\\n4:UpdateDwithEqn 14\\n5:UpdateUwithEqn 18\\n6:UpdateVwithEqn 20\\n7:UpdateTwithEqn 22\\n8:Updatep,qwithEqn 23\\n9:untilconvergence\\n10:Calculatey\\nU=Sign(D\\nUp)\\n\\nandineachiterationitwillmonotonicallydecreasetheobjective\\nvalue, and finally it will converge to an optimal point [15].\\n4.2 Complexity Analysis\\nThemaincomputationcostcomesfromthefine-tuningvariablesfor\\nAlgorithm1.In each iteration,the time complexityfor computing\\nDisO(nd+nld2\\n+rd+rm+n2\\n).Similarly,thecomputationcostfor\\nVis approximatelyO(tnd), forUisO(m4\\nd3\\n+md), forTis about\\nO(m4\\nd3\\n+m2\\nd2\\n). To updatepandq, the costs are approximately\\nO(d3\\n+d2\\n+dr)andO(d2\\nln+d3\\n+dl).Theoveralltimecomplexity\\nis the sum of the costs of initialization and fine-tuning.\\n5 EXPERIMENTS\\nIn this section, we present the experiments to evaluate the effec-\\ntiveness of the proposed TriFN framework. Specifically, we aim to\\nanswer the following research questions:\\n•\\nIs TriFN able to improve fake news classification perfor-\\nmancebymodelingpublisherpartisananduserengagements\\nsimultaneously?\\n•\\nHow effective are publisher partisan bias modeling and user\\nengagement learning, respectively, in improving the fake\\nnews detection performance of TriFN?\\n•\\nCan the proposed method handle early fake news detection\\nwhenlimited user engagements are provided?\\n5.1 Datasets\\nTable 1: The statistics of FakeNewsNet dataset\\n\\nPlatformBuzzFeed PolitiFact\\n# Users15,257 23,865\\n# Engagements25,240 37,259\\n# Social Links634,750 574,744\\n# Candidate news182 240\\n# True news91 120\\n# Fake news91 120\\n# Publisher991\\nWe utilize one of the comprehensive fake news detection bench-\\nmark dataset called FakeNewsNet [31,32]. The dataset is collected\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n316from two platforms with fact-checking:BuzzFeedandPolitiFact,\\nboth containing news content with labels and social context in-\\nformation. News content includes the meta attributes of the news\\n(e.g., body text), and social context includes the related user so-\\ncial engagements of news items (e.g., user posting/sharing news in\\nTwitter).ThedetailedstatisticsofthedatasetsareshowninTable1.\\n5.2 ExperimentalSettings\\nToevaluatetheperformanceoffakenewsdetectionalgorithms,we\\nusethefollowingmetrics,whicharecommonlyusedtoevaluate\\nclassifiers in related areas: Accuracy, Precision, Recall, and F1. We\\nrandomlychoose80%ofnewspiecesfortrainingandremaining20%\\nfortesting,andtheprocessisperformedfor10timesandtheaverage\\nperformance is reported. We compare the proposed framework\\nTriFN with several state-of-the-art fake news detection methods.\\nExisting methods mainly focus on extractingdiscriminative features\\nandfeedthemintoaclassificationalgorithmtodifferentiatefake\\nnews.Next,weintroduceseveralrepresentativefeaturesasfollows,\\n•RST[26]:RSTstandsforRhetoricalStructureTheory,which\\nbuildsatreestructuretorepresentrhetoricalrelationsamong\\nthewordsinthetext.RSTcanextractstyle-basedfeatures\\nofnewsbymappingthefrequenciesofrhetoricalrelations\\nto a vector space4\\n.\\n•LIWC\\n[23]: LIWC stands for Linguistic Inquiry and Word\\nCount,whichiswidelyusedtoextractthelexiconsfalling\\ninto psycholinguistic categories. It’s based on a large sets of\\nwordsthatrepresentpsycholinguisticprocesses,summary\\ncategories, and part-of-speech categories. It learns a feature\\nvector from a psychology and deception perspective5\\n.\\n•Castillo\\n[4]: Castillo extract various kinds of features from\\nthose users who have shared a news item on social media.\\nThe features are extracted from user profiles and friendship\\nnetwork. We also include the credibility score of users in-\\nferred in Sec 3.3 as an additional social context feature.\\n•RST+Castillo\\n: RST+Castillo represents the concatenated\\nfeaturesofRSTandCastillo,whichincludefeaturesextracted\\nfrom both news content and social context.\\n•LIWC+Castillo\\n:LIWC+Castillorepresentstheconcatenated\\nfeaturesofLIWCandCastillo,whichconsistsoffeaturein-\\nformationfrom both news content and social context.\\nNotethatforafairandcomprehensivecomparison,wechoose\\nthe above feature extraction methods from following aspects: 1)\\nonly extract features from\\nnews contents, such as RST, LIWC;\\n2) only construct features from\\nsocial context, such as Castillo;\\nand 3) consider both\\nnews content and social context, such as\\nRST+Castillo, LIWC+Castillo\\n5.3 PerformanceComparison\\nWe evaluate the effectiveness of the proposed framework TriFN\\nfor fake news classification. We determine model parameters with\\ncross-validation strategy, and we repeat the generating process\\nof training/test set for three times and the average performance\\nis reported. We first perform cross validation on parameters\\nλ∈\\n\\n4\\nThe code is available at: https://github.com/jiyfeng/DPLP\\n5\\nThe readers can find more details about the software and feature description at:\\nhttp://liwc.wpengine.com/ {0.001,0.01,0.1,1,10},andchoosethose parametersthatachieves\\nbest performance, i.e.,λ=0.1. We also choose latent dimension\\nd=10foreasyparametertuning,andfocusontheparametersthat\\ncontribute the tri-relationshipmodeling components. The parame-\\nters for TriFN are set as{α=1e−4,β=1e−5,γ=1,η=1}for\\nBuzzFeed and{α=1e−5,β=1e−4,γ=10,η=1}for PolitiFact.\\nWe test the baseline features on different learning algorithms,\\nand choose the one that achieves the best performance (see Ta-\\nble 2). The algorithms include Logistic Regression (LogReg for\\nshort),NaïveBayes(NBayes),DecisionTree(DTree),RandomForest\\n(RForest), XGBoost, AdaBoost, and Gradient Boosting (GradBoost).\\nWeusedtheopen-sourcedxgboost[5]packageandscikit-learn[22]\\nmachine learning framework in Python to implement all these\\nalgorithms. To ensure a fair comparison of features, we ran all\\nthe algorithms using default parameter settings. We also show the\\nperformancesforeachlearningalgorithmandreporttheaverage\\nperformanceon bothdatasets.Due tothespacelimitation,weonly\\nshowthe results ofF1score (Table3and Table4).Weobservesimi-\\nlarresultsforothermetricsintermsofaverageperformance.Based\\non Table 2, Table 3, and Table 4, we have following observations:\\n•\\nFornewscontentbasedmethodsRSTandLIWC,wecansee\\nthatLIWC>RSTfor both best performance and average\\nperformance, indicating that LIWC can better capture the\\nlinguistic features in news contents. The good results of\\nLIWCdemonstratethatfakenewspiecesareverydifferent\\nfromrealnewsintermsofchoosingthewordsthatreveal\\npsychometricscharacteristics.\\n•\\nIn addition, social context based features are more effective\\nthan news content based features, i.e.,Castillo>RSTand\\nCastillo>LIWC. It shows that social context features have\\nmorediscriminativepowerthanthoseonlyonnewscontent\\nfor predicting fake news.\\n•\\nMoreover, methods using both news contents and social\\ncontext perform better than those methods purely based\\nonnewscontents,andthosemethodsonlybasedonsocial\\nengagements,i.e.,LIWC+Castillo>LIWCorCastilloand\\nRST+Castillo>RSTorCastillo. This indicates that fea-\\ntures extracted from news content and corresponding social\\ncontext have complementary information, and thus boost\\nthe detectionperformance.\\n•\\nGenerally, for methods based on both news content and\\nsocialcontext(i.e.,RST+Castillo,LIWC+Castillo,andTriFN),\\nwecanseethatTriFNconsistentlyoutperformstheothertwo\\nbaselines,i.e.,\\nTriFN>LIWC+CastilloandTriFN>RST+\\nCastillo\\n, in terms of all evaluation metrics on both datasets.\\nForexample,TriFNachievesaveragerelativeimprovement\\nof 4.72%,5.84% on BuzzFeed and 5.91%,4.39% on PolitiFact,\\ncomparingwithLIWC+CastillointermsofAccuracyandF1\\nscore.Itsupportstheimportancetomodeltri-relationshipof\\npublisher-news and news-user to better predict fake news.\\n5.4 Assessing Impacts of Users and Publishers\\nInprevioussection,weobservethatTriFNframeworkimprovesthe\\nclassification results significantly. In addition to news contents, we\\nalso captures user-news interactions and publisher-news relations.\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n317Table 2: Best performance comparison for fake news detection\\n\\nDatasetsMetricRSTLIWCCastilloRST+CastilloLIWC+CastilloTriFN\\n\\nBuzzFeed\\nAccuracy0.600±0.0630.719±0.0740.800±0.0370.816±0.0520.825±0.052\\n0.864±0.026\\n\\nPrecision0.662±0.1090.722±0.0770.822±0.0770.879±0.0490.821±0.061\\n0.849±0.040\\n\\nRecall0.615±0.0180.732±0.1710.776±0.0270.748±0.0980.829±0.055\\n0.893±0.013\\n\\nF10.633±0.0560.709±0.0750.797±0.0440.805±0.0660.822±0.035\\n0.870±0.019\\nPolitiFact\\nAccuracy0.604±0.0600.688±0.0630.796±0.0520.838±0.0360.829±0.052\\n0.878±0.017\\n\\nPrecision0.564±0.0640.725±0.0870.767±0.0560.851±0.0520.821±0.116\\n0.867±0.034\\n\\nRecall0.705±0.1480.617±0.1000.889±0.0440.824±0.0630.879±0.047\\n0.893±0.023\\n\\nF10.615±0.0740.666±0.0920.822±0.0370.835±0.0430.843±0.054\\n0.880±0.015\\nTable 3: Average F1 of baselines for different learning algo-\\nrithmson BuzzFeed. Best scores are highlighted.\\nMethod RST LIWC CastilloRST\\n+CastilloLIWC\\n+Castillo\\n\\nLogReg 0.519 0.660 0.714 0.728 0.760\\nNBayes 0.511 0.370 0.600 0.716 0.680\\nDTree 0.566 0.581 0.736 0.681 0.772\\nRForest 0.5380.709 0.7670.805 0.733\\nXGBoost 0.480 0.6720.797 0.795 0.782\\nAdaBoost0.633 0.701 0.724 0.791 0.768\\nGradBoost 0.492 0.699 0.772 0.7240.822\\n\\nTable 4: Average F1 of baselines for different learning algo-\\nrithmson PolitiFact. Best scores are highlighted.\\nMethod RST LIWC CastilloRST\\n+CastilloLIWC\\n+Castillo\\n\\nLogReg0.615 0.432 0.707 0.668 0.653\\nNBayes 0.537 0.486 0.442 0.746 0.687\\nDTree 0.514 0.661 0.771 0.792 0.772\\nRForest 0.463 0.586 0.7670.835 0.836\\nXGBoost 0.552 0.6480.822 0.783 0.823\\nAdaBoost 0.5020.666 0.800 0.787 0.831\\nGradBoost 0.517 0.650 0.818 0.8030.843\\nNow, we investigate the effects of these components by defining\\nthree variants of TriFN:\\n•\\nTriFN\\\\P - We eliminate the effect of publisher partisan mod-\\neling partγ/bardble⊙(¯BDq−o)/bardbl22\\nby settingγ=0.\\n•\\nTriFN\\\\S-Weeliminatetheeffectsofusersocialengagements\\ncomponentsα/bardblY⊙(A−UTUT\\n)/bardbl2F\\n+βtr(HT\\nLH)by setting\\nα,β=0.\\n•\\nTriFN\\\\PS-Weeliminatetheeffectsofbothpublisherpartisan\\nand user social engagements, by settingα,β,γ=0. The\\nmodel only consider news content embedding.\\nThe parameters in all the variants are determined with cross-\\nvalidation and the best performances are shown in Figure 3, we\\nhave following observations:\\n•\\nWhen we eliminate the effect of user social engagements\\ncomponent,theperformanceofTriFN\\\\Sdegradesincompar-\\nisonwithTriFN.Forexample,theperformancereduces5\\n.2%\\nand 6.1% in terms of F1 and Accuracy metrics on BuzzFeed,\\n7.6% and 10.6% on PolitiFact. The results suggest that social\\nengagementsin TriFN is important.\\n(a) BuzzFeed\\n(b) PolitiFact\\nFigure 3: Impact analysis of users and publishers for fake\\nnews detection.\\n•\\nWe have similar observations for TriFN\\\\P when eliminat-\\ningtheeffectofpublisherpartisancomponent.Theresults\\nsuggesttheimportancetoconsiderpublisher-newsrelations\\nthrough publisherpartisanbiasin TriFN.\\n•\\nWhenweeliminatebothcomponentsinTriFN\\\\PS,theresults\\narefurtherreducedcomparedtoTriFN\\\\SandTriFN\\\\P.Italso\\nsuggests that components of user-news and publisher-news\\nembedding are complementary to each other.\\nThrough the component analysis of TriFN, we conclude that (i)\\nboth components can contribute to the performance improvement\\nof TriFN; (ii) it’s necessary to model both news contents and social\\nengagementsbecause they contain complementary information.\\n5.5 EarlyFake News Detection\\nEarly detection of fake news is very desirable to restrict the dis-\\nsemination scope of fake news and prevent the future propagation\\non social media. Early fake news detection aims to give early alert\\noffakenews,byonlyconsideringlimitedsocialcontextwithina\\nspecificrangeoftimedelayoforiginalnewsposted.Specifically,we\\nchangethedelaytimein[12,24,36,48,60,72,84,96]hours.From\\nFigure4,wecanseethat:1)generally,thedetectionperformance\\nis getting better when the delay time increase for those methods\\nusing social context information, which indicates that more social\\nengagementsofusersonsocialmediaprovidemoreadditionalinfor-\\nmationforfakenewsdetection;2)TheproposedTriFNconsistently\\nachievesbestperformancesonbothdatasetsforaccuracyandF1,\\nwhich demonstrate the importance of embedding user-news inter-\\nactions to capture effective feature representations; and 3) Even in\\nthe very early stage after fake news has been published, TriFN can\\nalreadyachievegoodperformance.Forexample,TriFNcanachieve\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n318F1 score more than 80% within 48 hours on both datasets, which\\nshowspromisingpotentialstocombatfakenewattheearlystage.\\n\\nhours\\n12 24 36 48 60 72 84 96 AllAccuracy\\n\\n0.50.60.70.80.91\\nRST\\nLIWC\\nCastillo\\nRST+Castillo\\nLIWC+Castillo\\nTriFN\\n\\n(a) Accuracy on BuzzFeed\\nhours\\n12 24 36 48 60 72 84 96 AllF1\\n\\n0.50.60.70.80.91\\nRST\\nLIWC\\nCastillo\\nRST+Castillo\\nLIWC+Castillo\\nTriFN\\n\\n(b) F1 on BuzzFeed\\n\\nhours\\n12 24 36 48 60 72 84 96 AllAccuracy\\n\\n0.50.60.70.80.91\\nRST\\nLIWC\\nCastillo\\nRST+Castillo\\nLIWC+Castillo\\nTriFN\\n\\n(c) Accuracy on PolitiFact\\nhours\\n12 24 36 48 60 72 84 96 AllF1\\n\\n0.50.60.70.80.91\\nRST\\nLIWC\\nCastillo\\nRST+Castillo\\nLIWC+Castillo\\nTriFN\\n\\n(d) F1 on PolitiFact\\nFigure 4: The performance of early fake news detection on\\nBuzzFeed and PolitiFact in terms of Accuracy and F1.\\n5.6 Model Parameter Analysis\\nThe proposed TriFN has four important parameters. The first two\\nareαandβ,whichcontrolthecontributionsfromsocialrelationship\\nand user-news engagements.γcontrols the contribution of pub-\\nlisherpartisanandηcontrolsthecontributionofsemi-supervised\\nclassifier. We first fix{α=1e−4,β=1e−5}and{α=1e−5,β=\\n1e−4}forBuzzFeedandPolitiFact,respectively.Thenwevaryηas\\n{1,10,20,50,100}andγin{1,10,20,30,100}.Theperformancevari-\\nationsaredepictedinFigure5.Wecanseei)when\\nηincreasesfrom\\n0, eliminating the impact of semi-supervised classification term, to\\n1,theperformanceincreasedramaticallyinbothdatasets.Thesere-\\nsults support the importance to combine semi-supervised classifier\\nto feature learning; ii) generally, the increase ofγwill increase the\\nperformance in a certain region,γ∈[1,50]andη∈[1,50]for both\\ndatasets, which easy the process for parameter setting. Next, we\\nfix{γ=1,η=1}and{γ=10,η=1}forBuzzFeedandPolitiFact,\\nrespectively.Thenwevaryα,β∈[0,1e−5,1e−4,1e−3,0.001,0.01].\\nWecan seethati)whenαandβincreasefrom0, whicheliminate\\nthesocialengagements,to1e−5,theperformanceincreasesrela-\\ntively, which again support the importance of social engagements;\\nii)Theperformancetendstoincreasefirstandthendecrease,and\\nit’s relatively stable in[1e−5,1e−3].\\n6 RELATED WORK\\nWe briefly introduce the related work about fake news detection\\nonsocial media. Fakenewsdetection methodsgenerallyfocuson\\nusingnews contentsandsocial contexts[32, 40].\\nNews contents contain the clues to differentiate fake and real\\nnews.Fornewscontentbasedapproaches,featuresareextractedas\\nlinguistic-basedandvisual-based.Linguistic-basedfeaturescapture\\n100\\n30\\n20\\n10\\nγ\\n1\\n00110\\nη\\n20501001\\n0.8\\n0.6F1\\n(a)ηandγon BuzzFeed\\n100\\n30\\n20\\n10\\nγ\\n1\\n00110\\nη\\n20501000.81\\n0.6F1\\n(b)ηandγon PolitiFact\\n\\n0.01\\n0.001\\n0.0001\\n\\nα\\n1e-05\\n001e-05\\n\\nβ0.00010.0010.010.8\\n0.61F1\\n(c)αandβon BuzzFeed\\n0.01\\n0.001\\n0.0001\\n\\nα\\n1e-05\\n001e-05\\n\\nβ\\n0.00010.0010.010.80.91F1\\n(d)αandβon PolitiFact\\nFigure 5: Model parameter analysis for TriFN on BuzzFeed\\nand PolitiFactin terms of F1.\\nspecificwritingstylesandsensationalheadlinesthatcommonlyoc-\\ncurinfakenewscontent[\\n24],suchaslexicalandsyntacticfeatures.\\nVisual-based features try to identify fake images [9] that are in-\\ntentionally created or capturing specific characteristics for images\\nin fake news. News content based models include i) knowledge-\\nbased: using external sources to fact-checking claims in news con-\\ntent [17,37], and 2) style-based: capturing the manipulators in\\nwritingstyle,suchasdeception[7,27]andnon-objectivity[24].For\\nexample,Potthastet al.[24]extractedvariousstylefeaturesfrom\\nnews contents and predict fake news and media bias.\\nInadditiontonewscontent,socialcontextrelatedtonewspieces\\ncontains rich information to help detect fake news. For social con-\\ntext based approaches, the features mainly include user-based,\\npost-basedandnetwork-based.User-basedfeaturesareextracted\\nfrom user profiles to measure their characteristics and credibili-\\nties[4,14,34,39].Forexample,Shuet al.[34]proposedtounder-\\nstand user profiles from various aspects to differentiate fake news.\\nYanget al.[39] proposed an unsupervised fake news detection\\nalgorithm by utilizing users’ opinions on social media and estimat-\\ning their credibilities. Post-based features represent users’ social\\nresponse in term of stance [\\n10], topics [16], or credibility [4,36].\\nNetwork-based features [29] are extracted by constructing specific\\nnetworks,suchasdiffusionnetwork[14]etc.Socialcontextmodels\\nbasicallyincludestance-basedandpropagation-based.Stance-based\\nmodelsutilizeusers’opinionstowardsthenewstoinfernewsve-\\nracity[\\n10].Propagation-basedmodelsassumethatthecredibility\\nofnewsishighlyrelatedtothecredibilitiesofrelevantsocialme-\\ndia posts, which several propagation methods can be applied [10].\\nRecently,deeplearningmodelsareappliedtolearnthetemporal\\nand linguistic representation of news [11,30,35]. Shuet al.[33]\\nproposedtogeneratesyntheticdataforaugmentingtrainingdatato\\nhelpimprovethedetectionofclickbaits.It’sworthmentioningthat\\nwe can not directly compare the propagation-based approaches,\\nbecause we assume we only have user actions, e.g., posting the\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n319newsornot.Inthiscase,thepropagationsignalsinferredfromtext\\nare the same and thus become ineffective.\\nIn this paper, we are to our best knowledge the first to clas-\\nsify fake news by learning the effective news features through the\\ntri-relationshipembeddingamongpublishers,newscontents,and\\nsocial engagements.\\n7 CONCLUSION AND FUTURE WORK\\nDue to the inherent relationship among publisher, news and social\\nengagementsduringnewsdisseminationprocessonsocialmedia,\\nwe propose a novel framework TriFN to model tri-relationship\\nforfakenewsdetection.TriFNcanextracteffectivefeaturesfrom\\nnews publisher and user engagements separately, as well as cap-\\nture the interrelationship simultaneously. Experimental results on\\nreal world fake news datasets demonstrate the effectiveness of the\\nproposed framework and importance of tri-relationship for fake\\nnews prediction. It’s worth mentioning TriFN can achieve good\\ndetectionperformance in the early stage of news dissemination.\\nThereareseveralinterestingfuturedirections.First,it’sworthto\\nexploreeffectivefeaturesandmodelsforearlyfakenewsdetection,\\nasfakenewsusuallyevolvesveryfastonsocialmedia;Second,how\\ntoextractfeaturestomodelfakenewsintentionfrompsychology’s\\nperspectiveneedsfurtherinvestigation.Atlast,howtoidentifylow\\nqualityorevenmalicioususersspreadingfakenewsisimportant\\nfor fake news intervention and mitigation.\\n8 ACKOWLEDGMENTS\\nThismaterialisbaseduponworksupportedby,orinpartby,the\\nNSF #1614576and the ONR grantN00014-16-1-2257.\\nREFERENCES\\n[1]MohammadAliAbbasiandHuanLiu.2013. MeasuringUserCredibilityinSocial\\nMedia.. InSBP. Springer, 441–448.\\n[2]\\nHunt Allcott and Matthew Gentzkow. 2017.Social media and fake news in the\\n2016 election. Technical Report. National Bureau of Economic Research.\\n[3]\\nStephen Boyd and Lieven Vandenberghe. 2004.Convex optimization. Cambridge\\nuniversity press.\\n[4]\\nCarlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credi-\\nbility on twitter. InProceedings of the 20th international conference on World wide\\nweb. ACM, 675–684.\\n[5]\\nTianqiChenandCarlosGuestrin.2016. Xgboost:Ascalabletreeboostingsystem.\\nInProceedings of the 22nd acm sigkdd international conference on knowledge\\ndiscovery and data mining. ACM, 785–794.\\n[6]\\nRobertMEntman.2007. Framingbias:Mediainthedistributionofpower.Journal\\nof communication57, 1 (2007), 163–173.\\n[7]\\nSongFeng,RitwikBanerjee,andYejinChoi.2012. Syntacticstylometryforde-\\nceptiondetection.InProceedings of the 50th Annual Meeting of the Association for\\nComputational Linguistics: Short Papers-Volume 2. Association for Computational\\nLinguistics, 171–175.\\n[8]\\nMatthew Gentzkow, Jesse M Shapiro, and Daniel F Stone. 2014.Media bias in the\\nmarketplace: Theory. Technical Report. National Bureau of Economic Research.\\n[9]Aditi Gupta, Hemank Lamba, Ponnurangam Kumaraguru, and Anupam Joshi.\\n2013. Fakingsandy:characterizingandidentifyingfakeimagesontwitterduring\\nhurricane sandy. InProceedings of the 22nd international conference on World\\nWide Web. ACM, 729–736.\\n[10]\\nZhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News Verification\\nbyExploitingConflictingSocialViewpointsinMicroblogs..InAAAI.2972–2978.\\n[11]Hamid Karimi, Proteek Roy, Sari Saba-Sadiya, and Jiliang Tang. Multi-Source\\nMulti-Class Fake News Detection. InCOLING’18.\\n[12]\\nAntino Kim and Alan R Dennis. 2017. Says Who?: How News Presentation\\nFormatInfluencesPerceivedBelievabilityandtheEngagementLevelofSocial\\nMedia Users. (2017).\\n[13]\\nDavid O Klein and Joshua R Wueller. 2017. Fake News: A Legal Perspective.\\n(2017).[14]Sejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei Chen, and Yajun Wang. 2013.\\nProminent features of rumor propagation in online social media. InData Mining\\n(ICDM), 2013 IEEE 13th International Conference on. IEEE, 1103–1108.\\n[15]\\nDaniel D Lee and H Sebastian Seung. 2001. Algorithms for non-negative matrix\\nfactorization. InAdvances in neural information processing systems. 556–562.\\n[16]\\nJing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and Kam-Fai Wong. 2015. Detect\\nrumorsusingtimeseriesofsocialcontextinformationonmicrobloggingwebsites.\\nInProceedings of the 24th ACM International on Conference on Information and\\nKnowledge Management. ACM, 1751–1754.\\n[17]\\nAmr Magdy and Nayer Wanas. 2010. Web-based statistical fact checking of\\ntextual documents. InProceedings of the 2nd international workshop on Search\\nand mining user-generated contents. ACM, 103–110.\\n[18]\\nBrendanNyhan andJasonReifler.2010. Whencorrectionsfail: Thepersistence\\nof political misperceptions.Political Behavior32, 2 (2010), 303–330.\\n[19]\\nRongPanandMartinScholz. Mindthegaps:weightingtheunknowninlarge-\\nscale one-class collaborative filtering. InKDD’09.\\n[20]\\nVPaulPauca,FarialShahnaz,MichaelWBerry,andRobertJPlemmons.2004.\\nText mining using non-negative matrix factorizations. InProceedings of the 2004\\nSIAM International Conference on Data Mining. SIAM, 452–456.\\n[21]\\nChristopherPaulandMiriamMatthews.2016. TheRussian“FirehoseofFalse-\\nhood” Propaganda Model.RAND Corporation(2016).\\n[22]\\nFabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel,\\nBertrandThirion,OlivierGrisel,MathieuBlondel,PeterPrettenhofer,RonWeiss,\\nVincent Dubourg, et al.2011. Scikit-learn: Machine learning in Python.Journal\\nof machine learning research12, Oct (2011), 2825–2830.\\n[23]\\nJames WPennebaker, RyanL Boyd,Kayla Jordan,and KateBlackburn. 2015.The\\ndevelopment and psychometric properties of LIWC2015. Technical Report.\\n[24]\\nMartin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno\\nStein. 2017. A Stylometric Inquiry into Hyperpartisan and Fake News.arXiv\\npreprint arXiv:1702.05638(2017).\\n[25]\\nWalterQuattrociocchi,AntonioScala,andCassRSunstein.2016. Echochambers\\non facebook. (2016).\\n[26]\\nVictoria L Rubin, N Conroy, and Yimin Chen. 2015. Towards news verifica-\\ntion:Deceptiondetectionmethodsfornewsdiscourse.InHawaii International\\nConference on System Sciences.\\n[27]\\nVictoria L Rubin and Tatiana Lukoianova. 2015. Truth and deception at the\\nrhetoricalstructure level.Journal of the Association for Information Science and\\nTechnology66, 5 (2015), 905–917.\\n[28]\\nFarialShahnaz,MichaelWBerry,VPaulPauca,andRobertJPlemmons.2006.\\nDocumentclusteringusingnonnegativematrixfactorization.Information Pro-\\ncessing & Management42, 2 (2006), 373–386.\\n[29]\\nKaiShu,H.RussellBernard,andHuanLiu.2018.StudyingFakeNewsviaNetwork\\nAnalysis: Detection and Mitigation.CoRRabs/1804.10233 (2018).\\n[30]\\nKai Shu, Deepak Mahudeswaran, and Huan Liu. 2018. FakeNewsTracker: a\\ntool for fake news collection, detection, and visualization.Computational and\\nMathematical Organization Theory(2018), 1–12.\\n[31]\\nKaiShu,DeepakMahudeswaran,SuhangWang,DongwonLee,andHuanLiu.\\n2018. FakeNewsNet: A Data Repository with News Content, Social Context and\\nDynamicInformationforStudyingFakeNewsonSocialMedia.arXiv preprint\\narXiv:1809.01286(2018).\\n[32]\\nKai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake\\nNewsDetectiononSocialMedia:ADataMiningPerspective.KDD exploration\\nnewsletter(2017).\\n[33]\\nKaiShu,SuhangWang,ThaiLe,DongwonLee,andHuanLiu. DeepHeadline\\nGeneration for Clickbait Detection.. InICDM’18.\\n[34]\\nKai Shu, Suhang Wang, and Huan Liu. 2018. Understanding User Profiles on\\nSocialMediaforFakeNewsDetection.In2018 IEEE Conference on Multimedia\\nInformation Processing and Retrieval (MIPR). IEEE.\\n[35]\\nYaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu\\nSu,andJingGao. EANN:EventAdversarialNeuralNetworksforMulti-Modal\\nFake News Detection. InKDD’18.\\n[36]\\nLiang Wu and Huan Liu. Tracing fake-news footprints: Characterizing social\\nmedia messages by how they propagate. InWSDM’18.\\n[37]\\nYou Wu, Pankaj K Agarwal, Chengkai Li, Jun Yang, and Cong Yu. 2014. Toward\\ncomputational fact-checking.Proceedings of the VLDB Endowment7, 7 (2014),\\n589–600.\\n[38]\\nWei Xu, Xin Liu, and Yihong Gong. 2003. Document clustering based on non-\\nnegative matrix factorization. InProceedings of the 26th annual international\\nACM SIGIR conference on Research and development in informaion retrieval. ACM,\\n267–273.\\n[39]\\nShuo Yang, Kai Shu, Suhang Wang, Renjie Gu, Fan Wu, and Huan Liu. Un-\\nsupervised Fake News Detection on Social Media: A Generative Approach. In\\nAAAI’19.\\n[40]\\nXinyi Zhou, Reza Zafarani, Kai Shu, and Huan Liu. Fake News: Fundamental\\nTheories, Detection Strategies and Challenges. InWSDM’19.\\nSession 6: Networks and Social Behavior\\nWSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia\\n320'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the text from the pdf_source\n",
    "all_text=\"\"\n",
    "\n",
    "for page in range(0,fileReader.numPages):\n",
    "        all_text=all_text+pageObj[page].extractText()\n",
    "        \n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f10766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ac269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 INTRODUCTION', '2 PROBLEM STATEMENT', '3 A TRI-RELATIONSHIP EMBEDDING', '4 AN OPTIMIZATION ALGORITHM', '5 EXPERIMENTS', '6 RELATED WORK', '7 CONCLUSION AND FUTURE WORK', '8 ACKOWLEDGMENTS']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = all_text\n",
    "pattern = re.compile('([0-9][\\t ]([A-Z]+[-]*[\\t ]*)+[ ]?[:]?)+\\n')\n",
    "headings = []\n",
    "\n",
    "for match in pattern.finditer(text):\n",
    "    s=match.start()\n",
    "    e = match.end()\n",
    "    headings.append(text[s:e].replace('\\n',''))  \n",
    "\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd52234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Beyond News Contents:', 'The Role of Social Context for Fake News Detection', 'Kai Shu', 'Arizona State University', 'kai.shu@asu.eduSuhang Wang', 'Penn State University', 'szw494@psu.eduHuan Liu', 'Arizona State University', 'huan.liu@asu.edu', 'ABSTRACT', 'Social media is becoming popular for news consumption due to', 'itsfastdissemination,easyaccess,andlowcost.However,italso', 'enablesthewidepropagationoffake news,i.e.,newswithintention-', 'ally false information. Detecting fake news is an important task,', 'which not only ensures users receive authentic information but', 'alsohelpsmaintainatrustworthynewsecosystem.Themajority', 'ofexistingdetectionalgorithmsfocusonfindingcluesfromnews', 'contents, which are generally not effective because fake news is of-', 'ten intentionally written to mislead users by mimicking true news.', 'Therefore, we need to explore auxiliary information to improve', 'detection.Thesocialcontextduringnewsdisseminationprocess', 'on social media formsthe inherenttri-relationship, the relationship', 'amongpublishers,newspieces,andusers,whichhaspotentialto', 'improvefakenewsdetection.Forexample,partisan-biasedpublish-', 'ers are more likely to publish fake news, and low-credible users', 'are more likely to share fake news. In this paper, we study the', 'novel problem of exploiting social context for fake news detection.', 'We propose a tri-relationship embedding framework TriFN, which', 'models publisher-news relations and user-news interactions simul-', 'taneously for fake news classification. We conduct experiments', 'on two real-worlddatasets, which demonstratethat the proposed', 'approachsignificantlyoutperformsotherbaselinemethodsforfake', 'news detection.', 'KEYWORDS', 'Fake news detection; joint learning; social media mining', 'ACM Reference Format:', 'KaiShu,SuhangWang,andHuanLiu.2019.BeyondNewsContents:The', 'Role of Social Context for Fake News Detection. InThe Twelfth ACM Inter-', 'national Conference on Web Search and Data Mining (WSDM ’19), February', '11–15, 2019, Melbourne, VIC, Australia.ACM, New York, NY, USA, 9 pages.', 'https://doi.org/10.1145/3289600.3290994', '1 INTRODUCTION', 'Peoplenowadaystendtoseekoutand consumenewsfromsocial', 'mediaratherthantraditionalnewsorganizations.Forexample,62%', 'of U.S. adults get news on social media in 2016, while in 2012, only', 'Permissionto make digital or hard copies of all or part of this work for personal or', 'classroom use is granted without fee provided that copies are not made or distributed', 'forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation', 'on the first page. Copyrights for components of this work owned by others than ACM', 'mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,', 'topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora', 'fee. Request permissions from permissions@acm.org.', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '© 2019 Association for Computing Machinery.', 'ACM ISBN 978-1-4503-5940-5/19/02...$15.00', 'https://doi.org/10.1145/3289600.329099449percentisreportedseeingnewsonsocialmedia1', '.However,social', 'media is a double-edged sword for news consumption. The quality', 'of news on social media is much lower than that of traditional', 'news organizations. Large volumes offake news, i.e., news with', 'intentionallyfalseinformation,areproducedonlineforavariety', 'of purposes, such as financial and political gain [2, 13].', 'Fakenewscanhavedetrimentaleffectsonindividualsandthe', 'society. First, people may be misled by fake news and accept false', 'beliefs [18,21]. Second, fake news could change the way people', 'respondtotruenews2', '.Third,thewidepropagationoffakenews', 'could break the trustworthiness of entire news ecosystem. Thus, it', 'isimportanttodetectfakenewsonsocialmedia.Fakenewsisinten-', 'tionallywrittentomisleadconsumers,whichmakesitnontrivial', 'todetectsimplybasedonnewscontent.Tobuildaneffectiveand', 'practical fake news detection system, it is natural and necessary to', 'exploreauxiliary informationfrom different perspectives.', 'Thenewsecosystemonsocialmediaprovidesabundantsocial', 'contextinformation,whichinvolvesthreebasicentities,i.e.,pub-', 'lishers, news pieces, and social media users. Figure 1 gives an il-', 'lustration of such ecosystem. In Figure 1,', 'p', '1,p', '2andp', '3are news', 'publishers who publish news', 'a', '1,...,a', '4andu', '1,...,u', '6are users', 'who have engaged in sharing these news pieces. In addition, users', 'tendtoformsociallinkswithlike-mindedpeoplewithsimilarinter-', 'ests.Aswewillshow,thetri-relationship,therelationshipamong', 'publishers, news pieces, and users, contains additional information', 'to help detect fake news.', 'First,sociological studies on journalism have theorized the cor-', 'relation between the partisan bias of publisher and the veracity', 'degree of news content [8]. The partisan bias means the perceived', 'biasofthepublisherintheselectionofhownewsisreportedand', 'covered[6].Forexample,inFigure1,p', '1isapublisherwithextreme', 'left partisan bias andp', '2is a publisher with extreme right partisan', 'bias. To support their own partisan viewpoints, they have high', 'degreetodistortthefactsandreportfakenewspieces,suchasa', '1', 'anda', '3; while for a mainstream publisherp', '3that has least partisan', 'bias,he/shehasalowerchancetomanipulateoriginalnewsevents,', 'and is more likely to write a true news piecea', '4. Thus, exploit-', 'ing the partisan bias of publishers to bridge the publisher-news', 'relationships can bring additional benefits to predict fake news.', 'Second,mininguserengagementstowardsnewspiecesonsocial', 'media also help fake news detection. Previous approaches try to', 'aggregate users’ attributesto infer the degree of news veracity by', 'assumingthateither(i)alltheuserscontributeequallyforlearning', 'feature representations of news pieces [', '10]; or (ii) user features are', '1', 'http://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-', '2016/', '2', 'https://www.nytimes.com/2016/11/28/opinion/fake-news-and-the-internet-shell-', 'game.html?', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '312Figure 1: An illustration of tri-relationship among publish-', 'ers, news pieces, and users, during the news dissemination', 'process. For example, an edge(p→a)demonstrates that', 'publisherppublishes news itema,anedge(a→u)repre-', 'sents news itemais spread by useru, and an edge(u', '1↔u', '2)', 'indicatesthe social relation between useru', '1andu', '2.', 'grouped locally for specific news and the global user-news interac-', 'tions are ignored [', '4]. However, in practice, these assumptions may', 'not hold. On social media, different users have different credibility', 'levels. The credibility score, which means “the quality of being', 'trustworthy”[1],hasastrongindicationofwhethersomeuseris', 'more likely to share fake news or not. Those less credible users,', 'such as malicious accounts or normal users who are vulnerable to', 'fakenews,aremorelikelytospreadfakenews.Forexample,u', '2and', 'u', '4areuserswithlowcredibilityscores,andtheytendtospreadfake', 'news more than other highly credible users. In addition, users tend', 'to form relationships with like-minded people [25]. For example,', 'user', 'u', '5andu', '6are friends on social media, so they tend to post', 'those news that confirm their own views, such as', 'a', '4. Therefore,', 'incorporatingtheusercredibilitylevelstocapturetheuser-news', 'interactionshaspotentials to improve fake news prediction.', 'Moreover,thepublisher-newsrelationshipsanduser-newsinter-', 'actionsbothprovide new anddifferent perspectives ofsocial con-', 'text, and thus contain complementary information to advance fake', 'news detection. In this paper, we investigate: (1) how to mathemat-', 'icallymodelthetri-relationshiptoextractfeaturerepresentations', 'of news pieces; and (2) how to take advantage of tri-relationship', 'modeling for fake news detection. Our solutions to these two chal-', 'lenges results in a novel framework TriFN for fake news detection', 'problem. Our main contributions are summarized as follows:', '•', 'Weprovideaprincipledwaytomodeltri-relationshipamong', 'publishers,news pieces, and users simultaneously;', '•', 'WeproposeanovelframeworkTriFN,whichexploitsboth', 'user-newsinteractionsandpublisher-newsrelationsforlearn-', 'ing news feature representations to predict fake news; and', '•', 'Weconductextensiveexperimentsontworeal-worlddatasets', 'to assess the effectiveness of TriFN.', '2 PROBLEM STATEMENT', 'LetA={a', '1,a', '2,...,a', 'n}be the set ofnnews pieces, andU=', '{u', '1,u', '2,...,u', 'm}be the set ofmusers on social media posting these', 'newspieces.WedenoteX∈Rn×t', 'asthebag-of-wordfeaturematrix', '', 'Figure2:Thetri-relationshipembeddingframework,which', 'consistsoffivecomponents:newscontentsembedding,user', 'embedding, user-news interaction embedding, publisher-', 'news relation embedding, and news classification.', 'ofnewspieces,wheretisthedimensionofvocabularysize.Weuse', 'A∈{0,1}m×m', 'to denote the user-user adjacency matrix, where', 'A', 'ij=1indicatesthatuseru', 'iandu', 'jarefriends;otherwiseA', 'ij=0.', 'We denote the user-news interaction matrix asW∈{0,1}m×n', ',', 'where', 'W', 'ij=1 indicates that useru', 'ihas shared the news piece', 'a', 'j; otherwiseW', 'ij=0. It’s worth mentioning that we focus on', 'thoseuser-newsinteractionsinwhichusersagreewiththenews.', 'For example, we only consider those users who share news pieces', 'without comments, and these users share the same alignment of', 'viewpointswiththenewsitems[12].Wewillintroducemoredetails', 'in Section 3.3. We also denoteP={p', '1,p', '2,...,p', 'l}as the set ofl', 'news publishers. In addition, we denoteB∈Rl×n', 'as the publisher-', 'news publishing matrix, andB', 'kj=1 means news publisherp', 'k', 'publishesthenewsarticlea', 'j;otherwiseB', 'kj=0.Weassumethat', 'the partisan biaslabels of some publishers are given and available', '(seemoredetailsofhowtocollectpartisanbiaslabelsinSec3.4).', 'Wedefineo∈{− 1,0,1}l×1', 'asthepartisan label vectors,where-1,', '0, 1 represents left-, neutral-, and right-partisan bias.', 'Similartopreviousresearch[10,32],wetreatfakenewsdetec-', 'tionproblemasabinaryclassificationproblem.Inotherwords,each', 'news piece can be true or fake, and we usey={y', '1;y', '2;...;y', 'n}∈', 'R', 'n×1', 'to represent the labels, andy', 'j=1 means news piecea', 'jis', 'fake news;', 'y', 'j=−1 means true news. With the notations given', 'above, the problem is formally defined as,', 'Given news article feature matrixX, user adjacency matrixA, user', 'social engagement matrixW, publisher-news publishing matrixB,', 'publisher partisan label vectoro, and partial labeled news vectory', 'L,', 'we aim to predict remaining unlabeled news label vectory', 'U.', '3 A TRI-RELATIONSHIP EMBEDDING', 'FRAMEWORK', 'Inthissection,wepresentthedetailsoftheproposedframework', 'TriFN for modeling tri-relationship for fake news detection. It con-', 'sistsoffivemajor components (Figure2):anewscontentsembed-', 'dingcomponent,auserembeddingcomponent,auser-newsinterac-', 'tion embedding component, a publisher-news relation embedding', 'component, and a semi-supervised classification component.', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '313Ingeneral,thenewscontentsembeddingcomponentdescribes', 'themappingofnewsfrombag-of-wordfeaturestolatentfeature', 'space; the user embedding component illustrates the extraction', 'of user latent features from user social relations; the user-news', 'interactionembeddingcomponentlearnthefeaturerepresentations', 'of newspieces guidedby theirpartial labelsand usercredibilities;', 'The publisher-news relation embedding component regularize the', 'feature representations of news pieces through publisher partisan', 'bias labels; The semi-supervised classification component learns a', 'classificationfunctionto predict unlabeled news items.', '3.1 News Contents Embedding', 'Wecanusenewscontentstofindcluestodifferentiatefakenews', 'andtruenews.Recently,ithasbeenshownthatnonnegativematrix', 'factorization(NMF)algorithmsareverypracticalandpopularto', 'learndocumentrepresentations[20,28,38].Itcanprojectthenews-', 'word matrixXto a joint latent semantic factor space with low', 'dimensionality, such that the news-word relations are modeled', 'as the inner product in the space. Specifically, giving the news-', 'word matrixX∈Rn×t', ', NMF methods try to find two nonnegative', 'matricesD∈Rn×d+', 'andV∈Rt×d+', ', wheredis the dimension of the', 'latent space, by solving the following optimization problem,', 'min', 'D,V≥0/bardblX−DVT', '/bardbl2F', '+λ(/bardblD/bardbl2F', '+/bardblV/bardbl2F', ')(1)', 'whereDandVare the nonnegative matrices indicating low dimen-', 'sionrepresentationsofnewspiecesandwords.Notethatwedenote', 'D=[D', 'L;D', 'U], whereD', 'L∈Rr×d', 'is the news latent feature matrix', 'forlabelednews;whileD', 'U∈R(n−r)×d', 'isthenewslatentfeature', 'matrixforunlabelednews.Thetermλ(/bardblD/bardbl2F', '+/bardblV/bardbl2F', ')isintroduced', 'to avoid over-fitting.', '3.2 UserEmbedding', 'Onsocialmedia,peopletendtoformrelationshipswithlike-minded', 'people,ratherthanthoseuserswhohaveopposingpreferencesand', 'interests. Thus, connected users are more likely to share similar', 'latentinterestsinnewspieces.Toobtainastandardizedrepresen-', 'tation, we use nonnegative matrixfactorization to learn the users’', 'latent representations. Specifically, giving user-user adjacency ma-', 'trixA∈{0,1}m×m', ', we learn nonnegative matrixU∈Rm×d+', 'by', 'solvingthe followingoptimizationproblem,', 'min', 'U,T≥0/bardblY⊙(A−UTUT', ')/bardbl2F', '+λ(/bardblU/bardbl2F', '+/bardblT/bardbl2F', ')(2)', 'whereUis the user latent matrix,T∈Rd×d+', 'is the user-user cor-', 'relation matrix,', 'Y∈Rm×m', 'controls the contribution ofA, and', '⊙denotes the Hadamard product operation. Since only positive', 'links are observed inA, following common strategies [19], we first', 'setY', 'ij=1if A', 'ij=1, and then perform negative sampling and', 'generate the same number of unobserved links and set weights as', '0. The termλ(/bardblU/bardbl2F', '+/bardblT/bardbl2F', ')is to avoid over-fitting.', '3.3 User-News Interaction Embedding', 'Wemodeltheuser-newsinteractionsbyconsideringtherelation-', 'ships between user features and the labels of news items. We have', 'shown (see Section 1) that users with low credibilities are more', 'likelytospreadfakenews,whileuserswithhighcredibilitiesareless likely to spread fake news. To measure user credibility scores,', 'we adopt the practical approach in [1]. The basic idea in [1]is', 'that less credible users are more likely to coordinate with each', 'other and form big clusters, while more credible users are likely to', 'fromsmallclusters.Specifically,thecredibilityscoresaremeasured', 'through the following major steps: 1) detect and cluster coordinate', 'usersbasedonusersimilarities;2)weighteachclusterbasedonthe', 'clustersize.Notethatforourfakenewsdetectiontask,wedonot', 'assume that credibility scores are directly provided, but inferred', 'from widely available data, such as user-generated contents. By', 'using the method in [', '1], we can assign each useru', 'ia credibility', 'score', 'c', 'i∈[0,1]. A largerc', 'iindicates that useru', 'ihas a higher', 'credibility, while a lowerc', 'iindicates a lower credibility score. We', 'usec={c', '1,c', '2,...,c', 'm}to denote the credibility score vector for all', 'users.', 'First,high-credibilityusersaremorelikelytosharetruenews', 'pieces, so we ensure that the distance between latent features of', 'high-credibility users and that of true news is minimized,', 'min', 'U,D', 'L≥0m/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1W', 'ijc', 'i(1−1+yLj', '', '2)||Ui−D', 'L', 'j||22', '(3)', 'and(1−1+y', 'Lj', '', '2)is to ensure we only include true news pieces (i.e.,', 'y', 'Lj=−1), andc', 'iis to adjust the contribution of useru', 'ito the loss', 'function. For example, ifc', 'iis large (high-credibility) andW', 'ij=1,', 'we put a bigger weight on forcing the distance of featureU', 'iand', 'D', 'Ljto be small; ifc', 'iis small (low-credibility) andW', 'ij=1, than', 'weputasmallerweightonforcingthedistanceoffeatureU', 'iand', 'D', 'Ljto be small.', 'Second, low-credibility users are more likely to share fake news', 'pieces,andweaimtominimizethedistancebetweenlatentfeatures', 'of low-credibility users and that of fake news,', 'min', 'U,D', 'L≥0m/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1W', 'ij(1−c', 'i)(1+yLj', '', '2)||Ui−D', 'L', 'j||22', '(4)', 'andtheterm(1+y', 'Lj', '', '2)istoensureweonlyincludefakenewspieces', '(i.e.,', 'y', 'L', 'j=1),and(1−c', 'i)istoadjustthecontributionofuseru', 'ito', 'thelossfunction.Forexample,ifc', 'iislarge(high-credibility)and', 'W', 'ij=1,weputasmallerweightonforcingthedistanceoffeature', 'U', 'iandD', 'Ljto be small; ifc', 'iis small (low-credibility) andW', 'ij=1,', 'thenweputabiggerweightonforcingthedistanceoffeatureU', 'i', 'andD', 'Ljto be small.', 'Finally, We combine Eqn 3 and Eqn 4 to consider the above two', 'situations,and obtain the followingobjective function,', 'min', 'U,D', 'L≥0m/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1W', 'ijc', 'i(1−1+yLj', '', '2)||Ui−D', 'L', 'j||22', '/bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright', 'True news', '+m', '/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1W', 'ij(1−c', 'i)(1+yLj', '', '2)||Ui−D', 'L', 'j||22', '/bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright', 'Fake news(5)', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '314For simplicity, Eqn 5 can be rewritten as,', 'min', 'U,D', 'L≥0m/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1G', 'ij||U', 'i−D', 'L', 'j||22', '(6)', 'whereG', 'ij=W', 'ij(c', 'i(1−1+y', 'Lj', '', '2)+(1−c', 'i)(1+y', 'Lj', '', '2)). If we denote a', 'newmatrixH=[U;D', 'L]∈R(m+r)×d', ',wecanalsorewriteEqn.6as', 'a matrix form as follows,', 'min', 'U,D', 'L≥0m/summationdisplay.1', 'i=1r/summationdisplay.1', 'j=1G', 'ij||U', 'i−D', 'L', 'j||22', '⇔min', 'H≥0m/summationdisplay.1', 'i=1r+m/summationdisplay.1', 'j=1+mG', 'ij||H', 'i−H', 'j||22', '⇔min', 'H≥0m+r/summationdisplay.1', 'i,j=1F', 'ij||H', 'i−H', 'j||22', '⇔min', 'H≥0tr(HT', 'LH)', '(7)', 'whereL=S−Fis the Laplacian matrix andSis a diagonal ma-', 'trix with diagonal element', 'S', 'ii=/summationtext.1m+rj=1', 'F', 'ij.F∈R(m+r)×(m+r)', 'is', 'computed as follows,', 'F', 'ij=⎧⎪⎪⎪⎨', '⎪⎪⎪⎩0,i,j∈[1,m]ori,j∈[m+1,m+r]', 'G', 'i(j−m),i∈[1,m],j∈[m+1,m+r]', 'G', '(i−m)j,i∈[m+1,m+r],j∈[1,m](8)', '3.4 Publisher-News Relation Embedding', 'Fakenewsisoftenwrittentoconveyopinionsorclaimsthatsup-', 'portthepartisanbiasofnewspublishers.Thus,agoodnewsrep-', 'resentation should be good at predicting the partisan bias of its', 'publisher.Weobtainthelistofpublishers’partisanscoresfroma', 'well-known media bias fact-checking websites MBFC3', '. The parti-', 'san bias labels are checked with a principled methodology that en-', 'suresthereliabilityandobjectivityofthepartisanannotations.The', 'labelsarecategorizedintofivecategories:“left”,“left-Center”,“least-', 'biased”,“right-Center”and“right”.Tofurtherensuretheaccuracyof', 'thelabels,weonlyconsiderthosenewspublisherswiththeannota-', 'tions [“left”,“least-biased”, “Right”], and rewrite the corresponding', 'labels as [-1,0,1]. Thus, we can construct a partisan label vectors', 'for news publishers aso. Note that we may not obtain the partisan', 'labelsforallpublishers,soweintroducee∈{0,1}l×1', 'tocontrolthe', 'weight ofo. If we have the partisan bias label of publisherp', 'k, then', 'e', 'k=1; otherwise,e', 'k=0. The basic idea is to utilize publisher par-', 'tisanlabelsvectoro∈Rl×1', 'andpublisher-newsmatrixB∈Rl×n', 'tooptimizethenewsfeaturerepresentationlearning.Specifically,', 'we optimization following objective function,', 'min', 'D≥0,q/bardble⊙(¯BDq−o)/bardbl22', '+λ/bardblq/bardbl22', '(9)', 'where we assume that the latent feature of news publisher can', 'be represented by the features of all the news it published, i.e.,', '¯BD', '.¯B', 'is the normalized user-news publishing relation matrix, i.e.,', '¯B', 'kj=B', 'kj', '', '/summationtext.1', 'nj=1', 'B', 'kj.q∈Rd×1', 'istheweightingmatrixthatmapsnews', 'publishers’ latent features to corresponding partisan label vectoro.', '3', 'https://mediabiasfactcheck.com/3.5 Proposed Framework - TriFN', 'Wehaveintroducedhowwecanlearnnewslatentfeaturesbymod-', 'eling different aspects of the tri-relationship. We further employ a', 'semi-supervised linear classifier term as follows,', 'min', 'p/bardblD', 'Lp−y', 'L/bardbl22', '+λ/bardblp/bardbl22', '(10)', 'wherep∈Rd×1', 'is the weighting matrix that maps news latent', 'features to fake news labels. With all previous components, TriFN', 'solves the following optimization problem,', 'min', 'D,U,V,T≥0,p,q/bardblX−DVT', '/bardbl2F', '+α/bardblY⊙(A−UTUT', ')/bardbl2F', '+βtr(HT', 'LH)+γ/bardble⊙(¯BDq−o)/bardbl22', '+η/bardblD', 'Lp−y', 'L/bardbl22', '+λR(11)', 'whereR=(/bardblD/bardbl2F', '+/bardblV/bardbl2F', '+/bardblU/bardbl2F', '+/bardblT/bardbl2F', '+/bardblp/bardbl22', '+/bardblq/bardbl22', ')is to', 'avoidover-fitting.Thefirsttermmodelsthenewslatentfeatures', 'from news contents; the second term extracts user latent features', 'from their social relationships; and the third term incorporates the', 'user-newsinteractions;andthefourthtermmodelspublisher-news', 'relationships. The fifth term adds a semi-supervised fake news', 'classifier. Therefore,this frameworkprovides aprincipledway to', 'model tri-relationship for fake news prediction.', '4 AN OPTIMIZATION ALGORITHM', 'Inthissection,wepresentthedetailoptimizationprocessforthe', 'proposed framework TriFN. If we update the variables jointly, the', 'objective function in Eq. 11 is not convex. Thus, we propose to', 'use alternating least squares to update the variables separately. For', 'simplicity, we userLto denote the objective function in Eq. 11.', 'Next, we introduce the updating rules for each variable in details.', 'UpdateD.', 'LetΨ', 'Dbe the Lagrange multiplier for constraint', 'D≥0, the Lagrange function related toDis,', 'min', 'D/bardblX−DVT', '/bardbl2F', '+βtr(HT', 'LH)+γ/bardble⊙(¯BDq−o)/bardbl22', '+η/bardblD', 'Lp−y', 'L/bardbl22', '+λ/bardblD/bardbl2F', '−tr(Ψ', 'DDT', ')(12)', 'andD=[D', 'L;D', 'U]andH=[U;D', 'L].WerewriteL=[L', '11,L', '12;L', '21,L', '22],', 'where', 'L', '11∈Rm×m', ',L', '12∈Rm×r', ',L', '21∈Rr×m', ',andL', '22∈Rr×r', ';and', 'X=[X', 'L,X', 'U]. The partial derivative ofLw.r.t.Das follows,', '1', '2∂L', '', '∂D=(DVT', '−X)V+λD+γ¯BT', 'ET', '(E¯BDq−Eo)qT', '+/bracketleftbigβL', '21U+βL', '22D', 'L+η(D', 'Lp−y', 'L)pT', ';0/bracketrightbig−Ψ', 'D(13)', 'whereE∈Rl×l', 'is a diagonal matrix with{e', 'k}lk=1', 'on the diago-', 'nal and zeros everywhere else. By setting the derivative to zero', 'andusingKarush-KuhnTuckercomplementarycondition[3],i.e.,', 'Ψ', 'D(i,j)D', 'ij=0,we get,', 'D', 'ij←D', 'ij/radicalBigg', '', 'ˆD(i,j)', '', '˜D(i,j)(14)', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '315ˆD=XV+γ/parenleftbig¯BT', 'ET', 'EoqT/parenrightbig', '+', '+γ/parenleftbig¯BT', 'ET', 'E¯BDqqT/parenrightbig', '−', '+/bracketleftbigη/parenleftbigD', 'LppT/parenrightbig', '−', '+η/parenleftbigy', 'LpT/parenrightbig', '+', '+β(L', '21U)−', '+β(L', '22D', 'L)−', ';0/bracketrightbig', '˜D=DV', 'T', 'V+λD+γ/parenleftbigBT', 'ET', 'E¯BDqqT', ')+', '+γ/parenleftbig¯BT', 'ET', 'EoqT/parenrightbig', '−', '+/bracketleftbigβ(L', '21U)+', '+β(L', '22D', 'L)+', '+η/parenleftbigD', 'LppT/parenrightbig', '+', '+η/parenleftbigy', 'LpT/parenrightbig', '−', ';0/bracketrightbig(15)', 'where for any matrixX,(X)+', 'and(X)−', 'denote the positive and', 'negative parts of', 'X, respectively. Specifically, we have(X)+', '=', 'ABS(X)+X', '', '2and(X)−', '=ABS(X)−X', '', '2,ABS(X)is the matrix with the', 'absolutevalueof elements inX.', 'UpdateU,VandT.', 'ThepartialderivativeoftheLagrangeob-', 'jective function w.r.t.Uand updating rule are as follows,', '1', '2∂L', '', '∂U=α(Y⊙(UTUT', '−A))UTT', '+α(Y⊙(UTUT', '−A))T', 'UT', '+λU−Ψ', 'U+β(L', '11U+L', '12D', 'L)', '(16)', 'U', 'ij←U', 'ij/radicaltp/radicalbt', '/bracketleftbigˆU/bracketrightbig(i,j)', '', '/bracketleftbig˜U/bracketrightbig(i,j)(17)', 'ˆU=α(Y⊙A)UT', 'T', '+α(Y⊙A)T', 'UT+β(L', '11U)−', '+β(L', '12D', 'L)−', '˜U=α(Y⊙UTUT', ')UTT', '+α(Y⊙UTUT', ')T', 'UT+λU', '+β(L', '11U)+', '+β(L', '12D', 'L)+', '(18)', 'The partial derivatives of the Lagrange objective w.r.tVand updat-', 'ing rule are,', '1', '2∂L', '', '∂V=(DVT', '−X)T', 'D+λV−Ψ', 'V(19)', 'V', 'ij←V', 'ij/radicaltp/radicalbt', '/bracketleftbigX', 'T', 'D/bracketrightbig(i,j)', '', '/bracketleftbigVD', 'T', 'D+λV/bracketrightbig(i,j)(20)', 'The partial derivative of the Lagrange objective w.r.tTand the', 'updating rule are,', '1', '2∂L', '', '∂T=αUT', '(Y⊙(UTUT', '−A))U+λT−Ψ', 'T(21)', 'T', 'ij←T', 'ij/radicaltp/radicalbt', '/bracketleftbigαU', 'T', '(Y⊙A)U/bracketrightbig(i,j)', '', '/bracketleftbigαU', 'T', '(Y⊙UTUT', ')U+λT/bracketrightbig(i,j)(22)', 'Updatepandq.', 'Optimization w.r.tpandqare essentially least', 'squareproblems.Bysetting∂L', '', '∂p=0and∂L', '', '∂q=0,theclosedfrom', 'solutionsofpandqare as follows,', 'p=(ηD', 'TL', 'D', 'L+λI)−1', 'ηDTL', 'y', 'L', 'q=(γDT', '¯BT', 'E¯BD+λI)−1', 'γDT', '¯BT', 'Eo(23)', 'WhereIis an identity matrix, andE∈Rl×l', 'withe', 'k,k=1,...,l', 'on the diagonal and zeros everywhere else.', '4.1 OptimizationAlgorithmof TriFN', 'WepresentthedetailstooptimizeTriFNinAlgorithm1.Wefirstran-', 'domlyinitialize', 'U,V,T,D,p,qinline1,andconstructtheLaplacian', 'matrixLinline2.Thenwerepeatedlyupdaterelatedparameters', 'through Line 4 to Line 8 until convergence. Finally, we predict the', 'labelsofunlabelednewsy', 'Uinline10.TheconvergenceofAlgo-', 'rithm1isguaranteedbecausetheobjectivefunctionisnonnegative', 'Algorithm1Theoptimizationprocess of TriFN framework', '', 'Require:X,A,B,W,Y,o,y', 'L,α,β,γ,λ,η', 'Ensure:y', 'U', '1:RandomlyinitializeU,V,T,D,p,q', '2:Precompute Laplacian matrixL', '3:repeat', '4:UpdateDwithEqn 14', '5:UpdateUwithEqn 18', '6:UpdateVwithEqn 20', '7:UpdateTwithEqn 22', '8:Updatep,qwithEqn 23', '9:untilconvergence', '10:Calculatey', 'U=Sign(D', 'Up)', '', 'andineachiterationitwillmonotonicallydecreasetheobjective', 'value, and finally it will converge to an optimal point [15].', '4.2 Complexity Analysis', 'Themaincomputationcostcomesfromthefine-tuningvariablesfor', 'Algorithm1.In each iteration,the time complexityfor computing', 'DisO(nd+nld2', '+rd+rm+n2', ').Similarly,thecomputationcostfor', 'Vis approximatelyO(tnd), forUisO(m4', 'd3', '+md), forTis about', 'O(m4', 'd3', '+m2', 'd2', '). To updatepandq, the costs are approximately', 'O(d3', '+d2', '+dr)andO(d2', 'ln+d3', '+dl).Theoveralltimecomplexity', 'is the sum of the costs of initialization and fine-tuning.', '5 EXPERIMENTS', 'In this section, we present the experiments to evaluate the effec-', 'tiveness of the proposed TriFN framework. Specifically, we aim to', 'answer the following research questions:', '•', 'Is TriFN able to improve fake news classification perfor-', 'mancebymodelingpublisherpartisananduserengagements', 'simultaneously?', '•', 'How effective are publisher partisan bias modeling and user', 'engagement learning, respectively, in improving the fake', 'news detection performance of TriFN?', '•', 'Can the proposed method handle early fake news detection', 'whenlimited user engagements are provided?', '5.1 Datasets', 'Table 1: The statistics of FakeNewsNet dataset', '', 'PlatformBuzzFeed PolitiFact', '# Users15,257 23,865', '# Engagements25,240 37,259', '# Social Links634,750 574,744', '# Candidate news182 240', '# True news91 120', '# Fake news91 120', '# Publisher991', 'We utilize one of the comprehensive fake news detection bench-', 'mark dataset called FakeNewsNet [31,32]. The dataset is collected', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '316from two platforms with fact-checking:BuzzFeedandPolitiFact,', 'both containing news content with labels and social context in-', 'formation. News content includes the meta attributes of the news', '(e.g., body text), and social context includes the related user so-', 'cial engagements of news items (e.g., user posting/sharing news in', 'Twitter).ThedetailedstatisticsofthedatasetsareshowninTable1.', '5.2 ExperimentalSettings', 'Toevaluatetheperformanceoffakenewsdetectionalgorithms,we', 'usethefollowingmetrics,whicharecommonlyusedtoevaluate', 'classifiers in related areas: Accuracy, Precision, Recall, and F1. We', 'randomlychoose80%ofnewspiecesfortrainingandremaining20%', 'fortesting,andtheprocessisperformedfor10timesandtheaverage', 'performance is reported. We compare the proposed framework', 'TriFN with several state-of-the-art fake news detection methods.', 'Existing methods mainly focus on extractingdiscriminative features', 'andfeedthemintoaclassificationalgorithmtodifferentiatefake', 'news.Next,weintroduceseveralrepresentativefeaturesasfollows,', '•RST[26]:RSTstandsforRhetoricalStructureTheory,which', 'buildsatreestructuretorepresentrhetoricalrelationsamong', 'thewordsinthetext.RSTcanextractstyle-basedfeatures', 'ofnewsbymappingthefrequenciesofrhetoricalrelations', 'to a vector space4', '.', '•LIWC', '[23]: LIWC stands for Linguistic Inquiry and Word', 'Count,whichiswidelyusedtoextractthelexiconsfalling', 'into psycholinguistic categories. It’s based on a large sets of', 'wordsthatrepresentpsycholinguisticprocesses,summary', 'categories, and part-of-speech categories. It learns a feature', 'vector from a psychology and deception perspective5', '.', '•Castillo', '[4]: Castillo extract various kinds of features from', 'those users who have shared a news item on social media.', 'The features are extracted from user profiles and friendship', 'network. We also include the credibility score of users in-', 'ferred in Sec 3.3 as an additional social context feature.', '•RST+Castillo', ': RST+Castillo represents the concatenated', 'featuresofRSTandCastillo,whichincludefeaturesextracted', 'from both news content and social context.', '•LIWC+Castillo', ':LIWC+Castillorepresentstheconcatenated', 'featuresofLIWCandCastillo,whichconsistsoffeaturein-', 'formationfrom both news content and social context.', 'Notethatforafairandcomprehensivecomparison,wechoose', 'the above feature extraction methods from following aspects: 1)', 'only extract features from', 'news contents, such as RST, LIWC;', '2) only construct features from', 'social context, such as Castillo;', 'and 3) consider both', 'news content and social context, such as', 'RST+Castillo, LIWC+Castillo', '5.3 PerformanceComparison', 'We evaluate the effectiveness of the proposed framework TriFN', 'for fake news classification. We determine model parameters with', 'cross-validation strategy, and we repeat the generating process', 'of training/test set for three times and the average performance', 'is reported. We first perform cross validation on parameters', 'λ∈', '', '4', 'The code is available at: https://github.com/jiyfeng/DPLP', '5', 'The readers can find more details about the software and feature description at:', 'http://liwc.wpengine.com/ {0.001,0.01,0.1,1,10},andchoosethose parametersthatachieves', 'best performance, i.e.,λ=0.1. We also choose latent dimension', 'd=10foreasyparametertuning,andfocusontheparametersthat', 'contribute the tri-relationshipmodeling components. The parame-', 'ters for TriFN are set as{α=1e−4,β=1e−5,γ=1,η=1}for', 'BuzzFeed and{α=1e−5,β=1e−4,γ=10,η=1}for PolitiFact.', 'We test the baseline features on different learning algorithms,', 'and choose the one that achieves the best performance (see Ta-', 'ble 2). The algorithms include Logistic Regression (LogReg for', 'short),NaïveBayes(NBayes),DecisionTree(DTree),RandomForest', '(RForest), XGBoost, AdaBoost, and Gradient Boosting (GradBoost).', 'Weusedtheopen-sourcedxgboost[5]packageandscikit-learn[22]', 'machine learning framework in Python to implement all these', 'algorithms. To ensure a fair comparison of features, we ran all', 'the algorithms using default parameter settings. We also show the', 'performancesforeachlearningalgorithmandreporttheaverage', 'performanceon bothdatasets.Due tothespacelimitation,weonly', 'showthe results ofF1score (Table3and Table4).Weobservesimi-', 'larresultsforothermetricsintermsofaverageperformance.Based', 'on Table 2, Table 3, and Table 4, we have following observations:', '•', 'FornewscontentbasedmethodsRSTandLIWC,wecansee', 'thatLIWC>RSTfor both best performance and average', 'performance, indicating that LIWC can better capture the', 'linguistic features in news contents. The good results of', 'LIWCdemonstratethatfakenewspiecesareverydifferent', 'fromrealnewsintermsofchoosingthewordsthatreveal', 'psychometricscharacteristics.', '•', 'In addition, social context based features are more effective', 'than news content based features, i.e.,Castillo>RSTand', 'Castillo>LIWC. It shows that social context features have', 'morediscriminativepowerthanthoseonlyonnewscontent', 'for predicting fake news.', '•', 'Moreover, methods using both news contents and social', 'context perform better than those methods purely based', 'onnewscontents,andthosemethodsonlybasedonsocial', 'engagements,i.e.,LIWC+Castillo>LIWCorCastilloand', 'RST+Castillo>RSTorCastillo. This indicates that fea-', 'tures extracted from news content and corresponding social', 'context have complementary information, and thus boost', 'the detectionperformance.', '•', 'Generally, for methods based on both news content and', 'socialcontext(i.e.,RST+Castillo,LIWC+Castillo,andTriFN),', 'wecanseethatTriFNconsistentlyoutperformstheothertwo', 'baselines,i.e.,', 'TriFN>LIWC+CastilloandTriFN>RST+', 'Castillo', ', in terms of all evaluation metrics on both datasets.', 'Forexample,TriFNachievesaveragerelativeimprovement', 'of 4.72%,5.84% on BuzzFeed and 5.91%,4.39% on PolitiFact,', 'comparingwithLIWC+CastillointermsofAccuracyandF1', 'score.Itsupportstheimportancetomodeltri-relationshipof', 'publisher-news and news-user to better predict fake news.', '5.4 Assessing Impacts of Users and Publishers', 'Inprevioussection,weobservethatTriFNframeworkimprovesthe', 'classification results significantly. In addition to news contents, we', 'also captures user-news interactions and publisher-news relations.', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '317Table 2: Best performance comparison for fake news detection', '', 'DatasetsMetricRSTLIWCCastilloRST+CastilloLIWC+CastilloTriFN', '', 'BuzzFeed', 'Accuracy0.600±0.0630.719±0.0740.800±0.0370.816±0.0520.825±0.052', '0.864±0.026', '', 'Precision0.662±0.1090.722±0.0770.822±0.0770.879±0.0490.821±0.061', '0.849±0.040', '', 'Recall0.615±0.0180.732±0.1710.776±0.0270.748±0.0980.829±0.055', '0.893±0.013', '', 'F10.633±0.0560.709±0.0750.797±0.0440.805±0.0660.822±0.035', '0.870±0.019', 'PolitiFact', 'Accuracy0.604±0.0600.688±0.0630.796±0.0520.838±0.0360.829±0.052', '0.878±0.017', '', 'Precision0.564±0.0640.725±0.0870.767±0.0560.851±0.0520.821±0.116', '0.867±0.034', '', 'Recall0.705±0.1480.617±0.1000.889±0.0440.824±0.0630.879±0.047', '0.893±0.023', '', 'F10.615±0.0740.666±0.0920.822±0.0370.835±0.0430.843±0.054', '0.880±0.015', 'Table 3: Average F1 of baselines for different learning algo-', 'rithmson BuzzFeed. Best scores are highlighted.', 'Method RST LIWC CastilloRST', '+CastilloLIWC', '+Castillo', '', 'LogReg 0.519 0.660 0.714 0.728 0.760', 'NBayes 0.511 0.370 0.600 0.716 0.680', 'DTree 0.566 0.581 0.736 0.681 0.772', 'RForest 0.5380.709 0.7670.805 0.733', 'XGBoost 0.480 0.6720.797 0.795 0.782', 'AdaBoost0.633 0.701 0.724 0.791 0.768', 'GradBoost 0.492 0.699 0.772 0.7240.822', '', 'Table 4: Average F1 of baselines for different learning algo-', 'rithmson PolitiFact. Best scores are highlighted.', 'Method RST LIWC CastilloRST', '+CastilloLIWC', '+Castillo', '', 'LogReg0.615 0.432 0.707 0.668 0.653', 'NBayes 0.537 0.486 0.442 0.746 0.687', 'DTree 0.514 0.661 0.771 0.792 0.772', 'RForest 0.463 0.586 0.7670.835 0.836', 'XGBoost 0.552 0.6480.822 0.783 0.823', 'AdaBoost 0.5020.666 0.800 0.787 0.831', 'GradBoost 0.517 0.650 0.818 0.8030.843', 'Now, we investigate the effects of these components by defining', 'three variants of TriFN:', '•', 'TriFN\\\\P - We eliminate the effect of publisher partisan mod-', 'eling partγ/bardble⊙(¯BDq−o)/bardbl22', 'by settingγ=0.', '•', 'TriFN\\\\S-Weeliminatetheeffectsofusersocialengagements', 'componentsα/bardblY⊙(A−UTUT', ')/bardbl2F', '+βtr(HT', 'LH)by setting', 'α,β=0.', '•', 'TriFN\\\\PS-Weeliminatetheeffectsofbothpublisherpartisan', 'and user social engagements, by settingα,β,γ=0. The', 'model only consider news content embedding.', 'The parameters in all the variants are determined with cross-', 'validation and the best performances are shown in Figure 3, we', 'have following observations:', '•', 'When we eliminate the effect of user social engagements', 'component,theperformanceofTriFN\\\\Sdegradesincompar-', 'isonwithTriFN.Forexample,theperformancereduces5', '.2%', 'and 6.1% in terms of F1 and Accuracy metrics on BuzzFeed,', '7.6% and 10.6% on PolitiFact. The results suggest that social', 'engagementsin TriFN is important.', '(a) BuzzFeed', '(b) PolitiFact', 'Figure 3: Impact analysis of users and publishers for fake', 'news detection.', '•', 'We have similar observations for TriFN\\\\P when eliminat-', 'ingtheeffectofpublisherpartisancomponent.Theresults', 'suggesttheimportancetoconsiderpublisher-newsrelations', 'through publisherpartisanbiasin TriFN.', '•', 'WhenweeliminatebothcomponentsinTriFN\\\\PS,theresults', 'arefurtherreducedcomparedtoTriFN\\\\SandTriFN\\\\P.Italso', 'suggests that components of user-news and publisher-news', 'embedding are complementary to each other.', 'Through the component analysis of TriFN, we conclude that (i)', 'both components can contribute to the performance improvement', 'of TriFN; (ii) it’s necessary to model both news contents and social', 'engagementsbecause they contain complementary information.', '5.5 EarlyFake News Detection', 'Early detection of fake news is very desirable to restrict the dis-', 'semination scope of fake news and prevent the future propagation', 'on social media. Early fake news detection aims to give early alert', 'offakenews,byonlyconsideringlimitedsocialcontextwithina', 'specificrangeoftimedelayoforiginalnewsposted.Specifically,we', 'changethedelaytimein[12,24,36,48,60,72,84,96]hours.From', 'Figure4,wecanseethat:1)generally,thedetectionperformance', 'is getting better when the delay time increase for those methods', 'using social context information, which indicates that more social', 'engagementsofusersonsocialmediaprovidemoreadditionalinfor-', 'mationforfakenewsdetection;2)TheproposedTriFNconsistently', 'achievesbestperformancesonbothdatasetsforaccuracyandF1,', 'which demonstrate the importance of embedding user-news inter-', 'actions to capture effective feature representations; and 3) Even in', 'the very early stage after fake news has been published, TriFN can', 'alreadyachievegoodperformance.Forexample,TriFNcanachieve', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '318F1 score more than 80% within 48 hours on both datasets, which', 'showspromisingpotentialstocombatfakenewattheearlystage.', '', 'hours', '12 24 36 48 60 72 84 96 AllAccuracy', '', '0.50.60.70.80.91', 'RST', 'LIWC', 'Castillo', 'RST+Castillo', 'LIWC+Castillo', 'TriFN', '', '(a) Accuracy on BuzzFeed', 'hours', '12 24 36 48 60 72 84 96 AllF1', '', '0.50.60.70.80.91', 'RST', 'LIWC', 'Castillo', 'RST+Castillo', 'LIWC+Castillo', 'TriFN', '', '(b) F1 on BuzzFeed', '', 'hours', '12 24 36 48 60 72 84 96 AllAccuracy', '', '0.50.60.70.80.91', 'RST', 'LIWC', 'Castillo', 'RST+Castillo', 'LIWC+Castillo', 'TriFN', '', '(c) Accuracy on PolitiFact', 'hours', '12 24 36 48 60 72 84 96 AllF1', '', '0.50.60.70.80.91', 'RST', 'LIWC', 'Castillo', 'RST+Castillo', 'LIWC+Castillo', 'TriFN', '', '(d) F1 on PolitiFact', 'Figure 4: The performance of early fake news detection on', 'BuzzFeed and PolitiFact in terms of Accuracy and F1.', '5.6 Model Parameter Analysis', 'The proposed TriFN has four important parameters. The first two', 'areαandβ,whichcontrolthecontributionsfromsocialrelationship', 'and user-news engagements.γcontrols the contribution of pub-', 'lisherpartisanandηcontrolsthecontributionofsemi-supervised', 'classifier. We first fix{α=1e−4,β=1e−5}and{α=1e−5,β=', '1e−4}forBuzzFeedandPolitiFact,respectively.Thenwevaryηas', '{1,10,20,50,100}andγin{1,10,20,30,100}.Theperformancevari-', 'ationsaredepictedinFigure5.Wecanseei)when', 'ηincreasesfrom', '0, eliminating the impact of semi-supervised classification term, to', '1,theperformanceincreasedramaticallyinbothdatasets.Thesere-', 'sults support the importance to combine semi-supervised classifier', 'to feature learning; ii) generally, the increase ofγwill increase the', 'performance in a certain region,γ∈[1,50]andη∈[1,50]for both', 'datasets, which easy the process for parameter setting. Next, we', 'fix{γ=1,η=1}and{γ=10,η=1}forBuzzFeedandPolitiFact,', 'respectively.Thenwevaryα,β∈[0,1e−5,1e−4,1e−3,0.001,0.01].', 'Wecan seethati)whenαandβincreasefrom0, whicheliminate', 'thesocialengagements,to1e−5,theperformanceincreasesrela-', 'tively, which again support the importance of social engagements;', 'ii)Theperformancetendstoincreasefirstandthendecrease,and', 'it’s relatively stable in[1e−5,1e−3].', '6 RELATED WORK', 'We briefly introduce the related work about fake news detection', 'onsocial media. Fakenewsdetection methodsgenerallyfocuson', 'usingnews contentsandsocial contexts[32, 40].', 'News contents contain the clues to differentiate fake and real', 'news.Fornewscontentbasedapproaches,featuresareextractedas', 'linguistic-basedandvisual-based.Linguistic-basedfeaturescapture', '100', '30', '20', '10', 'γ', '1', '00110', 'η', '20501001', '0.8', '0.6F1', '(a)ηandγon BuzzFeed', '100', '30', '20', '10', 'γ', '1', '00110', 'η', '20501000.81', '0.6F1', '(b)ηandγon PolitiFact', '', '0.01', '0.001', '0.0001', '', 'α', '1e-05', '001e-05', '', 'β0.00010.0010.010.8', '0.61F1', '(c)αandβon BuzzFeed', '0.01', '0.001', '0.0001', '', 'α', '1e-05', '001e-05', '', 'β', '0.00010.0010.010.80.91F1', '(d)αandβon PolitiFact', 'Figure 5: Model parameter analysis for TriFN on BuzzFeed', 'and PolitiFactin terms of F1.', 'specificwritingstylesandsensationalheadlinesthatcommonlyoc-', 'curinfakenewscontent[', '24],suchaslexicalandsyntacticfeatures.', 'Visual-based features try to identify fake images [9] that are in-', 'tentionally created or capturing specific characteristics for images', 'in fake news. News content based models include i) knowledge-', 'based: using external sources to fact-checking claims in news con-', 'tent [17,37], and 2) style-based: capturing the manipulators in', 'writingstyle,suchasdeception[7,27]andnon-objectivity[24].For', 'example,Potthastet al.[24]extractedvariousstylefeaturesfrom', 'news contents and predict fake news and media bias.', 'Inadditiontonewscontent,socialcontextrelatedtonewspieces', 'contains rich information to help detect fake news. For social con-', 'text based approaches, the features mainly include user-based,', 'post-basedandnetwork-based.User-basedfeaturesareextracted', 'from user profiles to measure their characteristics and credibili-', 'ties[4,14,34,39].Forexample,Shuet al.[34]proposedtounder-', 'stand user profiles from various aspects to differentiate fake news.', 'Yanget al.[39] proposed an unsupervised fake news detection', 'algorithm by utilizing users’ opinions on social media and estimat-', 'ing their credibilities. Post-based features represent users’ social', 'response in term of stance [', '10], topics [16], or credibility [4,36].', 'Network-based features [29] are extracted by constructing specific', 'networks,suchasdiffusionnetwork[14]etc.Socialcontextmodels', 'basicallyincludestance-basedandpropagation-based.Stance-based', 'modelsutilizeusers’opinionstowardsthenewstoinfernewsve-', 'racity[', '10].Propagation-basedmodelsassumethatthecredibility', 'ofnewsishighlyrelatedtothecredibilitiesofrelevantsocialme-', 'dia posts, which several propagation methods can be applied [10].', 'Recently,deeplearningmodelsareappliedtolearnthetemporal', 'and linguistic representation of news [11,30,35]. Shuet al.[33]', 'proposedtogeneratesyntheticdataforaugmentingtrainingdatato', 'helpimprovethedetectionofclickbaits.It’sworthmentioningthat', 'we can not directly compare the propagation-based approaches,', 'because we assume we only have user actions, e.g., posting the', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '319newsornot.Inthiscase,thepropagationsignalsinferredfromtext', 'are the same and thus become ineffective.', 'In this paper, we are to our best knowledge the first to clas-', 'sify fake news by learning the effective news features through the', 'tri-relationshipembeddingamongpublishers,newscontents,and', 'social engagements.', '7 CONCLUSION AND FUTURE WORK', 'Due to the inherent relationship among publisher, news and social', 'engagementsduringnewsdisseminationprocessonsocialmedia,', 'we propose a novel framework TriFN to model tri-relationship', 'forfakenewsdetection.TriFNcanextracteffectivefeaturesfrom', 'news publisher and user engagements separately, as well as cap-', 'ture the interrelationship simultaneously. Experimental results on', 'real world fake news datasets demonstrate the effectiveness of the', 'proposed framework and importance of tri-relationship for fake', 'news prediction. It’s worth mentioning TriFN can achieve good', 'detectionperformance in the early stage of news dissemination.', 'Thereareseveralinterestingfuturedirections.First,it’sworthto', 'exploreeffectivefeaturesandmodelsforearlyfakenewsdetection,', 'asfakenewsusuallyevolvesveryfastonsocialmedia;Second,how', 'toextractfeaturestomodelfakenewsintentionfrompsychology’s', 'perspectiveneedsfurtherinvestigation.Atlast,howtoidentifylow', 'qualityorevenmalicioususersspreadingfakenewsisimportant', 'for fake news intervention and mitigation.', '8 ACKOWLEDGMENTS', 'Thismaterialisbaseduponworksupportedby,orinpartby,the', 'NSF #1614576and the ONR grantN00014-16-1-2257.', 'REFERENCES', '[1]MohammadAliAbbasiandHuanLiu.2013. MeasuringUserCredibilityinSocial', 'Media.. InSBP. Springer, 441–448.', '[2]', 'Hunt Allcott and Matthew Gentzkow. 2017.Social media and fake news in the', '2016 election. Technical Report. National Bureau of Economic Research.', '[3]', 'Stephen Boyd and Lieven Vandenberghe. 2004.Convex optimization. Cambridge', 'university press.', '[4]', 'Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credi-', 'bility on twitter. InProceedings of the 20th international conference on World wide', 'web. ACM, 675–684.', '[5]', 'TianqiChenandCarlosGuestrin.2016. Xgboost:Ascalabletreeboostingsystem.', 'InProceedings of the 22nd acm sigkdd international conference on knowledge', 'discovery and data mining. ACM, 785–794.', '[6]', 'RobertMEntman.2007. Framingbias:Mediainthedistributionofpower.Journal', 'of communication57, 1 (2007), 163–173.', '[7]', 'SongFeng,RitwikBanerjee,andYejinChoi.2012. Syntacticstylometryforde-', 'ceptiondetection.InProceedings of the 50th Annual Meeting of the Association for', 'Computational Linguistics: Short Papers-Volume 2. Association for Computational', 'Linguistics, 171–175.', '[8]', 'Matthew Gentzkow, Jesse M Shapiro, and Daniel F Stone. 2014.Media bias in the', 'marketplace: Theory. Technical Report. National Bureau of Economic Research.', '[9]Aditi Gupta, Hemank Lamba, Ponnurangam Kumaraguru, and Anupam Joshi.', '2013. Fakingsandy:characterizingandidentifyingfakeimagesontwitterduring', 'hurricane sandy. InProceedings of the 22nd international conference on World', 'Wide Web. ACM, 729–736.', '[10]', 'Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News Verification', 'byExploitingConflictingSocialViewpointsinMicroblogs..InAAAI.2972–2978.', '[11]Hamid Karimi, Proteek Roy, Sari Saba-Sadiya, and Jiliang Tang. Multi-Source', 'Multi-Class Fake News Detection. InCOLING’18.', '[12]', 'Antino Kim and Alan R Dennis. 2017. Says Who?: How News Presentation', 'FormatInfluencesPerceivedBelievabilityandtheEngagementLevelofSocial', 'Media Users. (2017).', '[13]', 'David O Klein and Joshua R Wueller. 2017. Fake News: A Legal Perspective.', '(2017).[14]Sejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei Chen, and Yajun Wang. 2013.', 'Prominent features of rumor propagation in online social media. InData Mining', '(ICDM), 2013 IEEE 13th International Conference on. IEEE, 1103–1108.', '[15]', 'Daniel D Lee and H Sebastian Seung. 2001. Algorithms for non-negative matrix', 'factorization. InAdvances in neural information processing systems. 556–562.', '[16]', 'Jing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and Kam-Fai Wong. 2015. Detect', 'rumorsusingtimeseriesofsocialcontextinformationonmicrobloggingwebsites.', 'InProceedings of the 24th ACM International on Conference on Information and', 'Knowledge Management. ACM, 1751–1754.', '[17]', 'Amr Magdy and Nayer Wanas. 2010. Web-based statistical fact checking of', 'textual documents. InProceedings of the 2nd international workshop on Search', 'and mining user-generated contents. ACM, 103–110.', '[18]', 'BrendanNyhan andJasonReifler.2010. Whencorrectionsfail: Thepersistence', 'of political misperceptions.Political Behavior32, 2 (2010), 303–330.', '[19]', 'RongPanandMartinScholz. Mindthegaps:weightingtheunknowninlarge-', 'scale one-class collaborative filtering. InKDD’09.', '[20]', 'VPaulPauca,FarialShahnaz,MichaelWBerry,andRobertJPlemmons.2004.', 'Text mining using non-negative matrix factorizations. InProceedings of the 2004', 'SIAM International Conference on Data Mining. SIAM, 452–456.', '[21]', 'ChristopherPaulandMiriamMatthews.2016. TheRussian“FirehoseofFalse-', 'hood” Propaganda Model.RAND Corporation(2016).', '[22]', 'Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel,', 'BertrandThirion,OlivierGrisel,MathieuBlondel,PeterPrettenhofer,RonWeiss,', 'Vincent Dubourg, et al.2011. Scikit-learn: Machine learning in Python.Journal', 'of machine learning research12, Oct (2011), 2825–2830.', '[23]', 'James WPennebaker, RyanL Boyd,Kayla Jordan,and KateBlackburn. 2015.The', 'development and psychometric properties of LIWC2015. Technical Report.', '[24]', 'Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno', 'Stein. 2017. A Stylometric Inquiry into Hyperpartisan and Fake News.arXiv', 'preprint arXiv:1702.05638(2017).', '[25]', 'WalterQuattrociocchi,AntonioScala,andCassRSunstein.2016. Echochambers', 'on facebook. (2016).', '[26]', 'Victoria L Rubin, N Conroy, and Yimin Chen. 2015. Towards news verifica-', 'tion:Deceptiondetectionmethodsfornewsdiscourse.InHawaii International', 'Conference on System Sciences.', '[27]', 'Victoria L Rubin and Tatiana Lukoianova. 2015. Truth and deception at the', 'rhetoricalstructure level.Journal of the Association for Information Science and', 'Technology66, 5 (2015), 905–917.', '[28]', 'FarialShahnaz,MichaelWBerry,VPaulPauca,andRobertJPlemmons.2006.', 'Documentclusteringusingnonnegativematrixfactorization.Information Pro-', 'cessing & Management42, 2 (2006), 373–386.', '[29]', 'KaiShu,H.RussellBernard,andHuanLiu.2018.StudyingFakeNewsviaNetwork', 'Analysis: Detection and Mitigation.CoRRabs/1804.10233 (2018).', '[30]', 'Kai Shu, Deepak Mahudeswaran, and Huan Liu. 2018. FakeNewsTracker: a', 'tool for fake news collection, detection, and visualization.Computational and', 'Mathematical Organization Theory(2018), 1–12.', '[31]', 'KaiShu,DeepakMahudeswaran,SuhangWang,DongwonLee,andHuanLiu.', '2018. FakeNewsNet: A Data Repository with News Content, Social Context and', 'DynamicInformationforStudyingFakeNewsonSocialMedia.arXiv preprint', 'arXiv:1809.01286(2018).', '[32]', 'Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake', 'NewsDetectiononSocialMedia:ADataMiningPerspective.KDD exploration', 'newsletter(2017).', '[33]', 'KaiShu,SuhangWang,ThaiLe,DongwonLee,andHuanLiu. DeepHeadline', 'Generation for Clickbait Detection.. InICDM’18.', '[34]', 'Kai Shu, Suhang Wang, and Huan Liu. 2018. Understanding User Profiles on', 'SocialMediaforFakeNewsDetection.In2018 IEEE Conference on Multimedia', 'Information Processing and Retrieval (MIPR). IEEE.', '[35]', 'Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu', 'Su,andJingGao. EANN:EventAdversarialNeuralNetworksforMulti-Modal', 'Fake News Detection. InKDD’18.', '[36]', 'Liang Wu and Huan Liu. Tracing fake-news footprints: Characterizing social', 'media messages by how they propagate. InWSDM’18.', '[37]', 'You Wu, Pankaj K Agarwal, Chengkai Li, Jun Yang, and Cong Yu. 2014. Toward', 'computational fact-checking.Proceedings of the VLDB Endowment7, 7 (2014),', '589–600.', '[38]', 'Wei Xu, Xin Liu, and Yihong Gong. 2003. Document clustering based on non-', 'negative matrix factorization. InProceedings of the 26th annual international', 'ACM SIGIR conference on Research and development in informaion retrieval. ACM,', '267–273.', '[39]', 'Shuo Yang, Kai Shu, Suhang Wang, Renjie Gu, Fan Wu, and Huan Liu. Un-', 'supervised Fake News Detection on Social Media: A Generative Approach. In', 'AAAI’19.', '[40]', 'Xinyi Zhou, Reza Zafarani, Kai Shu, and Huan Liu. Fake News: Fundamental', 'Theories, Detection Strategies and Challenges. InWSDM’19.', 'Session 6: Networks and Social Behavior', 'WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia', '320']\n"
     ]
    }
   ],
   "source": [
    "#split string by single space\n",
    "\n",
    "chunks = all_text.split('\\n')\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a81aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headings: \n",
      "['1 INTRODUCTION', '2 PROBLEM STATEMENT', '3 A TRI-RELATIONSHIP EMBEDDING', '4 AN OPTIMIZATION ALGORITHM', '5 EXPERIMENTS', '6 RELATED WORK', '7 CONCLUSION AND FUTURE WORK', '8 ACKOWLEDGMENTS']\n"
     ]
    }
   ],
   "source": [
    "print(\"Headings: \")\n",
    "print(headings)\n",
    "#print(\"Index at which\"+ headings[0]+ \"is present in the all_text:\",chunks.index(headings[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b695195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index at which '1 INTRODUCTION' is present in the all_text: 41\n",
      "Index at which '2 PROBLEM STATEMENT' is present in the all_text: 177\n",
      "Index at which '3 A TRI-RELATIONSHIP EMBEDDING' is present in the all_text: 252\n",
      "Index at which '4 AN OPTIMIZATION ALGORITHM' is present in the all_text: 621\n",
      "Index at which '5 EXPERIMENTS' is present in the all_text: 909\n",
      "Index at which '6 RELATED WORK' is present in the all_text: 1264\n",
      "Index at which '7 CONCLUSION AND FUTURE WORK' is present in the all_text: 1364\n",
      "Index at which '8 ACKOWLEDGMENTS' is present in the all_text: 1382\n"
     ]
    }
   ],
   "source": [
    "#chunks[42]\n",
    "for i in range(8):\n",
    "    print(\"Index at which '\"+ headings[i]+ \"' is present in the all_text:\",chunks.index(headings[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0d71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the heading '1 INTRODUCTION': \n",
      "\n",
      "Peoplenowadaystendtoseekoutand consumenewsfromsocial mediaratherthantraditionalnewsorganizations.Forexample,62% of U.S. adults get news on social media in 2016, while in 2012, only Permissionto make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation on the first page. Copyrights for components of this work owned by others than ACM mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish, topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora fee. Request permissions from permissions@acm.org. WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5940-5/19/02...$15.00 https://doi.org/10.1145/3289600.329099449percentisreportedseeingnewsonsocialmedia1 .However,social media is a double-edged sword for news consumption. The quality of news on social media is much lower than that of traditional news organizations. Large volumes offake news, i.e., news with intentionallyfalseinformation,areproducedonlineforavariety of purposes, such as financial and political gain [2, 13]. Fakenewscanhavedetrimentaleffectsonindividualsandthe society. First, people may be misled by fake news and accept false beliefs [18,21]. Second, fake news could change the way people respondtotruenews2 .Third,thewidepropagationoffakenews could break the trustworthiness of entire news ecosystem. Thus, it isimportanttodetectfakenewsonsocialmedia.Fakenewsisinten- tionallywrittentomisleadconsumers,whichmakesitnontrivial todetectsimplybasedonnewscontent.Tobuildaneffectiveand practical fake news detection system, it is natural and necessary to exploreauxiliary informationfrom different perspectives. Thenewsecosystemonsocialmediaprovidesabundantsocial contextinformation,whichinvolvesthreebasicentities,i.e.,pub- lishers, news pieces, and social media users. Figure 1 gives an il- lustration of such ecosystem. In Figure 1, p 1,p 2andp 3are news publishers who publish news a 1,...,a 4andu 1,...,u 6are users who have engaged in sharing these news pieces. In addition, users tendtoformsociallinkswithlike-mindedpeoplewithsimilarinter- ests.Aswewillshow,thetri-relationship,therelationshipamong publishers, news pieces, and users, contains additional information to help detect fake news. First,sociological studies on journalism have theorized the cor- relation between the partisan bias of publisher and the veracity degree of news content [8]. The partisan bias means the perceived biasofthepublisherintheselectionofhownewsisreportedand covered[6].Forexample,inFigure1,p 1isapublisherwithextreme left partisan bias andp 2is a publisher with extreme right partisan bias. To support their own partisan viewpoints, they have high degreetodistortthefactsandreportfakenewspieces,suchasa 1 anda 3; while for a mainstream publisherp 3that has least partisan bias,he/shehasalowerchancetomanipulateoriginalnewsevents, and is more likely to write a true news piecea 4. Thus, exploit- ing the partisan bias of publishers to bridge the publisher-news relationships can bring additional benefits to predict fake news. Second,mininguserengagementstowardsnewspiecesonsocial media also help fake news detection. Previous approaches try to aggregate users’ attributesto infer the degree of news veracity by assumingthateither(i)alltheuserscontributeequallyforlearning feature representations of news pieces [ 10]; or (ii) user features are 1 http://www.journalism.org/2016/05/26/news-use-across-social-media-platforms- 2016/ 2 https://www.nytimes.com/2016/11/28/opinion/fake-news-and-the-internet-shell- game.html? Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 312Figure 1: An illustration of tri-relationship among publish- ers, news pieces, and users, during the news dissemination process. For example, an edge(p→a)demonstrates that publisherppublishes news itema,anedge(a→u)repre- sents news itemais spread by useru, and an edge(u 1↔u 2) indicatesthe social relation between useru 1andu 2. grouped locally for specific news and the global user-news interac- tions are ignored [ 4]. However, in practice, these assumptions may not hold. On social media, different users have different credibility levels. The credibility score, which means “the quality of being trustworthy”[1],hasastrongindicationofwhethersomeuseris more likely to share fake news or not. Those less credible users, such as malicious accounts or normal users who are vulnerable to fakenews,aremorelikelytospreadfakenews.Forexample,u 2and u 4areuserswithlowcredibilityscores,andtheytendtospreadfake news more than other highly credible users. In addition, users tend to form relationships with like-minded people [25]. For example, user u 5andu 6are friends on social media, so they tend to post those news that confirm their own views, such as a 4. Therefore, incorporatingtheusercredibilitylevelstocapturetheuser-news interactionshaspotentials to improve fake news prediction. Moreover,thepublisher-newsrelationshipsanduser-newsinter- actionsbothprovide new anddifferent perspectives ofsocial con- text, and thus contain complementary information to advance fake news detection. In this paper, we investigate: (1) how to mathemat- icallymodelthetri-relationshiptoextractfeaturerepresentations of news pieces; and (2) how to take advantage of tri-relationship modeling for fake news detection. Our solutions to these two chal- lenges results in a novel framework TriFN for fake news detection problem. Our main contributions are summarized as follows: • Weprovideaprincipledwaytomodeltri-relationshipamong publishers,news pieces, and users simultaneously; • WeproposeanovelframeworkTriFN,whichexploitsboth user-newsinteractionsandpublisher-newsrelationsforlearn- ing news feature representations to predict fake news; and • Weconductextensiveexperimentsontworeal-worlddatasets to assess the effectiveness of TriFN.\n",
      "\n",
      "Contents of the heading '2 PROBLEM STATEMENT': \n",
      "\n",
      "LetA={a 1,a 2,...,a n}be the set ofnnews pieces, andU= {u 1,u 2,...,u m}be the set ofmusers on social media posting these newspieces.WedenoteX∈Rn×t asthebag-of-wordfeaturematrix  Figure2:Thetri-relationshipembeddingframework,which consistsoffivecomponents:newscontentsembedding,user embedding, user-news interaction embedding, publisher- news relation embedding, and news classification. ofnewspieces,wheretisthedimensionofvocabularysize.Weuse A∈{0,1}m×m to denote the user-user adjacency matrix, where A ij=1indicatesthatuseru iandu jarefriends;otherwiseA ij=0. We denote the user-news interaction matrix asW∈{0,1}m×n , where W ij=1 indicates that useru ihas shared the news piece a j; otherwiseW ij=0. It’s worth mentioning that we focus on thoseuser-newsinteractionsinwhichusersagreewiththenews. For example, we only consider those users who share news pieces without comments, and these users share the same alignment of viewpointswiththenewsitems[12].Wewillintroducemoredetails in Section 3.3. We also denoteP={p 1,p 2,...,p l}as the set ofl news publishers. In addition, we denoteB∈Rl×n as the publisher- news publishing matrix, andB kj=1 means news publisherp k publishesthenewsarticlea j;otherwiseB kj=0.Weassumethat the partisan biaslabels of some publishers are given and available (seemoredetailsofhowtocollectpartisanbiaslabelsinSec3.4). Wedefineo∈{− 1,0,1}l×1 asthepartisan label vectors,where-1, 0, 1 represents left-, neutral-, and right-partisan bias. Similartopreviousresearch[10,32],wetreatfakenewsdetec- tionproblemasabinaryclassificationproblem.Inotherwords,each news piece can be true or fake, and we usey={y 1;y 2;...;y n}∈ R n×1 to represent the labels, andy j=1 means news piecea jis fake news; y j=−1 means true news. With the notations given above, the problem is formally defined as, Given news article feature matrixX, user adjacency matrixA, user social engagement matrixW, publisher-news publishing matrixB, publisher partisan label vectoro, and partial labeled news vectory L, we aim to predict remaining unlabeled news label vectory U.\n",
      "\n",
      "Contents of the heading '3 A TRI-RELATIONSHIP EMBEDDING': \n",
      "\n",
      "FRAMEWORK Inthissection,wepresentthedetailsoftheproposedframework TriFN for modeling tri-relationship for fake news detection. It con- sistsoffivemajor components (Figure2):anewscontentsembed- dingcomponent,auserembeddingcomponent,auser-newsinterac- tion embedding component, a publisher-news relation embedding component, and a semi-supervised classification component. Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 313Ingeneral,thenewscontentsembeddingcomponentdescribes themappingofnewsfrombag-of-wordfeaturestolatentfeature space; the user embedding component illustrates the extraction of user latent features from user social relations; the user-news interactionembeddingcomponentlearnthefeaturerepresentations of newspieces guidedby theirpartial labelsand usercredibilities; The publisher-news relation embedding component regularize the feature representations of news pieces through publisher partisan bias labels; The semi-supervised classification component learns a classificationfunctionto predict unlabeled news items. 3.1 News Contents Embedding Wecanusenewscontentstofindcluestodifferentiatefakenews andtruenews.Recently,ithasbeenshownthatnonnegativematrix factorization(NMF)algorithmsareverypracticalandpopularto learndocumentrepresentations[20,28,38].Itcanprojectthenews- word matrixXto a joint latent semantic factor space with low dimensionality, such that the news-word relations are modeled as the inner product in the space. Specifically, giving the news- word matrixX∈Rn×t , NMF methods try to find two nonnegative matricesD∈Rn×d+ andV∈Rt×d+ , wheredis the dimension of the latent space, by solving the following optimization problem, min D,V≥0/bardblX−DVT /bardbl2F +λ(/bardblD/bardbl2F +/bardblV/bardbl2F )(1) whereDandVare the nonnegative matrices indicating low dimen- sionrepresentationsofnewspiecesandwords.Notethatwedenote D=[D L;D U], whereD L∈Rr×d is the news latent feature matrix forlabelednews;whileD U∈R(n−r)×d isthenewslatentfeature matrixforunlabelednews.Thetermλ(/bardblD/bardbl2F +/bardblV/bardbl2F )isintroduced to avoid over-fitting. 3.2 UserEmbedding Onsocialmedia,peopletendtoformrelationshipswithlike-minded people,ratherthanthoseuserswhohaveopposingpreferencesand interests. Thus, connected users are more likely to share similar latentinterestsinnewspieces.Toobtainastandardizedrepresen- tation, we use nonnegative matrixfactorization to learn the users’ latent representations. Specifically, giving user-user adjacency ma- trixA∈{0,1}m×m , we learn nonnegative matrixU∈Rm×d+ by solvingthe followingoptimizationproblem, min U,T≥0/bardblY⊙(A−UTUT )/bardbl2F +λ(/bardblU/bardbl2F +/bardblT/bardbl2F )(2) whereUis the user latent matrix,T∈Rd×d+ is the user-user cor- relation matrix, Y∈Rm×m controls the contribution ofA, and ⊙denotes the Hadamard product operation. Since only positive links are observed inA, following common strategies [19], we first setY ij=1if A ij=1, and then perform negative sampling and generate the same number of unobserved links and set weights as 0. The termλ(/bardblU/bardbl2F +/bardblT/bardbl2F )is to avoid over-fitting. 3.3 User-News Interaction Embedding Wemodeltheuser-newsinteractionsbyconsideringtherelation- ships between user features and the labels of news items. We have shown (see Section 1) that users with low credibilities are more likelytospreadfakenews,whileuserswithhighcredibilitiesareless likely to spread fake news. To measure user credibility scores, we adopt the practical approach in [1]. The basic idea in [1]is that less credible users are more likely to coordinate with each other and form big clusters, while more credible users are likely to fromsmallclusters.Specifically,thecredibilityscoresaremeasured through the following major steps: 1) detect and cluster coordinate usersbasedonusersimilarities;2)weighteachclusterbasedonthe clustersize.Notethatforourfakenewsdetectiontask,wedonot assume that credibility scores are directly provided, but inferred from widely available data, such as user-generated contents. By using the method in [ 1], we can assign each useru ia credibility score c i∈[0,1]. A largerc iindicates that useru ihas a higher credibility, while a lowerc iindicates a lower credibility score. We usec={c 1,c 2,...,c m}to denote the credibility score vector for all users. First,high-credibilityusersaremorelikelytosharetruenews pieces, so we ensure that the distance between latent features of high-credibility users and that of true news is minimized, min U,D L≥0m/summationdisplay.1 i=1r/summationdisplay.1 j=1W ijc i(1−1+yLj  2)||Ui−D L j||22 (3) and(1−1+y Lj  2)is to ensure we only include true news pieces (i.e., y Lj=−1), andc iis to adjust the contribution of useru ito the loss function. For example, ifc iis large (high-credibility) andW ij=1, we put a bigger weight on forcing the distance of featureU iand D Ljto be small; ifc iis small (low-credibility) andW ij=1, than weputasmallerweightonforcingthedistanceoffeatureU iand D Ljto be small. Second, low-credibility users are more likely to share fake news pieces,andweaimtominimizethedistancebetweenlatentfeatures of low-credibility users and that of fake news, min U,D L≥0m/summationdisplay.1 i=1r/summationdisplay.1 j=1W ij(1−c i)(1+yLj  2)||Ui−D L j||22 (4) andtheterm(1+y Lj  2)istoensureweonlyincludefakenewspieces (i.e., y L j=1),and(1−c i)istoadjustthecontributionofuseru ito thelossfunction.Forexample,ifc iislarge(high-credibility)and W ij=1,weputasmallerweightonforcingthedistanceoffeature U iandD Ljto be small; ifc iis small (low-credibility) andW ij=1, thenweputabiggerweightonforcingthedistanceoffeatureU i andD Ljto be small. Finally, We combine Eqn 3 and Eqn 4 to consider the above two situations,and obtain the followingobjective function, min U,D L≥0m/summationdisplay.1 i=1r/summationdisplay.1 j=1W ijc i(1−1+yLj  2)||Ui−D L j||22 /bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright True news +m /summationdisplay.1 i=1r/summationdisplay.1 j=1W ij(1−c i)(1+yLj  2)||Ui−D L j||22 /bracehtipupleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipdownright/bracehtipdownleft/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehext/bracehtipupright Fake news(5) Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 314For simplicity, Eqn 5 can be rewritten as, min U,D L≥0m/summationdisplay.1 i=1r/summationdisplay.1 j=1G ij||U i−D L j||22 (6) whereG ij=W ij(c i(1−1+y Lj  2)+(1−c i)(1+y Lj  2)). If we denote a newmatrixH=[U;D L]∈R(m+r)×d ,wecanalsorewriteEqn.6as a matrix form as follows, min U,D L≥0m/summationdisplay.1 i=1r/summationdisplay.1 j=1G ij||U i−D L j||22 ⇔min H≥0m/summationdisplay.1 i=1r+m/summationdisplay.1 j=1+mG ij||H i−H j||22 ⇔min H≥0m+r/summationdisplay.1 i,j=1F ij||H i−H j||22 ⇔min H≥0tr(HT LH) (7) whereL=S−Fis the Laplacian matrix andSis a diagonal ma- trix with diagonal element S ii=/summationtext.1m+rj=1 F ij.F∈R(m+r)×(m+r) is computed as follows, F ij=⎧⎪⎪⎪⎨ ⎪⎪⎪⎩0,i,j∈[1,m]ori,j∈[m+1,m+r] G i(j−m),i∈[1,m],j∈[m+1,m+r] G (i−m)j,i∈[m+1,m+r],j∈[1,m](8) 3.4 Publisher-News Relation Embedding Fakenewsisoftenwrittentoconveyopinionsorclaimsthatsup- portthepartisanbiasofnewspublishers.Thus,agoodnewsrep- resentation should be good at predicting the partisan bias of its publisher.Weobtainthelistofpublishers’partisanscoresfroma well-known media bias fact-checking websites MBFC3 . The parti- san bias labels are checked with a principled methodology that en- suresthereliabilityandobjectivityofthepartisanannotations.The labelsarecategorizedintofivecategories:“left”,“left-Center”,“least- biased”,“right-Center”and“right”.Tofurtherensuretheaccuracyof thelabels,weonlyconsiderthosenewspublisherswiththeannota- tions [“left”,“least-biased”, “Right”], and rewrite the corresponding labels as [-1,0,1]. Thus, we can construct a partisan label vectors for news publishers aso. Note that we may not obtain the partisan labelsforallpublishers,soweintroducee∈{0,1}l×1 tocontrolthe weight ofo. If we have the partisan bias label of publisherp k, then e k=1; otherwise,e k=0. The basic idea is to utilize publisher par- tisanlabelsvectoro∈Rl×1 andpublisher-newsmatrixB∈Rl×n tooptimizethenewsfeaturerepresentationlearning.Specifically, we optimization following objective function, min D≥0,q/bardble⊙(¯BDq−o)/bardbl22 +λ/bardblq/bardbl22 (9) where we assume that the latent feature of news publisher can be represented by the features of all the news it published, i.e., ¯BD .¯B is the normalized user-news publishing relation matrix, i.e., ¯B kj=B kj  /summationtext.1 nj=1 B kj.q∈Rd×1 istheweightingmatrixthatmapsnews publishers’ latent features to corresponding partisan label vectoro. 3 https://mediabiasfactcheck.com/3.5 Proposed Framework - TriFN Wehaveintroducedhowwecanlearnnewslatentfeaturesbymod- eling different aspects of the tri-relationship. We further employ a semi-supervised linear classifier term as follows, min p/bardblD Lp−y L/bardbl22 +λ/bardblp/bardbl22 (10) wherep∈Rd×1 is the weighting matrix that maps news latent features to fake news labels. With all previous components, TriFN solves the following optimization problem, min D,U,V,T≥0,p,q/bardblX−DVT /bardbl2F +α/bardblY⊙(A−UTUT )/bardbl2F +βtr(HT LH)+γ/bardble⊙(¯BDq−o)/bardbl22 +η/bardblD Lp−y L/bardbl22 +λR(11) whereR=(/bardblD/bardbl2F +/bardblV/bardbl2F +/bardblU/bardbl2F +/bardblT/bardbl2F +/bardblp/bardbl22 +/bardblq/bardbl22 )is to avoidover-fitting.Thefirsttermmodelsthenewslatentfeatures from news contents; the second term extracts user latent features from their social relationships; and the third term incorporates the user-newsinteractions;andthefourthtermmodelspublisher-news relationships. The fifth term adds a semi-supervised fake news classifier. Therefore,this frameworkprovides aprincipledway to model tri-relationship for fake news prediction.\n",
      "\n",
      "Contents of the heading '4 AN OPTIMIZATION ALGORITHM': \n",
      "\n",
      "Inthissection,wepresentthedetailoptimizationprocessforthe proposed framework TriFN. If we update the variables jointly, the objective function in Eq. 11 is not convex. Thus, we propose to use alternating least squares to update the variables separately. For simplicity, we userLto denote the objective function in Eq. 11. Next, we introduce the updating rules for each variable in details. UpdateD. LetΨ Dbe the Lagrange multiplier for constraint D≥0, the Lagrange function related toDis, min D/bardblX−DVT /bardbl2F +βtr(HT LH)+γ/bardble⊙(¯BDq−o)/bardbl22 +η/bardblD Lp−y L/bardbl22 +λ/bardblD/bardbl2F −tr(Ψ DDT )(12) andD=[D L;D U]andH=[U;D L].WerewriteL=[L 11,L 12;L 21,L 22], where L 11∈Rm×m ,L 12∈Rm×r ,L 21∈Rr×m ,andL 22∈Rr×r ;and X=[X L,X U]. The partial derivative ofLw.r.t.Das follows, 1 2∂L  ∂D=(DVT −X)V+λD+γ¯BT ET (E¯BDq−Eo)qT +/bracketleftbigβL 21U+βL 22D L+η(D Lp−y L)pT ;0/bracketrightbig−Ψ D(13) whereE∈Rl×l is a diagonal matrix with{e k}lk=1 on the diago- nal and zeros everywhere else. By setting the derivative to zero andusingKarush-KuhnTuckercomplementarycondition[3],i.e., Ψ D(i,j)D ij=0,we get, D ij←D ij/radicalBigg  ˆD(i,j)  ˜D(i,j)(14) Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 315ˆD=XV+γ/parenleftbig¯BT ET EoqT/parenrightbig + +γ/parenleftbig¯BT ET E¯BDqqT/parenrightbig − +/bracketleftbigη/parenleftbigD LppT/parenrightbig − +η/parenleftbigy LpT/parenrightbig + +β(L 21U)− +β(L 22D L)− ;0/bracketrightbig ˜D=DV T V+λD+γ/parenleftbigBT ET E¯BDqqT )+ +γ/parenleftbig¯BT ET EoqT/parenrightbig − +/bracketleftbigβ(L 21U)+ +β(L 22D L)+ +η/parenleftbigD LppT/parenrightbig + +η/parenleftbigy LpT/parenrightbig − ;0/bracketrightbig(15) where for any matrixX,(X)+ and(X)− denote the positive and negative parts of X, respectively. Specifically, we have(X)+ = ABS(X)+X  2and(X)− =ABS(X)−X  2,ABS(X)is the matrix with the absolutevalueof elements inX. UpdateU,VandT. ThepartialderivativeoftheLagrangeob- jective function w.r.t.Uand updating rule are as follows, 1 2∂L  ∂U=α(Y⊙(UTUT −A))UTT +α(Y⊙(UTUT −A))T UT +λU−Ψ U+β(L 11U+L 12D L) (16) U ij←U ij/radicaltp/radicalbt /bracketleftbigˆU/bracketrightbig(i,j)  /bracketleftbig˜U/bracketrightbig(i,j)(17) ˆU=α(Y⊙A)UT T +α(Y⊙A)T UT+β(L 11U)− +β(L 12D L)− ˜U=α(Y⊙UTUT )UTT +α(Y⊙UTUT )T UT+λU +β(L 11U)+ +β(L 12D L)+ (18) The partial derivatives of the Lagrange objective w.r.tVand updat- ing rule are, 1 2∂L  ∂V=(DVT −X)T D+λV−Ψ V(19) V ij←V ij/radicaltp/radicalbt /bracketleftbigX T D/bracketrightbig(i,j)  /bracketleftbigVD T D+λV/bracketrightbig(i,j)(20) The partial derivative of the Lagrange objective w.r.tTand the updating rule are, 1 2∂L  ∂T=αUT (Y⊙(UTUT −A))U+λT−Ψ T(21) T ij←T ij/radicaltp/radicalbt /bracketleftbigαU T (Y⊙A)U/bracketrightbig(i,j)  /bracketleftbigαU T (Y⊙UTUT )U+λT/bracketrightbig(i,j)(22) Updatepandq. Optimization w.r.tpandqare essentially least squareproblems.Bysetting∂L  ∂p=0and∂L  ∂q=0,theclosedfrom solutionsofpandqare as follows, p=(ηD TL D L+λI)−1 ηDTL y L q=(γDT ¯BT E¯BD+λI)−1 γDT ¯BT Eo(23) WhereIis an identity matrix, andE∈Rl×l withe k,k=1,...,l on the diagonal and zeros everywhere else. 4.1 OptimizationAlgorithmof TriFN WepresentthedetailstooptimizeTriFNinAlgorithm1.Wefirstran- domlyinitialize U,V,T,D,p,qinline1,andconstructtheLaplacian matrixLinline2.Thenwerepeatedlyupdaterelatedparameters through Line 4 to Line 8 until convergence. Finally, we predict the labelsofunlabelednewsy Uinline10.TheconvergenceofAlgo- rithm1isguaranteedbecausetheobjectivefunctionisnonnegative Algorithm1Theoptimizationprocess of TriFN framework  Require:X,A,B,W,Y,o,y L,α,β,γ,λ,η Ensure:y U 1:RandomlyinitializeU,V,T,D,p,q 2:Precompute Laplacian matrixL 3:repeat 4:UpdateDwithEqn 14 5:UpdateUwithEqn 18 6:UpdateVwithEqn 20 7:UpdateTwithEqn 22 8:Updatep,qwithEqn 23 9:untilconvergence 10:Calculatey U=Sign(D Up)  andineachiterationitwillmonotonicallydecreasetheobjective value, and finally it will converge to an optimal point [15]. 4.2 Complexity Analysis Themaincomputationcostcomesfromthefine-tuningvariablesfor Algorithm1.In each iteration,the time complexityfor computing DisO(nd+nld2 +rd+rm+n2 ).Similarly,thecomputationcostfor Vis approximatelyO(tnd), forUisO(m4 d3 +md), forTis about O(m4 d3 +m2 d2 ). To updatepandq, the costs are approximately O(d3 +d2 +dr)andO(d2 ln+d3 +dl).Theoveralltimecomplexity is the sum of the costs of initialization and fine-tuning.\n",
      "\n",
      "Contents of the heading '5 EXPERIMENTS': \n",
      "\n",
      "In this section, we present the experiments to evaluate the effec- tiveness of the proposed TriFN framework. Specifically, we aim to answer the following research questions: • Is TriFN able to improve fake news classification perfor- mancebymodelingpublisherpartisananduserengagements simultaneously? • How effective are publisher partisan bias modeling and user engagement learning, respectively, in improving the fake news detection performance of TriFN? • Can the proposed method handle early fake news detection whenlimited user engagements are provided? 5.1 Datasets Table 1: The statistics of FakeNewsNet dataset  PlatformBuzzFeed PolitiFact # Users15,257 23,865 # Engagements25,240 37,259 # Social Links634,750 574,744 # Candidate news182 240 # True news91 120 # Fake news91 120 # Publisher991 We utilize one of the comprehensive fake news detection bench- mark dataset called FakeNewsNet [31,32]. The dataset is collected Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 316from two platforms with fact-checking:BuzzFeedandPolitiFact, both containing news content with labels and social context in- formation. News content includes the meta attributes of the news (e.g., body text), and social context includes the related user so- cial engagements of news items (e.g., user posting/sharing news in Twitter).ThedetailedstatisticsofthedatasetsareshowninTable1. 5.2 ExperimentalSettings Toevaluatetheperformanceoffakenewsdetectionalgorithms,we usethefollowingmetrics,whicharecommonlyusedtoevaluate classifiers in related areas: Accuracy, Precision, Recall, and F1. We randomlychoose80%ofnewspiecesfortrainingandremaining20% fortesting,andtheprocessisperformedfor10timesandtheaverage performance is reported. We compare the proposed framework TriFN with several state-of-the-art fake news detection methods. Existing methods mainly focus on extractingdiscriminative features andfeedthemintoaclassificationalgorithmtodifferentiatefake news.Next,weintroduceseveralrepresentativefeaturesasfollows, •RST[26]:RSTstandsforRhetoricalStructureTheory,which buildsatreestructuretorepresentrhetoricalrelationsamong thewordsinthetext.RSTcanextractstyle-basedfeatures ofnewsbymappingthefrequenciesofrhetoricalrelations to a vector space4 . •LIWC [23]: LIWC stands for Linguistic Inquiry and Word Count,whichiswidelyusedtoextractthelexiconsfalling into psycholinguistic categories. It’s based on a large sets of wordsthatrepresentpsycholinguisticprocesses,summary categories, and part-of-speech categories. It learns a feature vector from a psychology and deception perspective5 . •Castillo [4]: Castillo extract various kinds of features from those users who have shared a news item on social media. The features are extracted from user profiles and friendship network. We also include the credibility score of users in- ferred in Sec 3.3 as an additional social context feature. •RST+Castillo : RST+Castillo represents the concatenated featuresofRSTandCastillo,whichincludefeaturesextracted from both news content and social context. •LIWC+Castillo :LIWC+Castillorepresentstheconcatenated featuresofLIWCandCastillo,whichconsistsoffeaturein- formationfrom both news content and social context. Notethatforafairandcomprehensivecomparison,wechoose the above feature extraction methods from following aspects: 1) only extract features from news contents, such as RST, LIWC; 2) only construct features from social context, such as Castillo; and 3) consider both news content and social context, such as RST+Castillo, LIWC+Castillo 5.3 PerformanceComparison We evaluate the effectiveness of the proposed framework TriFN for fake news classification. We determine model parameters with cross-validation strategy, and we repeat the generating process of training/test set for three times and the average performance is reported. We first perform cross validation on parameters λ∈  4 The code is available at: https://github.com/jiyfeng/DPLP 5 The readers can find more details about the software and feature description at: http://liwc.wpengine.com/ {0.001,0.01,0.1,1,10},andchoosethose parametersthatachieves best performance, i.e.,λ=0.1. We also choose latent dimension d=10foreasyparametertuning,andfocusontheparametersthat contribute the tri-relationshipmodeling components. The parame- ters for TriFN are set as{α=1e−4,β=1e−5,γ=1,η=1}for BuzzFeed and{α=1e−5,β=1e−4,γ=10,η=1}for PolitiFact. We test the baseline features on different learning algorithms, and choose the one that achieves the best performance (see Ta- ble 2). The algorithms include Logistic Regression (LogReg for short),NaïveBayes(NBayes),DecisionTree(DTree),RandomForest (RForest), XGBoost, AdaBoost, and Gradient Boosting (GradBoost). Weusedtheopen-sourcedxgboost[5]packageandscikit-learn[22] machine learning framework in Python to implement all these algorithms. To ensure a fair comparison of features, we ran all the algorithms using default parameter settings. We also show the performancesforeachlearningalgorithmandreporttheaverage performanceon bothdatasets.Due tothespacelimitation,weonly showthe results ofF1score (Table3and Table4).Weobservesimi- larresultsforothermetricsintermsofaverageperformance.Based on Table 2, Table 3, and Table 4, we have following observations: • FornewscontentbasedmethodsRSTandLIWC,wecansee thatLIWC>RSTfor both best performance and average performance, indicating that LIWC can better capture the linguistic features in news contents. The good results of LIWCdemonstratethatfakenewspiecesareverydifferent fromrealnewsintermsofchoosingthewordsthatreveal psychometricscharacteristics. • In addition, social context based features are more effective than news content based features, i.e.,Castillo>RSTand Castillo>LIWC. It shows that social context features have morediscriminativepowerthanthoseonlyonnewscontent for predicting fake news. • Moreover, methods using both news contents and social context perform better than those methods purely based onnewscontents,andthosemethodsonlybasedonsocial engagements,i.e.,LIWC+Castillo>LIWCorCastilloand RST+Castillo>RSTorCastillo. This indicates that fea- tures extracted from news content and corresponding social context have complementary information, and thus boost the detectionperformance. • Generally, for methods based on both news content and socialcontext(i.e.,RST+Castillo,LIWC+Castillo,andTriFN), wecanseethatTriFNconsistentlyoutperformstheothertwo baselines,i.e., TriFN>LIWC+CastilloandTriFN>RST+ Castillo , in terms of all evaluation metrics on both datasets. Forexample,TriFNachievesaveragerelativeimprovement of 4.72%,5.84% on BuzzFeed and 5.91%,4.39% on PolitiFact, comparingwithLIWC+CastillointermsofAccuracyandF1 score.Itsupportstheimportancetomodeltri-relationshipof publisher-news and news-user to better predict fake news. 5.4 Assessing Impacts of Users and Publishers Inprevioussection,weobservethatTriFNframeworkimprovesthe classification results significantly. In addition to news contents, we also captures user-news interactions and publisher-news relations. Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 317Table 2: Best performance comparison for fake news detection  DatasetsMetricRSTLIWCCastilloRST+CastilloLIWC+CastilloTriFN  BuzzFeed Accuracy0.600±0.0630.719±0.0740.800±0.0370.816±0.0520.825±0.052 0.864±0.026  Precision0.662±0.1090.722±0.0770.822±0.0770.879±0.0490.821±0.061 0.849±0.040  Recall0.615±0.0180.732±0.1710.776±0.0270.748±0.0980.829±0.055 0.893±0.013  F10.633±0.0560.709±0.0750.797±0.0440.805±0.0660.822±0.035 0.870±0.019 PolitiFact Accuracy0.604±0.0600.688±0.0630.796±0.0520.838±0.0360.829±0.052 0.878±0.017  Precision0.564±0.0640.725±0.0870.767±0.0560.851±0.0520.821±0.116 0.867±0.034  Recall0.705±0.1480.617±0.1000.889±0.0440.824±0.0630.879±0.047 0.893±0.023  F10.615±0.0740.666±0.0920.822±0.0370.835±0.0430.843±0.054 0.880±0.015 Table 3: Average F1 of baselines for different learning algo- rithmson BuzzFeed. Best scores are highlighted. Method RST LIWC CastilloRST +CastilloLIWC +Castillo  LogReg 0.519 0.660 0.714 0.728 0.760 NBayes 0.511 0.370 0.600 0.716 0.680 DTree 0.566 0.581 0.736 0.681 0.772 RForest 0.5380.709 0.7670.805 0.733 XGBoost 0.480 0.6720.797 0.795 0.782 AdaBoost0.633 0.701 0.724 0.791 0.768 GradBoost 0.492 0.699 0.772 0.7240.822  Table 4: Average F1 of baselines for different learning algo- rithmson PolitiFact. Best scores are highlighted. Method RST LIWC CastilloRST +CastilloLIWC +Castillo  LogReg0.615 0.432 0.707 0.668 0.653 NBayes 0.537 0.486 0.442 0.746 0.687 DTree 0.514 0.661 0.771 0.792 0.772 RForest 0.463 0.586 0.7670.835 0.836 XGBoost 0.552 0.6480.822 0.783 0.823 AdaBoost 0.5020.666 0.800 0.787 0.831 GradBoost 0.517 0.650 0.818 0.8030.843 Now, we investigate the effects of these components by defining three variants of TriFN: • TriFN\\P - We eliminate the effect of publisher partisan mod- eling partγ/bardble⊙(¯BDq−o)/bardbl22 by settingγ=0. • TriFN\\S-Weeliminatetheeffectsofusersocialengagements componentsα/bardblY⊙(A−UTUT )/bardbl2F +βtr(HT LH)by setting α,β=0. • TriFN\\PS-Weeliminatetheeffectsofbothpublisherpartisan and user social engagements, by settingα,β,γ=0. The model only consider news content embedding. The parameters in all the variants are determined with cross- validation and the best performances are shown in Figure 3, we have following observations: • When we eliminate the effect of user social engagements component,theperformanceofTriFN\\Sdegradesincompar- isonwithTriFN.Forexample,theperformancereduces5 .2% and 6.1% in terms of F1 and Accuracy metrics on BuzzFeed, 7.6% and 10.6% on PolitiFact. The results suggest that social engagementsin TriFN is important. (a) BuzzFeed (b) PolitiFact Figure 3: Impact analysis of users and publishers for fake news detection. • We have similar observations for TriFN\\P when eliminat- ingtheeffectofpublisherpartisancomponent.Theresults suggesttheimportancetoconsiderpublisher-newsrelations through publisherpartisanbiasin TriFN. • WhenweeliminatebothcomponentsinTriFN\\PS,theresults arefurtherreducedcomparedtoTriFN\\SandTriFN\\P.Italso suggests that components of user-news and publisher-news embedding are complementary to each other. Through the component analysis of TriFN, we conclude that (i) both components can contribute to the performance improvement of TriFN; (ii) it’s necessary to model both news contents and social engagementsbecause they contain complementary information. 5.5 EarlyFake News Detection Early detection of fake news is very desirable to restrict the dis- semination scope of fake news and prevent the future propagation on social media. Early fake news detection aims to give early alert offakenews,byonlyconsideringlimitedsocialcontextwithina specificrangeoftimedelayoforiginalnewsposted.Specifically,we changethedelaytimein[12,24,36,48,60,72,84,96]hours.From Figure4,wecanseethat:1)generally,thedetectionperformance is getting better when the delay time increase for those methods using social context information, which indicates that more social engagementsofusersonsocialmediaprovidemoreadditionalinfor- mationforfakenewsdetection;2)TheproposedTriFNconsistently achievesbestperformancesonbothdatasetsforaccuracyandF1, which demonstrate the importance of embedding user-news inter- actions to capture effective feature representations; and 3) Even in the very early stage after fake news has been published, TriFN can alreadyachievegoodperformance.Forexample,TriFNcanachieve Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 318F1 score more than 80% within 48 hours on both datasets, which showspromisingpotentialstocombatfakenewattheearlystage.  hours 12 24 36 48 60 72 84 96 AllAccuracy  0.50.60.70.80.91 RST LIWC Castillo RST+Castillo LIWC+Castillo TriFN  (a) Accuracy on BuzzFeed hours 12 24 36 48 60 72 84 96 AllF1  0.50.60.70.80.91 RST LIWC Castillo RST+Castillo LIWC+Castillo TriFN  (b) F1 on BuzzFeed  hours 12 24 36 48 60 72 84 96 AllAccuracy  0.50.60.70.80.91 RST LIWC Castillo RST+Castillo LIWC+Castillo TriFN  (c) Accuracy on PolitiFact hours 12 24 36 48 60 72 84 96 AllF1  0.50.60.70.80.91 RST LIWC Castillo RST+Castillo LIWC+Castillo TriFN  (d) F1 on PolitiFact Figure 4: The performance of early fake news detection on BuzzFeed and PolitiFact in terms of Accuracy and F1. 5.6 Model Parameter Analysis The proposed TriFN has four important parameters. The first two areαandβ,whichcontrolthecontributionsfromsocialrelationship and user-news engagements.γcontrols the contribution of pub- lisherpartisanandηcontrolsthecontributionofsemi-supervised classifier. We first fix{α=1e−4,β=1e−5}and{α=1e−5,β= 1e−4}forBuzzFeedandPolitiFact,respectively.Thenwevaryηas {1,10,20,50,100}andγin{1,10,20,30,100}.Theperformancevari- ationsaredepictedinFigure5.Wecanseei)when ηincreasesfrom 0, eliminating the impact of semi-supervised classification term, to 1,theperformanceincreasedramaticallyinbothdatasets.Thesere- sults support the importance to combine semi-supervised classifier to feature learning; ii) generally, the increase ofγwill increase the performance in a certain region,γ∈[1,50]andη∈[1,50]for both datasets, which easy the process for parameter setting. Next, we fix{γ=1,η=1}and{γ=10,η=1}forBuzzFeedandPolitiFact, respectively.Thenwevaryα,β∈[0,1e−5,1e−4,1e−3,0.001,0.01]. Wecan seethati)whenαandβincreasefrom0, whicheliminate thesocialengagements,to1e−5,theperformanceincreasesrela- tively, which again support the importance of social engagements; ii)Theperformancetendstoincreasefirstandthendecrease,and it’s relatively stable in[1e−5,1e−3].\n",
      "\n",
      "Contents of the heading '6 RELATED WORK': \n",
      "\n",
      "We briefly introduce the related work about fake news detection onsocial media. Fakenewsdetection methodsgenerallyfocuson usingnews contentsandsocial contexts[32, 40]. News contents contain the clues to differentiate fake and real news.Fornewscontentbasedapproaches,featuresareextractedas linguistic-basedandvisual-based.Linguistic-basedfeaturescapture 100 30 20 10 γ 1 00110 η 20501001 0.8 0.6F1 (a)ηandγon BuzzFeed 100 30 20 10 γ 1 00110 η 20501000.81 0.6F1 (b)ηandγon PolitiFact  0.01 0.001 0.0001  α 1e-05 001e-05  β0.00010.0010.010.8 0.61F1 (c)αandβon BuzzFeed 0.01 0.001 0.0001  α 1e-05 001e-05  β 0.00010.0010.010.80.91F1 (d)αandβon PolitiFact Figure 5: Model parameter analysis for TriFN on BuzzFeed and PolitiFactin terms of F1. specificwritingstylesandsensationalheadlinesthatcommonlyoc- curinfakenewscontent[ 24],suchaslexicalandsyntacticfeatures. Visual-based features try to identify fake images [9] that are in- tentionally created or capturing specific characteristics for images in fake news. News content based models include i) knowledge- based: using external sources to fact-checking claims in news con- tent [17,37], and 2) style-based: capturing the manipulators in writingstyle,suchasdeception[7,27]andnon-objectivity[24].For example,Potthastet al.[24]extractedvariousstylefeaturesfrom news contents and predict fake news and media bias. Inadditiontonewscontent,socialcontextrelatedtonewspieces contains rich information to help detect fake news. For social con- text based approaches, the features mainly include user-based, post-basedandnetwork-based.User-basedfeaturesareextracted from user profiles to measure their characteristics and credibili- ties[4,14,34,39].Forexample,Shuet al.[34]proposedtounder- stand user profiles from various aspects to differentiate fake news. Yanget al.[39] proposed an unsupervised fake news detection algorithm by utilizing users’ opinions on social media and estimat- ing their credibilities. Post-based features represent users’ social response in term of stance [ 10], topics [16], or credibility [4,36]. Network-based features [29] are extracted by constructing specific networks,suchasdiffusionnetwork[14]etc.Socialcontextmodels basicallyincludestance-basedandpropagation-based.Stance-based modelsutilizeusers’opinionstowardsthenewstoinfernewsve- racity[ 10].Propagation-basedmodelsassumethatthecredibility ofnewsishighlyrelatedtothecredibilitiesofrelevantsocialme- dia posts, which several propagation methods can be applied [10]. Recently,deeplearningmodelsareappliedtolearnthetemporal and linguistic representation of news [11,30,35]. Shuet al.[33] proposedtogeneratesyntheticdataforaugmentingtrainingdatato helpimprovethedetectionofclickbaits.It’sworthmentioningthat we can not directly compare the propagation-based approaches, because we assume we only have user actions, e.g., posting the Session 6: Networks and Social Behavior WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia 319newsornot.Inthiscase,thepropagationsignalsinferredfromtext are the same and thus become ineffective. In this paper, we are to our best knowledge the first to clas- sify fake news by learning the effective news features through the tri-relationshipembeddingamongpublishers,newscontents,and social engagements.\n",
      "\n",
      "Contents of the heading '7 CONCLUSION AND FUTURE WORK': \n",
      "\n",
      "Due to the inherent relationship among publisher, news and social engagementsduringnewsdisseminationprocessonsocialmedia, we propose a novel framework TriFN to model tri-relationship forfakenewsdetection.TriFNcanextracteffectivefeaturesfrom news publisher and user engagements separately, as well as cap- ture the interrelationship simultaneously. Experimental results on real world fake news datasets demonstrate the effectiveness of the proposed framework and importance of tri-relationship for fake news prediction. It’s worth mentioning TriFN can achieve good detectionperformance in the early stage of news dissemination. Thereareseveralinterestingfuturedirections.First,it’sworthto exploreeffectivefeaturesandmodelsforearlyfakenewsdetection, asfakenewsusuallyevolvesveryfastonsocialmedia;Second,how toextractfeaturestomodelfakenewsintentionfrompsychology’s perspectiveneedsfurtherinvestigation.Atlast,howtoidentifylow qualityorevenmalicioususersspreadingfakenewsisimportant for fake news intervention and mitigation.\n",
      "\n",
      "Contents of the heading '8 ACKOWLEDGMENTS': \n",
      "\n",
      "Thismaterialisbaseduponworksupportedby,orinpartby,the NSF #1614576and the ONR grantN00014-16-1-2257.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(\"Contents of the heading '\"+headings[i]+\"': \")\n",
    "    print()\n",
    "    para_text=[]\n",
    "    if i>=0 and i<7:\n",
    "        for j in range (((chunks.index(headings[i]))+1), (chunks.index(headings[i+1])) ): #e.g, 42 to (177-1) (since, exclusive upper bound for 177) for \"1 Introduction\"\n",
    "                para_text.append(chunks[j])  \n",
    "    else:\n",
    "         for j in range (((chunks.index(headings[i]))+1), (chunks.index('REFERENCES'))):  #e.g, There's no next heading for '8 Acknowledgements'\n",
    "                para_text.append(chunks[j])  \n",
    "\n",
    "    paragraph_string=\" \".join(para_text)\n",
    "    print(paragraph_string)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9ff22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b72d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa7458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21726ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e89612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b4ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad415c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
