{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b6068f",
   "metadata": {},
   "source": [
    "# Computing with Language: Simple Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f77f9b",
   "metadata": {},
   "source": [
    "# Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6cc97",
   "metadata": {},
   "source": [
    "Frequency Distributions, in the context of Natural Language Processing (NLP), are, put simply, the tally of the number of times that each unique word is present in the given piece of text. Recording the frequency distribution can be used to determine what words are high/ low in significance to the given context or in general and to determine the summary/ gist/ topic of discussion that the text is based on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f159bf6",
   "metadata": {},
   "source": [
    "NLTK makes it easier to deal with frequency distributions and various pertinent statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca559815",
   "metadata": {},
   "source": [
    "IMPLEMENTATION: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8208bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205c2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " '--',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " ',',\n",
       " 'heart',\n",
       " ',',\n",
       " 'body',\n",
       " ',',\n",
       " 'and',\n",
       " 'brain',\n",
       " ';',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing first 50 words of one of the books\n",
    "ex= text1[:50]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b060fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist=FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f528e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting to know the count of number of unique words\n",
    "\n",
    "count=len(fdist)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a055a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Knowing about 50 most common words and their respective frequencies\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bdee9c",
   "metadata": {},
   "source": [
    "# Fine-grained Selection of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb3424",
   "metadata": {},
   "source": [
    "Fine- grained selection of words is essential because while performing natural language processing (NLP) mostly with Natural language toolkit (NLTK) and other libraries, we deal with texts of huge size (including corpora, web- based textual information, etc.) and we are usually only interested in dealing with a particular small piece of text and or specific feauture, property, dimension, etc. So, we need some technically efficient and accurate methods to get fine-grained portions (usually words) of a large piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e07354",
   "metadata": {},
   "source": [
    "Sometimes, we take assistance from set theory and we apply set operations to speed up the process, since set operations assist in de- duplication and it can be really helpful in situations where there is a large- size input text and there are a lot of duplicates of a lot of words , reducing the computational time for which significantly increases the technical efficiency of the computational process under consideration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d963a82",
   "metadata": {},
   "source": [
    "EXAMPLE OF SIGNIFICANCE OF SET OPERATIONS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a05775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the text to be considered\n",
    "\n",
    "original_text=\"Artificial Intelligence (AI) By JAKE FRANKENFIELD Updated March 08, 2021 Reviewed by GORDON SCOTT What Is Artificial Intelligence (AI)? Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving. The ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. A subset of artificial intelligence is machine learning, which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by humans. Deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as text, images, or video. KEY TAKEAWAYS Artificial intelligence refers to the simulation of human intelligence in machines. The goals of artificial intelligence include learning, reasoning, and perception. AI is being used across different industries including finance and healthcare. Weak AI tends to be simple and single-task oriented, while strong AI carries on tasks that are more complex and human-like. What if you had started investing years ago? Find out what a hypothetical investment would be worth today. SELECT A STOCK TSLA TESLA INC AAPL APPLE INC NKE NIKE INC AMZN AMAZON.COM, INC WMT WALMART INC SELECT INVESTMENT AMOUNT $ 1,000 SELECT A PURCHASE DATE 5 years ago CALCULATE Understanding Artificial Intelligence (AI) When most people hear the term artificial intelligence, the first thing they usually think of is robots. That's because big-budget films and novels weave stories about human-like machines that wreak havoc on Earth. But nothing could be further from the truth. Artificial intelligence is based on the principle that human intelligence can be defined in a way that a machine can easily mimic it and execute tasks, from the most simple to those that are even more complex. The goals of artificial intelligence include mimicking human cognitive activity. Researchers and developers in the field are making surprisingly rapid strides in mimicking activities such as learning, reasoning, and perception, to the extent that these can be concretely defined. Some believe that innovators may soon be able to develop systems that exceed the capacity of humans to learn or reason out any subject. But others remain skeptical because all cognitive activity is laced with value judgments that are subject to human experience. As technology advances, previous benchmarks that defined artificial intelligence become outdated. For example, machines that calculate basic functions or recognize text through optical character recognition are no longer considered to embody artificial intelligence, since this function is now taken for granted as an inherent computer function. AI is continuously evolving to benefit many different industries. Machines are wired using a cross-disciplinary approach based on mathematics, computer science, linguistics, psychology, and more. Algorithms often play a very important part in the structure of artificial intelligence, where simple algorithms are used in simple applications, while more complex ones help frame strong artificial intelligence. Applications of Artificial Intelligence The applications for artificial intelligence are endless. The technology can be applied to many different sectors and industries. AI is being tested and used in the healthcare industry for dosing drugs and different treatment in patients, and for surgical procedures in the operating room. Other examples of machines with artificial intelligence include computers that play chess and self-driving cars. Each of these machines must weigh the consequences of any action they take, as each action will impact the end result. In chess, the end result is winning the game. For self-driving cars, the computer system must account for all external data and compute it to act in a way that prevents a collision. Artificial intelligence also has applications in the financial industry, where it is used to detect and flag activity in banking and finance such as unusual debit card usage and large account deposits—all of which help a bank's fraud department. Applications for AI are also being used to help streamline and make trading easier. This is done by making supply, demand, and pricing of securities easier to estimate. Categorization of Artificial Intelligence Artificial intelligence can be divided into two different categories: weak and strong. Weak artificial intelligence embodies a system designed to carry out one particular job. Weak AI systems include video games such as the chess example from above and personal assistants such as Amazon's Alexa and Apple's Siri. You ask the assistant a question, it answers it for you. Strong artificial intelligence systems are systems that carry on the tasks considered to be human-like. These tend to be more complex and complicated systems. They are programmed to handle situations in which they may be required to problem solve without having a person intervene. These kinds of systems can be found in applications like self-driving cars or in hospital operating rooms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7163e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in list version of the text split into words: 817\n"
     ]
    }
   ],
   "source": [
    "#Split the given string text into individual word- tokens\n",
    "text= original_text.split()\n",
    "\n",
    "#print(text)\n",
    "print(\"The number of words in list version of the text split into words: \"+str(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "280fd1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in set version of the text split into words (i.e, size of VOCABULARY): 421\n"
     ]
    }
   ],
   "source": [
    "#Get the set version of the text\n",
    "set_text= set(text)\n",
    "\n",
    "#print(set_text)\n",
    "print(\"The number of words in set version of the text split into words (i.e, size of VOCABULARY): \"+str(len(set_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefc8c5",
   "metadata": {},
   "source": [
    "Note: We can clearly see how significantly choosing the set mode for computational operations can increase the technical efficiency of the computational operations.\n",
    "\n",
    "We can perform the following kind of operations to perform fine- grained analysis on words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "431bdc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long words of lengths more than 8  in the vocabulary are: \n",
      "\n",
      "['complicated', 'activities', 'linguistics,', 'intelligence', 'reasoning,', 'Understanding', 'associated', 'intelligence.', 'situations', 'cognitive', 'human-like.', 'judgments', 'cross-disciplinary', 'department.', 'achieving', 'mimicking', 'treatment', 'estimate.', 'INVESTMENT', 'applications,', 'concretely', 'assistants', 'securities', 'different', 'recognition', 'industries', 'technology', 'problem-solving.', 'mathematics,', 'FRANKENFIELD', 'outdated.', 'collision.', 'streamline', 'unstructured', 'big-budget', 'algorithms', 'continuously', 'perception.', 'developers', 'automatic', 'activity.', 'functions', 'Categorization', 'AMAZON.COM,', 'Algorithms', 'healthcare', 'structure', 'Intelligence', 'character', 'Artificial', 'calculate', 'Applications', 'principle', 'oriented,', 'intelligence,', 'self-driving', 'hypothetical', 'function.', 'including', 'consequences', 'intervene.', 'artificial', 'psychology,', 'industries.', 'TAKEAWAYS', 'assistant', 'experience.', 'CALCULATE', 'rationalize', 'perception,', 'question,', 'absorption', 'advances,', 'programmed', 'benchmarks', 'considered', 'machines.', 'procedures', 'operating', 'computers', 'learning,', 'skeptical', 'characteristic', 'deposits—all', 'important', 'single-task', 'automatically', 'techniques', 'categories:', 'surprisingly', 'investing', 'patients,', 'investment', 'human-like', 'Researchers', 'healthcare.', 'recognize', 'simulation', 'innovators', 'particular', 'industry,', 'applications', 'financial']\n"
     ]
    }
   ],
   "source": [
    "#Defining the V variable for vocabulary\n",
    "V= set_text\n",
    "\n",
    "#Filtering off the words that are significantly long\n",
    "long_words = [w for w in V if len(w) > 8]\n",
    "\n",
    "print(\"Long words of lengths more than 8  in the vocabulary are: \")\n",
    "print()\n",
    "print(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd4b6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted words of lengths more than 8  in the vocabulary are: \n",
      "\n",
      "['AMAZON.COM,', 'Algorithms', 'Applications', 'Artificial', 'CALCULATE', 'Categorization', 'FRANKENFIELD', 'INVESTMENT', 'Intelligence', 'Researchers', 'TAKEAWAYS', 'Understanding', 'absorption', 'achieving', 'activities', 'activity.', 'advances,', 'algorithms', 'applications', 'applications,', 'artificial', 'assistant', 'assistants', 'associated', 'automatic', 'automatically', 'benchmarks', 'big-budget', 'calculate', 'categories:', 'character', 'characteristic', 'cognitive', 'collision.', 'complicated', 'computers', 'concretely', 'consequences', 'considered', 'continuously', 'cross-disciplinary', 'department.', 'deposits—all', 'developers', 'different', 'estimate.', 'experience.', 'financial', 'function.', 'functions', 'healthcare', 'healthcare.', 'human-like', 'human-like.', 'hypothetical', 'important', 'including', 'industries', 'industries.', 'industry,', 'innovators', 'intelligence', 'intelligence,', 'intelligence.', 'intervene.', 'investing', 'investment', 'judgments', 'learning,', 'linguistics,', 'machines.', 'mathematics,', 'mimicking', 'operating', 'oriented,', 'outdated.', 'particular', 'patients,', 'perception,', 'perception.', 'principle', 'problem-solving.', 'procedures', 'programmed', 'psychology,', 'question,', 'rationalize', 'reasoning,', 'recognition', 'recognize', 'securities', 'self-driving', 'simulation', 'single-task', 'situations', 'skeptical', 'streamline', 'structure', 'surprisingly', 'techniques', 'technology', 'treatment', 'unstructured']\n"
     ]
    }
   ],
   "source": [
    "#Performing sort operation on long_words so that the filtered- off list is, now, even more organized and aligned\n",
    "\n",
    "print(\"Sorted words of lengths more than 8  in the vocabulary are: \")\n",
    "print()\n",
    "print(sorted(long_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737fd437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All- lowercase versions of sorted words of lengths more than 8  in the vocabulary are: \n",
      "\n",
      "['amazon.com,', 'algorithms', 'applications', 'artificial', 'calculate', 'categorization', 'frankenfield', 'investment', 'intelligence', 'researchers', 'takeaways', 'understanding', 'absorption', 'achieving', 'activities', 'activity.', 'advances,', 'algorithms', 'applications', 'applications,', 'artificial', 'assistant', 'assistants', 'associated', 'automatic', 'automatically', 'benchmarks', 'big-budget', 'calculate', 'categories:', 'character', 'characteristic', 'cognitive', 'collision.', 'complicated', 'computers', 'concretely', 'consequences', 'considered', 'continuously', 'cross-disciplinary', 'department.', 'deposits—all', 'developers', 'different', 'estimate.', 'experience.', 'financial', 'function.', 'functions', 'healthcare', 'healthcare.', 'human-like', 'human-like.', 'hypothetical', 'important', 'including', 'industries', 'industries.', 'industry,', 'innovators', 'intelligence', 'intelligence,', 'intelligence.', 'intervene.', 'investing', 'investment', 'judgments', 'learning,', 'linguistics,', 'machines.', 'mathematics,', 'mimicking', 'operating', 'oriented,', 'outdated.', 'particular', 'patients,', 'perception,', 'perception.', 'principle', 'problem-solving.', 'procedures', 'programmed', 'psychology,', 'question,', 'rationalize', 'reasoning,', 'recognition', 'recognize', 'securities', 'self-driving', 'simulation', 'single-task', 'situations', 'skeptical', 'streamline', 'structure', 'surprisingly', 'techniques', 'technology', 'treatment', 'unstructured']\n"
     ]
    }
   ],
   "source": [
    "#Performing the upper-case to lower- case word transformation to get all the words in lower case\n",
    "\n",
    "lower_case_sorted_long_words= [w.lower() for w in sorted(long_words)]\n",
    "\n",
    "print(\"All- lowercase versions of sorted words of lengths more than 8  in the vocabulary are: \")\n",
    "print()\n",
    "print(lower_case_sorted_long_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76f474",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e90fdd76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8be18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f9d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a6144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
